\documentclass{article}[14pts]

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
\usepackage[spanish]{babel}
\usepackage{amssymb, amsthm}
\usepackage{bbm}
\usepackage{bm}
\usepackage[bb=dsserif]{mathalpha}
\usepackage{amsmath}
\usepackage{stackrel}
\usepackage{tikz}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{kbordermatrix}
\usepackage{unicode-math}
\usepackage{dsfont}
\usepackage{geometry}
\usetikzlibrary{shapes.geometric}

\usepackage[utf8]{inputenc}
%\usepackage[vietnam]{babel}
\usepackage{xcolor,colortbl}

\newcommand\Bbbbone{%
    \ifdefined\mathbbb%
        \mathbbb{1}%
    \else%
        \boldsymbol{\mathbb{1}}%
    \fi}

\newcommand{\hh}[1]{{\color{red} * #1 *}}
\newcommand{\fs}[1]{{\color{blue}* #1 *}}

%%%% Ajustamos el margen y el font de la descripción de cada figura.
\captionsetup[figure]{margin=50pt, justification=justified}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Para teoremas, proposición y demnostración
\newtheorem{teorema}{Teorema}
\newtheorem{prop}[teorema]{Proposición}
\newtheorem{lema}[teorema]{Lema}
\newtheorem{corolario}[teorema]{Corolario}
\newtheorem{definicion}[teorema]{Definición}
%\newtheorem{}{}


% Creación de comandos %
\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}

\newcommand{\K}[2][5]{
    \begin{tikzpicture}
        \def\ang{360/#2}
        % Dibujar vértices como círculos negros
        \foreach \i in {1,...,#2}
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt] at (\ang*\i:#1) {};
        % Dibujar aristas
        \foreach \i in {1,...,#2}
            \foreach \j in {1,...,#2}
                \draw (\ang*\i:#1) -- (\ang*\j:#1);
    \end{tikzpicture}
}


% Palabras recurrentes Chung,Graham y Wilson
\newcommand{\disc}{\mathrm{DISC}}
\newcommand{\discp}{\mathrm{DISC'}}
\newcommand{\Count}{\mathrm{COUNT}}
%\newcommand{\Cuatro}{\mathrm{COUNT}_{p,C_4}}
\newcommand{\codeg}{\mathrm{CODEG}}
\newcommand{\eig}{\mathrm{EIG}}

% Ahora para Chung-Graham y Wilson bipartito
\newcommand{\bidisc}{\mathrm{BI-DISC}}
\newcommand{\bicount}{\mathrm{BI-COUNT}}
\newcommand{\izcodeg}{\mathrm{IZQ-CODEG}}
\newcommand{\dercodeg}{\mathrm{DER-CODEG}}
\newcommand{\bieig}{\mathrm{BI-EIG}}

% Define codeg
\newcommand{\cod}{\mathrm{codeg}}
% Define Traza
\newcommand{\Tr}{\mathrm{Tr}}
% Define varianza
\newcommand{\var}{\mathrm{Var}}
%\documentclass[tikz, border = 10pt]{standalone}

\usepackage{pgfgantt}
%\def\proof{\paragraph{Demostraci\'on Segunda parte Teorema 3:\\}}
%\def\endproof{\hfill$\blacksquare$}

\newcommand{\prooftext}{}

\newenvironment{myproof}[1]
{
  \renewcommand{\prooftext}{#1}    
  
  \paragraph{\prooftext:}\par
}
{
  \hfill$\blacksquare$
  \renewcommand{\prooftext}{}
}


\usepackage{forloop}
\newcounter{loopcntr}
\newcommand{\rpt}[2][1]{%
  \forloop{loopcntr}{0}{\value{loopcntr}<#1}{#2}%
}
\newcommand{\on}[1][1]{
  \forloop{loopcntr}{0}{\value{loopcntr}<#1}{&\cellcolor{gray}}
}
\newcommand{\off}[1][1]{
  \forloop{loopcntr}{0}{\value{loopcntr}<#1}{&}
}

% Set page size and margins
% Replace `letterpaper' with `a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\providecommand{\abs}[1]{\lvert#1\rvert}
\providecommand{\norm}[1]{\lVert#1\rVert}


\let\varepsilon=\varepsilon

\usetikzlibrary{backgrounds}


%% Lo de abajo es ultra temporal
\makeatletter
\newcommand{\canvaswidth}{12}
\newcommand{\canvasheight}{6}

\newcommand{\gettikzxy}[3]{ % I got this from http://tex.stackexchange.com/questions/33703/extract-x-y-coordinate-of-an-arbitrary-point-in-tikz
    \tikz@scan@one@point\pgfutil@firstofone#1\relax
    \edef#2{\the\pgf@x}
    \edef#3{\the\pgf@y}
}
\makeatother

\tikzstyle{node}=[circle, draw, thin,fill=cyan!20, scale=0.8]

\begin{document}

\begin{titlepage}
    \begin{center}

        \includegraphics[width=0.33\textwidth]{Imágenes/logo_usach.png}
        \vspace{1.5cm}

        \textbf{\LARGE Grafos cuasi-aleatorios y lema de regularidad de Szemerédi}

        \vspace{0.5cm}

        \vspace{1.5cm}

        \textbf{\textbf{Estudiante:} \\Felipe Sánchez Erazo\\   \vspace{1.5cm} \textbf{Profesor Guía:}   \vspace{0.5cm} \\ Dr. Hi\d{ê}p Hàn}

        \vspace{1.cm}
            
\textbf{Tesis para optar al título de Ingeniero Matemático de la Universidad de Santiago de Chile}\\      
\vspace{0.5cm}

Departamento de Matemática y Ciencia de la computación \\
Universidad de Santiago de Chile \\
%11 de Julio de 2022 
\date{\today}
            
        \vspace{0.8cm}
    
            \vspace{0.5cm}

    \end{center}
\end{titlepage}

%\tableofcontents
\newpage
\vspace*{\fill}
\begin{center}
    \emph{\Large A mi abuelo, Sergio Sánchez.}
\end{center}
\vspace*{\fill}
\newpage


\section{Introducción}

%Para adentrarnos en esta historia, debemos de saber que las estructuras %pseudo-aleatorias son objetos determinísticos que tienen comportamientos, o %bien, lucen como un objeto aleatorio\hh{objetos aleatorios?}. A lo largo de la %historia, la formalización de este concepto se ha vuelto una herramienta muy %útil en diferentes áreas, tales como teoría de números, teoría de grafos, %combinatorial extremal, diseño de algoritmos, teoría de complejidad, entre %otras. Estas contribuciones son debidas, en general, a que si un objeto es %pseudo-aleatorio \hh{cuasi-aleatorio en vez de pseudo-aleatorio}, entonces %goza de muchas propiedades satisfacidas por su contraparte aleatoria.\\
%
%El trabajo fundamental sobre la pseudo-aleatoriedad se ha desarrollado en %grafos, probablemente por lo natural que muchas veces resulta modelar un %problema utilizándolos. Un \emph{grafo pseudo-aleatorio} $G = (V,E)$ es un %grafo que se comporta como un verdadero grafo aleatorio $G = (|V|,p)$ con la %misma densidad de aristas $p= |E| \Big/ \binom{|V|}{2}$. Si bien la sentencia %anterior nos entrega una idea inicial de este concepto, no logra ser demasiado %satisfactoria en el sentido de que no nos dice en qué aspecto  el %comportamiento del grafo pseaudo-aleatorio es similar al un grafo aleatorio, y %tampoco nos otorga ninguna medida cuantitativa de esta semejanza.\\
%
%A mediados de los 80, Andrew Thomason introdujo la noción de %"Grafos-revueltos", los cuales hacen posible medir en términos cuantitativos %la similitud entre la distribución de aristas de los grafos pseudo-aleatorios %y los aleatorios. Su investigación también nos otorgó ejemplos de grafos %pseudo-aleatorios con discusiones de sus propiedades.\\
%
%Sin duda alguna, una contribución clave fue la de Chung, Grahan y Wilson, %quienes en 1989 logran caracterizar la noción de pseudo-aleatoriedad de formas %superficialmente distintas, pero equivalentes entre sí. Este resultado abrió %muchos nuevos horizontes mostrando nuevas facetas de la pseudo-aleatoriedad.\\
%
%Con estos avances, otros objetos combinatorios fueron incluidos al estudio de %la pseudo-aleatoriedad, como lo son los subconjuntos de $\mathbb{Z}_n$, %hipergrafos, grupos finitos, permutaciones, y recientemente las palabras (i.e, %secuencias de letras de un alfabeto finito).\\
%
%El objeto de estudio principal en este trabajo son las palabras %pseudo-aleatoria, enfocándonos en una equivalencia en particular, análoga a %las planteadas en el teorema de Chung, Graham y Wilson. Para evidenciar el %objetivo, daremos un paseo por la teoría clásica en grafos de %pseudo-aleatoriedad y culminaremos planteando la formulación del problema en %cuestion.

\section{Preeliminares} \label{Preeliminares}

Este capítulo proporciona una introducción concisa de los conceptos y terminologías que se utilizarán en esta tesis. La sección \ref{Teoría de grafos} da un paseo por las nociones más básicas de la teoría de grafos, otorgando una línea de base para el desarrollo de las siguientes secciones. En la sección \ref{Teoría espectral} se repasan algunos conceptos y resultados clásicos del álgebra lineal para abordar las propiedades necesarias de la teoría espectral de grafos. Por último, la sección \ref{Grafos aleatorios} contextualiza y motiva el contenido de la sección \ref{cuasi-aleatoriedad}.

Para los efectos de este trabajo, se define $[n] := \lbrace 1,...,n\rbrace$, y $\mathcal{M}_{n\times m}(\mathbb{R})$ como el conjunto de matrices reales de $n$ filas y $m$ columnas. Denotamos $\mathbbm{1}_{X}$ a la función indicatriz del conjunto $X$, $\Bbbbone$ $\in\mathcal{M}_{n\times 1}(\mathbb{R})$ al vector de $1$-entradas, $J\in\mathcal{M}_{n\times n}$ a las matriz de $1$-entradas, $I_n\in \mathcal{M}_{n\times n}(\mathbb{R})$ a la matriz identidad, y $\boldsymbol{e}_i\in\mathcal{M}_{n\times 1}$ como el vector de la base canónica de $\mathbb{R}^{n}$ con entrada $1$ en la posición $i$. Además, $\norm{\cdot}$ y $\langle \cdot, \cdot\rangle$ representarán en todo momento la norma y producto interno usales respectivamente.

En muchos de los resultados de esta tesis, la \emph{desigualdad de Cauchy-Schwarz} (DCS) es un argumento fundamental en sus demostraciones. En particular, se emplearán dos variantes que se enunciarán a continuación. Primero recuerde que la DCS establece que todo $\boldsymbol{a},\boldsymbol{b}\in\mathbb{R}^{k}$ satisfacen

\begin{equation}
    \sum_{i=1}^{k}a_{i}^{2}\sum_{i=1}^{k}b_i^{2} \geq \left( \sum_{i=1}^{k}a_{i}b_{i}\right)^{2}.
\end{equation}

Entonces, si $\boldsymbol{b} = (1,...,1)$, se obtiene la primera variante:

\begin{equation} \label{CS_versión1}
    \sum_{i=1}^{k}a_{i}^{2} \geq \frac{1}{k}\left( \sum_{i=1}^{k} a_{i}\right)^{2}.
\end{equation}

Adicionalmente, considerando los reales $\alpha_1,...,\alpha_k > 0$ y $\beta_1,...\beta_k \geq 0$, defina $a_i = \sqrt{\alpha_i}$ y $b_i = \frac{\beta_i}{\sqrt{\alpha_i}}$ para conseguir la segunda variante:

\begin{equation} \label{Desigualdad_from_CS}
    \sum_{i=1}^{k} \frac{\beta_{i}^{2}}{\alpha_i} \geq \frac{\left( \sum_{i = 1}^{k} \beta_i\right)^{2}}{\sum_{i=1}^{k}\alpha_i}.
\end{equation}


\subsection{Teoría de grafos} \label{Teoría de grafos}

Si $S$ es un conjunto finito y $r$ es un entero positivo, se establece $\tbinom{S}{r}$ como el conjunto de todos los subconjuntos de $r$ elementos de $S$.

%%%% Definir grafo
Un \textbf{grafo} es un par $G = (V,E)$, donde $V$ representa el conjunto de \textbf{vértices} (o \emph{nodos}, o \emph{puntos}), y $E\subseteq \tbinom{V}{2}$ el conjunto de \textbf{aristas} (o \emph{líneas}). Dado un grafo $G$, se escribe $V(G)$ como su conjunto de vértices, $E(G)$ como su conjunto de aristas, y $e_G := |E(G)|$ como la cantidad de aristas presentes en el grafo.

%%%% Ejemplo grafo
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        % vértices
        \node[fill=black, circle, inner sep=1pt, minimum size=4pt, label={180:$\mathbf{2}$}] (2) at (-1.5, 0) {};
        \node[fill=black, circle, inner sep=1pt, minimum size=4pt, label={180:$\mathbf{1}$}] (1) at (-1.5, -1.5) {};
        \node[fill=black, circle, inner sep=1pt, minimum size=4pt, label={0:$\mathbf{3}$}] (3) at (0, 0) {};
        \node[fill=black, circle, inner sep=1pt, minimum size=4pt, label={0:$\mathbf{5}$}] (5) at (1.8, 0) {};
        \node[fill=black, circle, inner sep=1pt, minimum size=4pt, label={0:$\mathbf{4}$}] (4) at (1.8, -1.5) {};

        % aristas
        \draw[line width=1.2] (1) -- (2);
        \draw[line width=1.2] (2) -- (3);
        \draw[line width=1.2] (1) -- (3);
        \draw[line width=1.2] (5) -- (4);
    \end{tikzpicture}
    \caption{Ejemplo de un grafo con conjunto de vértices $V = \lbrace 1,2,3,4,5\rbrace$ y conjunto de aristas $E = \lbrace \lbrace1,2\rbrace, \lbrace2,3\rbrace, \lbrace1,3\rbrace, \lbrace4,5\rbrace\rbrace$.}
\end{figure}

Consideramos $G = (V,E)$ un grafo cualquiera. Si $u,v\in V$, se dirá que $u$ es \textbf{adyacencte} a $v$ (o viceversa) si y solamente si $\lbrace u,v\rbrace\in E$. Si $X,Y\subset$ son dos subconjuntos no necesariamente disjuntos, se define el conjunto de tuplas que forman una arista en $G$ de la siguiente manera:

\begin{equation} \label{eq e(X,Y)}
    e(X,Y) := \Big|\lbrace (x,y)\in X\times Y : \lbrace x,y\rbrace\in E\rbrace\Big|.
\end{equation}

Cuando $X\cap Y = \emptyset$, $e(X,Y)$ cuenta el número de aristas entre $X$ e $Y$, y cuando $X\cap Y\not=\emptyset$, $e(X,Y)$ realiza un doble conteo sobre las aristas que se encuentran en $X\cap Y$.

Se entenderá por \textbf{vecindad} de $u\in V$, $N(u)$, como el conjunto de todos los vértices adyacentes a $u$, es decir,

\begin{equation} \label{vecindad}
    N(u) := \lbrace v\in V(G) : \lbrace u,v\rbrace\in E(G)\rbrace.
\end{equation}

Se define el \textbf{grado} de un vértice $u\in V$ con respecto a algún subconjunto de vértices $Y\subseteq V$ de la siguiente manera:

\begin{equation*}
    \deg(u;Y) := \sum_{v\in Y} \mathbbm{1}_{E}(uv) = |N(u)\cap Y|.
\end{equation*}

En particular, cuando $Y=V$,

\begin{equation*}
    \deg(u) = \sum_{v\in V} \mathbbm{1}_{E}(uv) = |N(u)|.
\end{equation*}

Una propiedad elemental en teoría de grafos, es la relación que guarda la suma del grado de todos los vértices y la cantidad de aristas de un grafo.
%%%% Suma grados = 2e
\begin{prop}
    Dado un grafo $G = (V,E)$, entonces
    \begin{equation}
        \sum_{u\in V}\deg (u) = 2e_G.
    \end{equation}
\end{prop}

%%%% Demostración suma grados = 2e
\begin{proof}
    Cada arista $\lbrace u,v\rbrace\in E$ será contada dos veces en la suma, una contribución por $u$, y otra por $v$.
\end{proof}

En algunas ocasiones estaremos interesados en la cantidad de vecinos que comparten dos vértices del grafo $G = (V, E)$. Entonces, se define el \textbf{cogrado} de un par de vértices $u,v\in V$ no necesariamente diferentes mediante:

\begin{equation*}
    \cod(u,v) = \sum_{w\in V} \mathbbm{1}_{E}(\lbrace w,u\rbrace) \mathbbm{1}_{E}(\lbrace w,v\rbrace)=|N(u)\cap N(v)|.
\end{equation*}

Mostraremos que existe una relación intrínseca entre los conceptos de grado y cogrado, cual será de utilidad en la sección \ref{cuasi-aleatoriedad}.

%%%% Proposición: Relación grado-cogrado
\begin{prop} \label{Prop: grado-cogrado}
    Sea $G = (V,E)$ un grafo e $Y\subset V$ un subconjunto de vértices, entonces

    \[
        \sum_{u\in V} \deg(u;Y)^{2} = \sum_{v,v'\in Y\subseteq V} \cod(v,v').
    \]
\end{prop}

%%%% Demostración Proposición: Relación grado-cogrado
\begin{proof}
    Utilizando las respectivas definiciones de grado y cogrado, el resultado se obtiene de seguir el siguiente cálculo:

    \begin{align*}
        \sum_{u\in V} \deg(u;Y)^{2} &= \sum_{u\in V}\sum_{v,v'\in Y} \mathbbm{1}_{E}(uv) \mathbbm{1}_{E}(uv')\\
        &= \sum_{v,v'\in Y}\sum_{u\in V} \mathbbm{1}_{E}(vu) \mathbbm{1}_{E}(v'u)\\
        &= \sum_{v,v'\in Y}\cod(v,v').
    \end{align*}
\end{proof}

Observe que en particular, cuando $Y=V$, se satisface

\begin{equation} \label{grado-cogrado}
    \sum_{u\in V} \deg(u)^{2} = \sum_{u,v\in V}\cod(u,v).
\end{equation}

A continuación, se enuncian algunos grafos especiales que son contemplados en esta tesis. Diremos que un grafo $G = (V,E)$ es $\boldsymbol{k}$-\textbf{partito} si $V$ se puede dividir en $k$ subconjuntos disjuntos $V_1,V_2,...,V_k$ tales que $\lbrace u,v\rbrace\in E$ si y solamente si $u\in V_i$ y $v\in V_j$, con $i\not=j$. En particular, a un grafo 2-partito lo llamaremos \textbf{bipartito}.\medskip

%%%% Ejemplo grafo 3-partito
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        % Conjunto 1
        \foreach \x in {1,2,3}
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (A\x) at (\x,2) {};

        % Conjunto 2
        \foreach \y in {1,2,3,4}
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (B\y) at (\y-0.5,0) {};

        % Conjunto 3
        \foreach \z in {1,2,3}
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (C\z) at (\z+1, -2) {};

        % Conexiones
        \draw (A1) -- (B1);
        \draw (A2) -- (B2);
        \draw (A3) -- (B3);
        \draw (A2) -- (B4);
        
        \draw (B1) -- (C2);
        \draw (B2) -- (C3);
        \draw (B3) -- (C1);

        \draw (C1) -- (A2);
        \draw (C2) -- (A3);
        \draw (C3) -- (A1);
    \end{tikzpicture}
    \caption{Ejemplo de un grafo 3-partito.}
\end{figure}

Un \textbf{grafo completo} de $n$ vértices, denotado por $K_n$, es un grafo en el cual todos sus vértices son adyacentes entre ellos, es decir, todo par de vértices en el grafo posee una arista que los conecta. Similarmente, se denota por $K_{n,m}$ al \textbf{grafo bipartito completo} con $n$ y $m$ elementos en sus respectivos conjuntos de vérrtices. Observe que la cantidad de aristas en los grafos anteriores son exactamente $e_{K_n} = \tbinom{n}{2}$ y $e_{K_{n,m}} = n\cdot m$. Por otro lado, un grafo $\boldsymbol{d}$-\textbf{regular} es aquel que presenta todos sus vértices con grado $d$.

% Ejemplos grafos especiales
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        \begin{scope}[shift={(0,0)}] % NO PUEDO CORRERLO UN POQUITO A LA IZQ.
            % Grafo completo: K_6
        \K[1.6]{6}    
        \end{scope}

        \begin{scope}[shift={(-2cm,0)}]
            % Grafo completo bipartito: K_{3,5}
            % Definir los vértices de la primera bipartición (A)
            \foreach \i in {1,2,3}{
                \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (A\i) at (-1,\i -0.7) {};
            }
        

            % Definir los vértices de la segunda bipartición (B)
            \foreach \i in {1,...,5}{
                \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (B\i) at (1,\i - 0.5 - 1.3) {};
            }
        

            % Conectar cada nodo de A con cada nodo de B
            \foreach \i in {1,2,3}{
                \foreach \j in {1,...,5}{
                    \draw (A\i) -- (B\j);
                }
            }
        \end{scope}
        
        \begin{scope}[shift={(6cm,1.4cm)}]
            % Grafo 3-regular
            \foreach \x [count=\i] in {18,90,162,234,306}{
                \coordinate (i\i) at (\x:1cm) {};
                \coordinate (o\i) at (\x:1.8cm) {};
                \draw (\x:1cm) -- (\x:1.8cm);
            }

            \draw (o1) -- (o2) -- (o3) -- (o4)-- (o5)--(o1);
            \draw (i1) -- (i3) -- (i5) -- (i2)-- (i4)--(i1);

            \foreach \x [count=\i] in {18,90,162,234,306}{
                \node[fill=black, circle, inner sep=2pt, minimum size=4pt] at (\x:1cm){};
                \node[fill=black, circle, inner sep=2pt, minimum size=4pt] at (\x:1.8cm){};
            }  
        \end{scope}
    \end{tikzpicture}
    \caption{Ejemplo de los grafos especiales $K_{3,5}$, $K_6$ y 3-regular.}
\end{figure}

%%%% Definición caminata, caminata cerrada, camino y ciclos
Otro concepto relevante en este trabajo son las diferentes nociones de rutas que se pueden encontrar siguiendo una secuencia de determinadas aristas de un grafo. Suponga que el grafo $G$ posee $n\geq k$ vértices, entonces se definen los siguientes conceptos:

\begin{itemize}
    % Caminata
    \item Una \textbf{caminata} es una secuencia de vértices no necesariamente distintos $v_0,v_1,...,v_k$ tales que $\lbrace v_{i},v_{i+1}\rbrace\in E(G)$ para todo $i\in [k]$. Si $v_0 = v_k$, se dice que es una \textbf{caminata cerrada}. El \textbf{largo} de una caminata está determinado por la cantidad de aristas que ésta posea.
    % Camino
    \item Un \textbf{camino} es una caminata con todos los vértices $v_i$ distintos.
    % Ciclo
    \item Un \textbf{ciclo} es un camino con $k\geq 2$, en el cual además $\lbrace v_{0},v_{k}\rbrace\in E(G)$. En específico, $v_0, v_1,...,v_k,v_0$ es un ciclo. Se denota por $C_k$ al ciclo de largo $k$.
\end{itemize}
\newpage
% Ejemplos de caminata, camino y ciclo.
\begin{figure}[h]
    \centering
    % minipage de grafo
    \begin{minipage}{0.35\textwidth}
        \centering
        \begin{tikzpicture}
            % vértices
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={90:$\mathbf{2}$}] (2) at (-0.8,0.4) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={0:$\mathbf{3}$}] (3) at (0.8, 0.4) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{5}$}] (5) at (-0.8,-1.2) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={0:$\mathbf{6}$}] (6) at (0.8,-1.2) {};

            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={180:$\mathbf{1}$}] (1) at (-2,1.1) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={180:$\mathbf{4}$}] (4) at (-2,-1.9) {};

            % Aristas
            \draw[line width=1.2] (1) -- (2) -- (3) -- (6) -- (5) -- (4);
            \draw[line width=1.2] (5) -- (2);
        \end{tikzpicture}
    \end{minipage}
    % minipage ejemplos concretos
    \begin{minipage}{0.15\linewidth}
        \begin{align*}
            &125456 \equiv \text{caminata de largo 5.}\\
            &\\
            &1236 \equiv \text{camino de largo 3.}\\
            &\\
            &23652 \equiv \text{ciclo de largo 4.}
        \end{align*}
    \end{minipage}
    \caption{Ejemplo de una caminata, un camino y un ciclo.}
    \label{ej caminos}
\end{figure}

Por último, diremos que una \textbf{copia etiquetada} de un grafo $H$ en $G$ es una aplicación inyectiva $f: V(H)\to V(G)$ tal que $\lbrace f(u)f(v)\rbrace\in E(G)$ cada vez que $\lbrace u,v\rbrace\in E(H)$. Se denota por $\tbinom{G}{H}$ al conjunto de copias etiquetadas de $H$ en $G$.

\begin{figure}[h]
    \centering
    \begin{minipage}{0.49\linewidth}
        \centering
        % G_1
        \begin{tikzpicture}[baseline,scale=0.8]
            %\draw[step=0.5cm, gray, very thin] (-3,-3) grid (3,3);
            % Comienza ecuación
            \node at (-3,0) {$H=$};
            % Vértices 
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={180:$\mathbf{3}$}]  (3) at (-1.5,0) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={0:$\mathbf{4}$}]  (4) at (1.5,0) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={90:$\mathbf{1}$}]  (1) at (0,1.7) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{5}$}]  (5) at (0,-2) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={90:$\mathbf{2}$}]  (2) at (3,2) {};
            % Aristas
            \draw[line width=1.2] (3) -- (1) -- (4) -- (2);
            \draw[line width=1.2] (1) -- (5);
        \end{tikzpicture}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\linewidth}
        \centering
        % G_2
        \begin{tikzpicture}[baseline,scale=0.8]
            \node at (-3,0) {$G=$};
            % Vértices
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={180:$\mathbf{b}$}]  (b) at (-1.5,0) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={0:$\mathbf{d}$}]  (d) at (1.5,0) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={90:$\mathbf{a}$}]  (a) at (0,1.7) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{e}$}]  (e) at (0,-2) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{c}$}]  (c) at (0,0) {};
            % Aristas
            \draw[line width=1.2] (e) -- (b) -- (a) -- (d) -- (e);
            \draw[line width=1.2] (a) -- (c);
        \end{tikzpicture}
    \end{minipage}
    \caption{Ejemplo de una copia etiquetada de $H$ en $G$ mediante la función $f : V(H)\to V(G)$ definida por $f(1)=a$, $f(2)=e$, $f(3)=c$, $f(4)=b$ y $f(5)=d$.}
\end{figure}


\subsection{Álgebra lineal y teoría espectral de grafos} \label{Teoría espectral}

Considere una matriz cuadrada $A\in \mathcal{M}_{n\times n}$, se define la \textbf{traza} de $A$ como la suma de sus elementos de la diagonal principal. Esto es,

\begin{equation*}
    \Tr(A) = a_{11} + a_{22} + ... + a_{nn}.
\end{equation*}

Si $A,B\in\mathcal{M}_{n\times n}$, entonces la traza resulta invariante bajo el orden de multiplicación de dichas matrices. En efecto, 

\begin{equation*}
    \Tr(AB) = \sum_{i=1}^{n}\left( \sum_{j=1}^{n} a_{ij}b_{ji}\right) = \sum_{j=1}^{n}\left( \sum_{i=1}^{n} a_{ij}b_{ji}\right) = \Tr(BA).
\end{equation*}

Una manera muy útil de representar un grafo es mediante una matriz cuadrada binaria, en la que sus filas y columnas representarán todos los vértices del grafo. La matriz adopta el valor $1$ en las coordenadas en que sus respectivos vértices forman una arista, y $0$ en otro caso. Bajo esta representación se consigue una visión clara y eficiente entre las relaciónes de los vértices del grafo, y se gozan de las propiedades que ofrece el álgebra lineal.

%%%% Definición formal matriz de adyacencia
\begin{definicion}
    Dado un grafo $G$ sobre $n$ vértices, se define su \textbf{matriz de adyacencia} $A_{G}\in \mathcal{M}_{n\times n}(\mathbb{R})$ de la siguiente manera:

    \begin{equation*}
        a_{ij} =
        \begin{cases}
            1 & \mathrm{si}\  ij\in E(G)\\
            0 & \mathrm{en\ otro\ caso.}
        \end{cases}
    \end{equation*}

    Cuando el contexto sea claro, la matriz de adyacencia será representada simplemente por $A$.
\end{definicion}

%%%% Ejemplo de matriz de adyacencia de un grafo.
\renewcommand{\kbldelim}{(}
\renewcommand{\kbrdelim}{)}
\begin{figure}[h]
    \centering
    % Grafo
    \begin{minipage}{0.49\linewidth}
        \centering
        \begin{tikzpicture}
            \node at (-2.5,-1.1) {$G = $};
            % Vértices
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{3}$}] (3) at (-0.5, -0.7) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={290:$\mathbf{4}$}] (4) at (1.5, -0.7) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={90:$\mathbf{1}$}] (1) at (-1, 0.8) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={90:$\mathbf{2}$}] (2) at (2, 0.8) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{5}$}] (5) at (-1.5, -1.7) {};
            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, label={270:$\mathbf{6}$}] (6) at (1, -2.2) {};
            % Aristas
            \draw[line width=1.2] (1) -- (2) -- (4) -- (3) -- (1) -- (5) -- (3);
            \draw[line width=1.2] (1) -- (4) -- (6) -- (3);
        \end{tikzpicture}
    \end{minipage}
    \hfill
    % Matriz
    \begin{minipage}{0.49\linewidth}
        \centering
        \begin{equation*}
            A_G = \kbordermatrix{
                & \mathbf{1} & \mathbf{2} & \mathbf{3} & \mathbf{4} & \mathbf{5} & \mathbf{6} \\
                \mathbf{1} & 0 & 1 & 1 & 1 & 1 & 0 \\
                \mathbf{2} & 1 & 0 & 0 & 1 & 0 & 0 \\
                \mathbf{3} & 1 & 0 & 0 & 1 & 1 & 1 \\
                \mathbf{4} & 1 & 1 & 1 & 0 & 0 & 1 \\
                \mathbf{5} & 1 & 0 & 1 & 0 & 0 & 0 \\
                \mathbf{6} & 0 & 0 & 1 & 1 & 0 & 0
            }
        \end{equation*}
    \end{minipage}
    \caption{Ejemplo de representación mediante la matriz de adyacencia de un grafo.}
\end{figure}

Observe que la representación anterior resulta siempre en una matriz simétrica, es decir, $A_{G}^{T} = A_{G}$. Además, en todo grafo $G = ([n], E)$ con matriz de adyacencia $A$, se puede obtener un vector con los grados de cada vértice del grafo aplicando el operador $A$ a l vector de 1-entradas $\Bbbbone\in\mathcal{M}_{n\times n}$.

\begin{equation} \label{A1=Mdeg}
    A\Bbbbone = 
    \begin{pmatrix}
        \deg(1) \\
        \vdots \\
        \deg(n)
    \end{pmatrix}
\end{equation}.

Otro aspecto interesante de la matriz de adyacencia que será de utilidad en la sección \ref{Sec. LRS}, es que nos permite reescribir la ecuación \eqref{eq e(X,Y)} en función de ella. Para ver esto, consideramos la matriz de adyacencia $A$ del grafo $G = ([n], E)$, y los vértices $i,j\in [n]$. Luego, por la definición de $A$,

\begin{equation*}
    e(\lbrace i\rbrace, \lbrace j\rbrace) = \boldsymbol{e}_i^{T} A \boldsymbol{e}_{j} = 
    \begin{cases}
        1 & \text{si } i=j \\
        0 & \text{En otro caso.}
    \end{cases}
\end{equation*}

Entonces, por linealidad, se extiende el resultado anterior sobre cualquier conjunto $X,Y\subset [n]$.

\begin{equation} \label{e(X,Y)=espectral}
    e(X,Y) = \sum_{i\in X}\sum_{j\in Y} \boldsymbol{e}_{i}^{T} A \boldsymbol{e}_{j} = \boldsymbol{v}_{X}^{T} A \boldsymbol{v}_{Y}.
\end{equation}

En la ecuación anterior, y desde ahora en adelante, el vector $\boldsymbol{v}_{X} = \sum_{i\in X}\boldsymbol{e}_{i}$ representa el vector indicador del subconjunto de vértices $X\subset [n]$ de algún grafo $G=([n], E)$.

Es importante destacar que la matriz de adyacencia no solo describe las conexiones entre cada par de vértices en un grafo, sino que también revela la cantidad exacta de caminatas que existen entre dos vértices de un largo determinado. En específico, la posición $ij$ de la $t$-ésima potencia de la matriz de adyacencia de un grafo guarda la cantidad de caminatas de largo $t$ entre los vértices $i$ y $j$.

%%%% Lema: Potencia matriz de adyacencia
\begin{prop} \label{potencia_matriz_adyacencia = caminatas}
    Sea $A$ la matriz de adyacencia de grafo $G = ([n], E)$. La $(i,j)$-ésima entrada $a_{ij}^{(t)}$ de $A^{t}$, cuenta la cantidad de caminatas de largo $t$ que comienzan y terminan en los vértices $i$ y $j$ respectivamente.
\end{prop}

%%%% Demostración Lema : Potencia matriz de adyacencia
\begin{proof}
    Cuando $t=1$, existe una caminata de largo $1$ que conecta los vértices $i$ y $j$ si y solamente si $a_{ij}^{(1)} = 1$. Ahora, asuma que el lema se cumple para algún $t > 1$ fijo. Note que cualquier caminata de largo $t+1$ entre $i$ y $j$ contiene una caminata de largo $t$ desde $i$ hasta un vecino de $j$, digamos $k$. Entonces si $k\in N(j)$, por la asunción del lema, el número de caminatas de largo $t$ entre $i$ y $k$ es $a_{ik}^{(t)}$. Por lo tanto, el número total de caminatas de largo $t+1$ desde $i$ hasta $t$ es exactamente

    \begin{equation*}
        \displaystyle\sum_{k\in V} a_{ik}^{(t)}\mathbbm{1}_{N(j)}(k) = \displaystyle\sum_{\ell=1}^{n}a_{i\ell}^{(t)}a_{\ell j} = a_{ij}^{(t+1)}.
    \end{equation*}
\end{proof}

Como consecuencia de la proposición anterior, en cualquier grafo $G = ([n], E)$ con matriz de adyacencia $A$, se puede representar la cantidad total de caminatas cerradas de largo $t$ en el grafo por medio de la traza, $\Tr(A^{t}) = \sum_{i=1}^{n}a_{ii}^{(t)}$. Con esto, note que $\Tr(A^{2}) = 2e_G$.\medskip

Por otro lado, para introducir algunos aspectos de la teoría espectral de grafos, recuerde que $\boldsymbol{v}\in \mathbb{R}^{n}$ es un vector propio de alguna matriz $A\in \mathcal{M}_{n\times n}(\mathbb{R})$ con valor propio $\lambda\in \mathbb{R}$ si $A\boldsymbol{v}=\lambda \boldsymbol{v}$. Esto significa que $\lambda$ es un valor propio si y solo si $\lambda I_{n} - A$ es una matriz singular. Así, los valores propios vienen dados por las raíces del polinomio característico $\det(xI_{n} - A)$. En este trabajo, cuando se haga referencia a los valores y vectores propios de un grafo $G$, siempre será con respecto a su matriz de adyacencia $A$.

Por ejemplo. si $G$ es un grafo $d$-regular, entonces con la igualdad \eqref{A1=Mdeg} se puede deducir que $d$ es el valor propio asociado al vector propio normalizado de $1$-entradas de la matriz de adyacencia $A_G$.

%%%% Proposición: VP relaes y vectores ortogonales.
\begin{prop}
    Sea $A\in\mathcal{M}_{n\times n}(\mathbb{R})$ una matriz real simétrica, entonces todos sus valores propios son reales. Además, si dos vectores propios están asociados a distintos valores propios, entonces éstos son ortogonales. Más aún, el conjunto de todos los vectores propios definen  una base ortonormal de $\mathbb{R}^{n}$.
\end{prop}

%%%% Demostración
\begin{proof}
    Se comienza probando que los valores propios de $A$ son reales. Sea $\lambda$ un valor propio de $A$ y $\boldsymbol{x}\not=0$ su correspondiente vector propio, satisfaciendo $A\boldsymbol{x} = \lambda \boldsymbol{x}$. Tomando su conjugado, se obtiene paralelamente que

    \begin{equation*}
        \begin{aligned}
            A\boldsymbol{x} &= \lambda \boldsymbol{x} & \hspace{2cm}  A\overline{\boldsymbol{\boldsymbol{x}}} &= \overline{\lambda}\overline{\boldsymbol{x}}\\
            &\Downarrow & \hspace{2cm} & \Downarrow\\
            \overline{\boldsymbol{x}}^{T}A\boldsymbol{x} &= \lambda\norm{\boldsymbol{x}}^{2} & \hspace{2cm} \boldsymbol{x}^{T}A\overline{\boldsymbol{x}} &= \overline{\lambda}\norm{\boldsymbol{x}}^{2}. 
        \end{aligned}
    \end{equation*}

    Además, como $A$ es simétrica,

    \begin{equation*}
        \overline{\boldsymbol{x}}^{T}A\boldsymbol{x} = (A\boldsymbol{x})^{T}\overline{\boldsymbol{x}} = \boldsymbol{x}^{T}A\overline{\boldsymbol{x}}.
    \end{equation*}

    Así, ya que $\boldsymbol{x}\not=0$, debe ocurrir que $\lambda = \overline{\lambda}$, permitiendo concluir que todos los valores propios de $A$ son números reales.

    Por otro lado, considere $\boldsymbol{u},\boldsymbol{v}\in \mathbb{R}^{n}$ vectores propios distintos de $A$ asociados a los valores propios $\lambda,\mu\in\mathbb{R}\setminus\lbrace 0\rbrace$ respectivamente. Calculamos como sigue,

    \begin{align*}
        \lambda \langle \boldsymbol{u},\boldsymbol{v}\rangle = \langle \lambda \boldsymbol{u},\boldsymbol{v}\rangle
        = \langle A\boldsymbol{u},\boldsymbol{v} \rangle
        = \langle \boldsymbol{u},A^{T} \boldsymbol{v} \rangle
        = \langle \boldsymbol{u},A\boldsymbol{v} \rangle
        = \langle \boldsymbol{u},\mu \boldsymbol{v} \rangle
        = \mu \langle \boldsymbol{u},\boldsymbol{v}\rangle.
    \end{align*}

    De esta manera, $\lambda\langle \boldsymbol{u},\boldsymbol{v}\rangle = \mu\langle \boldsymbol{u},\boldsymbol{v}\rangle$ si y solamente si $\langle \boldsymbol{u},\boldsymbol{v}\rangle = 0$. Ya probada la ortogonalidad de los vectores propios de $A$, defina $\mathcal{B} = \lbrace \boldsymbol{u}_1, \boldsymbol{u}_2,...,\boldsymbol{u}_n\rbrace$ como el conjunto de vectores propios normalizados de $A$ para probar que $\mathcal{B}$ constituye una base ortonormal de $\mathbb{R}^{n}$. Para esto, sean $c_1,...,c_n\in\mathbb{R}$ tales que

    \begin{equation*}
        c_1 \boldsymbol{u}_1 + c_2 \boldsymbol{u}_2 + ... + c_n \boldsymbol{u}_n = 0.
    \end{equation*}
    
    Entonces, para algún $i\in[n]$, multiplicando por la izquierda la igualdad anterior por $\boldsymbol{u}_{i}^{T}$,
    
    \begin{equation*}
        \boldsymbol{u}_{i}^{T} (c_1 \boldsymbol{u}_1 + ... + c_n \boldsymbol{u}_n) = c_i \boldsymbol{u}_{i}^{T}\boldsymbol{u}_i = c_i = 0.
    \end{equation*}

    Así, queda demostrado que $\mathcal{B}$ es una base ortonormal de $\mathbb{R}^{n}$.
\end{proof}

% Teorema espectral
A continuación, se enunciará sin demostración uno de los teoremas más importantes del álgebra lineal, y se estudiarán algunas de sus consecuencias bajo el contexto de la teoría de grafos.

%%%% Teorema espectral
\begin{teorema} (Teorema espectral)
    Sea $A\in\mathcal{M}_{n\times n}(\mathbb{R})$ una matriz real simétrica. Entonces existen matrices $P$ ortogonal y $D$ diagonal tales que

    \begin{equation} \label{Descomposición espectral}
        A = PDP^{T} = \sum_{i=1}^{n}\lambda_{i}\boldsymbol{v}_{i}\boldsymbol{v}_{i}^{T}.
    \end{equation}

    En donde la matriz diagonal $D$ está compuesta por los valores propios $\lambda_i \in\mathbb{R}$ de $A$, y las columnas de $P$ son los vectores propios normalizados $\boldsymbol{v}_{i}\in\mathbb{R}^{n}$ de $A$.
\end{teorema}

Con el teorema anterior es posible representar la matriz de adyacencia de un grafo por medio de dos matrices que dependen únicamente de sus valores y vectores propios para obtener propiedades desde una perspectiva espectral.

En primera instancia, observe que la descomposición espectral \eqref{Descomposición espectral} permite trabajar eficientemente con las potencias de una matriz real simétrica, puesto a que el problema se reduce a calcular la respectiva potencia de la matriz diagonal de valores propios. Para visualizar este hecho, primero observe como se comporta el cuadrado de una matriz simétrica $A\in\mathcal{M}_{n\times n}(\mathbb{R})$:

\begin{align*}
    A^{2} &= (PDP^{T})(PDP^{T})\\
    &= PD(P^{T}P)DP^{T}\\
    &= PD^{2}P^{T}.
\end{align*}

Luego, de manera inductiva se obtiene que $A^{k} = P D^{k}P^{T}$. Esta propiedad resulta altamente útil de cara al cálculo de caminatas de largo $k$ entre dos vértices de un grafo. Más aún, la Proposición \ref{Tr = autvalor} y el Corolario \ref{Tr_Ak} mostrarán que el número de caminatas cerradas en un grafo queda totalmente determinado por los valores propios del mismo.

%%%% Proposición: traza = suma valores propios
\begin{prop} \label{Tr = autvalor}
    La traza de toda matriz simétrica $A\in \mathcal{M}_{n\times n}(\mathbb{R})$ es igual a la suma de sus autovalores.
\end{prop}

%%%% Demostración : traza = suma valores propios
\begin{proof}
    Sea $A\in \mathcal{M}_{n\times n}(\mathbb{R})$ una matriz simétrica, $\lambda_1,...,\lambda_n$ sus valores propios, y $\boldsymbol{v}_1,...,\boldsymbol{v}_n$ sus vectores propios. Se escribe la traza estratégicamente de la siguiente manera:

    \[ 
        \Tr (A) = \sum_{i = 1}^{n} \boldsymbol{e}_{i}^{T} A \boldsymbol{e}_{i}.
    \]

    Con esto, se concluye utilizando la descomposición espectral.

    \begin{align*}
        \Tr(A) &= \sum_{i = 1}^{n}\boldsymbol{e}_{i}^{T} \left( \sum_{j = 1}^{n} \lambda_{j}\boldsymbol{v}_{j}\boldsymbol{v}_{j}^{T} \right) \boldsymbol{e}_{i}\\
        &= \sum_{i = 1}^{n}\sum_{j = 1}^{n} \lambda_{j} \boldsymbol{e}_{i}^{T} \boldsymbol{v}_{j} \boldsymbol{v}_{j}^{T} \boldsymbol{e}_{i}\\
        &= \sum_{i = 1}^{n}\sum_{j = 1}^{n} \lambda_{j} \langle \boldsymbol{e}_{i}, \boldsymbol{v}_{j}\rangle \langle \boldsymbol{v}_{j}, \boldsymbol{e}_{i}\rangle\\
        &= \sum_{j = 1}^{n} \lambda_{j} \norm{\boldsymbol{v}_j}^{2}\\
        &= \sum_{j = 1}^{n} \lambda_{j}.
    \end{align*}
\end{proof}

El siguiente corolario extiende el resultado anterior sobre cualquier potencia de una matriz real simétrica.

%%%% Corolario: Traza potencia k
\begin{corolario} \label{Tr_Ak}
    Sea $A \in\mathcal{M}_{n\times n}(\mathbb{R})$ una matriz simétrica y $\lambda_1 ,...,\lambda_n$ sus autovalores, entonces se cumple $\Tr(A^{k}) = \sum_{i = 1}^{n}\lambda_{i}^{k}$.
\end{corolario}

%%%% Demostración corolario traza potencia k
\begin{proof}
    El resultado sigue de utilizar que la traza de la multiplicación de dos matrices es invariante bajo orden del producto,

    \begin{align*}
        \Tr(A^{k}) = \Tr([PDP^{T}]^{k})
        = \Tr(P[D^{k}P^{T}])
        = \Tr([D^{k}P^{T}]P)
        = \Tr(D^{k})
        = \sum_{i = 1}^{n}\lambda_{i}^{k}.
    \end{align*}
\end{proof}

De esta manera, la cantidad de caminatas cerradas de largo $k$ entre dos vértices de un grafo se simplifica a solo calcular la suma de la $k$-ésima potencia de todos sus valores propios. Más adelante, en la sección \ref{cuasi-aleatoriedad}, esta propiedad será de utilidad debido a que entrega una buena aproximación de la cantidad de copias etiquetadas de ciclos de largo $k$ que existen en un grafo $G = ([n], E)$. En particular, si $A$ es la matriz de adyacencia de $G$ y $\lambda_1,...,\lambda_n$ sus valores propios,

\begin{equation} \label{Aprox_Cop_C_k}
    \left| \tbinom{G}{C_k}\right| = \Tr(A^{k}) + o(n^{k}) = \sum_{i=1}^{n}\lambda_{i}^{k} + o(n^{k})
\end{equation}

Por otro lado, es posible caracterizar cada valor propio de una matriz real simétrica por medio del teorema de \emph{Courant-Fischer}. Se enuncia sin demostración.

%%%% Teorema: Courant-Fischer
\begin{teorema} \label{Teo Courant-Fischer} (Teorema de Courant-Fischer)
    Sea $A\in \mathcal{M}_{n\times n}(\mathbb{R})$ una matriz real simétrica, cuyos valores propios son $\lambda_1 \geq \lambda_2 \geq ...\geq \lambda_n$, y $\lbrace \boldsymbol{v}_1, \boldsymbol{v}_2,..., \boldsymbol{v}_n \rbrace$ sus vectores propios. Entonces,

    \begin{itemize}
        \item[(i)] \[
                \lambda_k = \inf_{\substack{\boldsymbol{x}\perp \lbrace \boldsymbol{v}_1,...,\boldsymbol{v}_{k-1}\rbrace \\ \boldsymbol{v}\not= 0}} \frac{\langle \boldsymbol{x}, A\boldsymbol{x}\rangle}{\langle \boldsymbol{x},\boldsymbol{x}\rangle}.
                    \]
        \item[(ii)] \[
                \lambda_k = \sup_{\substack{\boldsymbol{x}\perp \lbrace \boldsymbol{v}_{k+1},...,\boldsymbol{v}_n\rbrace \\ \boldsymbol{x}\not= 0}} \frac{\langle \boldsymbol{x}, A\boldsymbol{x}\rangle}{\langle \boldsymbol{x},\boldsymbol{x}\rangle}.
                    \]
    \end{itemize}
\end{teorema}

Usualmente, el primer autovalor de todo grafo juega un papel protagónico. Para los fines de estas tesis, es necesario establecer una cota inferior del primer autovalor.

%%%% Proposición : Primer autovalor >= promedio grados
\begin{prop}\label{cota_primer_autovalor}
    El primer autovalor de la matriz de adyacencia de un grafo es al menos el promedio de los grados. En particular, cuando el grafo es $d$-regular, el primer autovalor coincide con $d$.
\end{prop}

%%%% Demostración : Primer autovalor >= promedio grados
\begin{proof}
    Considerando $A$ como la matriz de adyacencia del grafo $G = ([n], E)$, se desarrolla en función del Teorema \ref{Teo Courant-Fischer}:

    \begin{equation*}
        \lambda_1 = \sup_{\substack{\boldsymbol{x}\in \mathbb{R}^{n} \\ \boldsymbol{x}\not= 0}} \frac{\langle \boldsymbol{x}, A\boldsymbol{x}\rangle}{\langle \boldsymbol{x}, \boldsymbol{x}\rangle}
        \geq \frac{\langle \Bbbbone, A\Bbbbone \rangle}{\langle \Bbbbone, \Bbbbone \rangle}
        = \frac{2e_G}{n}\\
        = \dfrac{\sum_{v\in V(G)} \deg(v)}{n}.
    \end{equation*}

    Adicionalmente, con apoyo de la igualdad \eqref{A1=Mdeg}, usando la cota anterior se concluye que si $G$ es $d$-regular, entonces $\lambda_1 = d$.
\end{proof}

\subsection{Grafos aleatorios} \label{Grafos aleatorios}

El objetivo de la presente sección es proporcionar un breve contexto teórico para abordar más adelante la noción y propiedades de los grafos \emph{cuasi-aleatorios}. Para ello, se asumirán los conceptos básicos asociados a la teoría de la probabilidad.

De manera intuitiva, se podría pensar en primera instancia en un \emph{grafo aleatorio} de $n$ vértices como el resultado de selecciar aleatoriamente un subconjunto de aristas de $K_n$. La manera de seleccionar dicho subconjunto de aristas determina el tipo de modelo de grafo aleatorio. El modelo más popular, propuesto por Edgar Gilbert en 1959 \fs{referencia}, contempla una estructura que se desarrolla algoritmicamente agregando una arista a la vez, en la que comenzando con el grafo vacío $\overline{K_n}$, se decide iterativamente si existe una arista entre cada par de vértices del grafo con probabilidad $p$.

Cada repetición del proceso anterior genera un nuevo grafo de $n$ vértices. El conjunto de todos esos grafos constituye un espacio de probabilidad, al que denotaremos por $G(n,p)$ y llamaremos modelo binomial. Se define formalmente.

\begin{definicion} (Modelo binomial)
    Sea $G^{n}$ el conjunto de todos los grafos sobre $n$ vértices, y $p\in (0,1)$. Se define $G(n,p)$ como el espacio de probabilidad $\left( G^{n}, \mathcal{P}(G^{n}), \mathbb{P}\right)$, con

    \begin{equation*}
        \mathbb{P}\left(G(n,p) = G\right) = p^{e_G}(1-p)^{\tbinom{n}{2} - e_G}\ \ ,\ \ \forall G\in G(n,p).
    \end{equation*}
\end{definicion}

Se adopta el modelo binomial como referencia para trabajar más adelante con el concepto de un grafo \emph{cuasi-aleatorio}. 

%%%% Proposición: Distribución de aristas grafo aleatorio binomial
\begin{prop}
    Sea $p\in (0,1)$, $G\in G(n,p)$ y $X,Y\subset V(G)$. Entonces la cantidad de aristas esperadas entre $X$ e $Y$ es $p|X||Y|$.
\end{prop}
%%%% Demostración
\begin{proof}
    Enumere las aristas del grafo bipartito completo $K_{|X|,|Y|}$ desde $1$ hasta $|X||Y|$, y para cada arista $1\leq i\leq |X||Y|$, considere $Z_i$ como la siguiente variable aleatoria indicadora:

    \begin{equation*}
        Z_i =
        \begin{cases}
            1 & \mathrm{si}\ i\in E(G)\\
            0 & \mathrm{en\ otro\ caso.}
        \end{cases}.
    \end{equation*}\medskip

    Así, la variable aleatoria $Z = \sum_{i=1}^{|X||Y|} Z_i$ cuenta el número total de aristas que existen entre $X$ e $Y$. Finalmente,

    \begin{align*}
        \mathbb{E}[Z] = \sum_{i=1}^{|X||Y|} \mathbb{E} [Z_i]
        = \sum_{i=1}^{|X||Y|} \mathbb{P} (Z_i = 1)
        = \sum_{i=1}^{|X||Y|} p
        = p|X||Y|.
    \end{align*}
\end{proof}

Hemos probado que en cada grafo... \fs{completar que probamos en esperanza y ahora lo haremos con alta probabilidad...}



% DEFINICIONES PENDIENTES!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
%\begin{enumerate}

%    
%    \item
%    \begin{definicion}
%        Diremos que $\mathcal{P} = \lbrace X_1,X_2,...,X_k\rbrace$ es una %\textbf{partición} del conjunto $X$ si:
%        \begin{enumerate}
%            \item $\bigcup_{i=1}^{k} X_i = X$.
%            \item $X_i \cap X_j = \emptyset$ para todo $i,j\in[k]$.
%        \end{enumerate}
%        Cuando $|X_1|\leq|X_2|\leq ...\leq |X_k| = |X_1| + 1$, llamaremos a %$\mathcal{P}$ como una \textbf{equipartición}. En particular, cada %parte posee $\lceil |X|/k \rceil$ o $\lfloor |X|/k\rfloor$ elementos.
%    \end{definicion}
%    \item $I_n \in \mathcal{M}_{n\times n}(\mathbb{R})$ denota la matriz %identidad.
%\end{enumerate}






    
    %Además, se define la \textbf{densidad de aristas} entre $X$ e $Y$ %mediante\medskip
%
    %\begin{equation}
    %    d(X,Y) := \frac{e(X,Y)}{|X||Y|}.
    %\end{equation} 












%\newpage
%Como ya mencionamos en la introducción, un grafo pseudo aleatorio es un objeto determinístico que luce como un grafo aleatorio. Pongámonos en la situación de que queremos generar un grafo aleatorio sobre $n$ vértices; quizás la manera más sencilla es el proceso de considerar todos los posibles pares $(u,v)$ de vértices en $G$, y decidir independientemente con probabilidad $1/2$ si $(u,v)$ es una arista o no. \\
%
%Formalmente hablando, un \emph{grafo aleatorio} $G(n,p)$ es el espacio de probabilidad de todos los grafos etiquetados sobre $n$ vértices $[n]:=\lbrace 1,...,n\rbrace$, donde para cada par $1\leq i < j\leq n$, $(i,j)$ es una arista de $G(n,p)$ con probabilidad $p=p(n)$ independiente de cualquier otra arista. En otras palabras, la probabilidad de un grafo $G=([n],E)$ de estar en $G(n,p)$ es $Pr[G]= p^{|E(G)|}(1-p)^{\tbinom{n}{2}-|E(G)|}$.\\
%
%Un resultado de esta área que nos ayudará más adelante con la pseudo-aleatoriedad es el siguiente:\\
%
%\begin{flushleft}
%    \textbf{Teorema 1.-} Sea $p=p(n)\leq 0.99$, entonces casi seguramente $G\in G(n,p)$ es tal que si:
%        \begin{enumerate}
%            \item[i)] $U\subset V(G)$ es cualquier subconjunto de vértices de $G$, entonces
%            $$\left| e(U) - p\binom{|U|}{2} \right| = O(u^{3/2}p^{1/2}\log^{1/2}(2n/u)),$$
%            donde $e(U)$ es el número de pares $(i,j)\in U\times U$ tales que $(i,j)\in E(G)$.
%            \item[ii)] $U,W\subset V(G)$ subconjuntos disjuntos de vértices de $G$ que satisfacen $|U|\leq |W|$, entonces:
%            $$\left| e(U,W)-p|U||W|\right| = O(u^{1/2}wp^{1/2}\log^{1/2}(2n/w)),$$
%            donde $e(U,W)$ es el número de pares $(i,j)\in U\times W$ tales que $(i,j)\in E(G)$.
%        \end{enumerate}
%\end{flushleft}
%Sin entrar en detalles con respecto a los términos de errores, el espíritu de este teorema es que dado un grafo $G\in G(n,p)$, entonces la densidad de aristas en cualquier subconjunto de vértices de $G$ es razonablemente similar a la de $G$. Más aún, note que las cantidades $e(U)$ y $e(U,W)$ son binomialmente distribuidas como variables aleatorias con parámetros $\left(\binom{|U|}{2},p\right)$, y $\left(|U||W|,p\right)$ respectivamente.
%
%\section{Definiciones y conceptos basicos}
%
%\hh{Lo siguientes solo serán definiciones y resultados sueltos para en un futuro cercano ser reordenado en el documento}.
%
%
%\hh{La siguiente definición y teorema hacen recen referencia a la desigualdad de Jensen, cual será utilizada más adelante en la sección de regularidad}
%
%%%%% Definición función convexa
%\begin{definicion}
%    Sea $f:\mathbb{R}\to \mathbb{R}$ una función. Diremos que $f$ es \textbf{convexa} si para todo $x,y\in\mathbb{R}$ y $t\in [0,1]$ se verifica que
%    \begin{equation*}
%        f(tx +(t-1)y) \leq tf(x) + (1-t)f(y).
%    \end{equation*}
%\end{definicion}
%
%%%%% Teorema: Desigualdad de Jensen
%\begin{teorema} \label{Teo_Desigualdad_Jensen} (Desigualdad de Jensen) 
%    Sea $f:\mathbb{R}\to \mathbb{R}$ una función convexa. Para todo $n\in \mathbb{N}$ y $t_i\in \mathbb{R}$, con $i\in [n]$, tales que $t_i \geq 0$ y $\sum_{i = 1}^{n}t_i = 1$, se satisface
%    \begin{equation} \label{Formula_Desigualdad_Jensen}
%        f\left( \sum_{i = 1}^{n} t_i x_i\right) \leq \sum_{i = 1}^{n} t_i f(x_i),\ \ \forall x_i\in \mathbb{R}.
%    \end{equation}
%\end{teorema}
%
%%%%% Demostración: Desigualdad de Jensen
%\begin{proof}
%    Razonaremos por inducción sobre $n$. Cuando $n = 1$, entonces $t_1 = 1$ y el resultado ocurre trivialmente. También es verdad cuando $n = 2$ por la convexidad de $f$.
%    Asumiendo que \eqref{Formula_Desigualdad_Jensen} se cumple para algún $n \geq 2$ fijo y que $t_{n+1} \not=1$ (en caso contrario, los otros $t_i = 0$ cuando $i\in [n]$, y por consecuencia se satisface \eqref{Formula_Desigualdad_Jensen}), el resultado se consigue de utilizar la convexidad de $f$ y la hipótesis inductiva,
%    \begin{align*}
%        f\left( \sum_{i = 1}^{n+1} t_ix_i\right) &= f\left( (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}x_i + t_{n+1}x_{n+1}\right)\\
%        &\leq (1-t_{n+1})f\left( \sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}\right) + t_{n+1}f(x_{n+1})\\
%        &\leq (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1-t_{n+1}}f(x_i) + t_{n+1}f(x_{n+1})\\
%        &= \sum_{i = 1}^{n+1}t_if(x_i).
%    \end{align*}
%\end{proof}
%
%Sabemos que para una variable aleatoria $X$ con función de probabilidad $\mathbb{P}(X = x_i)$  con $i\in [n]$, su esperanza matemática está definida por
%\[ \mathbb{E}[X] = \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i.\]
%Ahora, como $\sum_{i = 1}^{n}\mathbb{P}(X = x_i) =1$ y $\mathbb{P}(X = x_i) \geq 0$, podemos usar la desigualdad de Jensen eligiendo la función convexa $f(x) = x^{2}$ para obtener
%\begin{equation} \label{Jensen_implicación}
%    f\left( \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i\right) \leq \sum_{i = 1}^{n} \mathbb{P}(X = x_i)f(x_i) \Rightarrow \mathbb{E}[X]^{2} \leq \mathbb{E}[X^{2}].
%\end{equation}
%\hh{Pregunta: Debería eliminar la implicancia y dejar solo el resultado? R: agregar un "Es decir,". De todas maneras debo adaptar la demostración de regularidad para no utilizar notación se probabilidad.}
%    \begin{align*}
%        f\left( \sum_{i = 1}^{n+1} t_ix_i\right) &= f\left( (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}x_i + t_{n+1}x_{n+1}\right)\\
%        &\leq (1-t_{n+1})f\left( \sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}\right) + t_{n+1}f(x_{n+1})\\
%        &\leq (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1-t_{n+1}}f(x_i) + t_{n+1}f(x_{n+1})\\
%        &= \sum_{i = 1}^{n+1}t_if(x_i).
%    \end{align*}
%\end{proof}
%
%Sabemos que para una variable aleatoria $X$ con función de probabilidad $\mathbb{P}(X = x_i)$  con $i\in [n]$, su esperanza matemática está definida por
%\[ \mathbb{E}[X] = \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i.\]
%Ahora, como $\sum_{i = 1}^{n}\mathbb{P}(X = x_i) =1$ y $\mathbb{P}(X = x_i) \geq 0$, podemos usar la desigualdad de Jensen eligiendo la función convexa $f(x) = x^{2}$ para obtener
%\begin{equation} \label{Jensen_implicación}
%    f\left( \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i\right) \leq \sum_{i = 1}^{n} \mathbb{P}(X = x_i)f(x_i) \Rightarrow \mathbb{E}[X]^{2} \leq \mathbb{E}[X^{2}].
%\end{equation}
%\hh{Pregunta: Debería eliminar la implicancia y dejar solo el resultado? R: agregar un "Es decir,". De todas maneras debo adaptar la demostración de regularidad para no utilizar notación se probabilidad.}
%    \begin{align*}
%        f\left( \sum_{i = 1}^{n+1} t_ix_i\right) &= f\left( (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}x_i + t_{n+1}x_{n+1}\right)\\
%        &\leq (1-t_{n+1})f\left( \sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}\right) + t_{n+1}f(x_{n+1})\\
%        &\leq (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1-t_{n+1}}f(x_i) + t_{n+1}f(x_{n+1})\\
%        &= \sum_{i = 1}^{n+1}t_if(x_i).
%    \end{align*}
%\end{proof}
%
%Sabemos que para una variable aleatoria $X$ con función de probabilidad $\mathbb{P}(X = x_i)$  con $i\in [n]$, su esperanza matemática está definida por
%\[ \mathbb{E}[X] = \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i.\]
%Ahora, como $\sum_{i = 1}^{n}\mathbb{P}(X = x_i) =1$ y $\mathbb{P}(X = x_i) \geq 0$, podemos usar la desigualdad de Jensen eligiendo la función convexa $f(x) = x^{2}$ para obtener
%\begin{equation} \label{Jensen_implicación}
%    f\left( \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i\right) \leq \sum_{i = 1}^{n} \mathbb{P}(X = x_i)f(x_i) \Rightarrow \mathbb{E}[X]^{2} \leq \mathbb{E}[X^{2}].
%\end{equation}
%\hh{Pregunta: Debería eliminar la implicancia y dejar solo el resultado? R: agregar un "Es decir,". De todas maneras debo adaptar la demostración de regularidad para no utilizar notación se probabilidad.}
%    \begin{align*}
%        f\left( \sum_{i = 1}^{n+1} t_ix_i\right) &= f\left( (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}x_i + t_{n+1}x_{n+1}\right)\\
%        &\leq (1-t_{n+1})f\left( \sum_{i = 1}^{n} \frac{t_i}{1 - t_{n+1}}\right) + t_{n+1}f(x_{n+1})\\
%        &\leq (1 - t_{n+1})\sum_{i = 1}^{n} \frac{t_i}{1-t_{n+1}}f(x_i) + t_{n+1}f(x_{n+1})\\
%        &= \sum_{i = 1}^{n+1}t_if(x_i).
%    \end{align*}
%\end{proof}
%
%Sabemos que para una variable aleatoria $X$ con función de probabilidad $\mathbb{P}(X = x_i)$  con $i\in [n]$, su esperanza matemática está definida por
%\[ \mathbb{E}[X] = \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i.\]
%Ahora, como $\sum_{i = 1}^{n}\mathbb{P}(X = x_i) =1$ y $\mathbb{P}(X = x_i) \geq 0$, podemos usar la desigualdad de Jensen eligiendo la función convexa $f(x) = x^{2}$ para obtener
%\begin{equation} \label{Jensen_implicación}
%    f\left( \sum_{i = 1}^{n} \mathbb{P}(X = x_i)x_i\right) \leq \sum_{i = 1}^{n} \mathbb{P}(X = x_i)f(x_i) \Rightarrow \mathbb{E}[X]^{2} \leq \mathbb{E}[X^{2}].
%\end{equation}
%\hh{Pregunta: Debería eliminar la implicancia y dejar solo el resultado? R: agregar un "Es decir,". De todas maneras debo adaptar la demostración de regularidad para no utilizar notación se probabilidad.}
%
\section{Teorema de Chung, Graham y Wilson} \label{cuasi-aleatoriedad}\medskip

%\subsection{Grafos aleatorios}\medskip





\subsection{Enunciado y demostración}\medskip

Ya familiarizados con la noción de un grafo aleatorio, intuitivamente, diremos que un grafo casi-aleatorio es aquel que luce como uno verdaderamente aleatorio dentro de un marco determinístico. En otras palabras, es casi-aleatorio si asintóticamente satisface las propiedades que posee un grafo aleatorio casi seguramente. Formalmente:\medskip 

\begin{definicion} \label{casi-aleatoriedad}
    Sea $p\in(0,1)$ y $(G_n)_{n\to\infty}$ una secuencia de grafos, en donde cada $G_n$ posee $n$ vértices. Entonces el grafo $G_n$ es \textbf{casi-aleatorio} si en todo subconjunto $X\subset V(G_n)$ se encuentra una distribución de aristas similar, i.e,\medskip

    \begin{equation*}
        \Big| e(X) - p\tbinom{|X|}{2} \Big| = o(n^{2})\ ,\ \forall X\in V(G).
    \end{equation*}
\end{definicion}\medskip

La definición anterior está basada en el modelo binomial según la distribución de aristas que se pueden encontrar en cualquiern subconjunto de vértices del grafo. Más adelante, en 1989, Chung, Graham y Wilson \fs{referencia} muestran que existen diversas maneras equivalentes de caracterizar la noción de un grafo casi-aleatorio desde diferentes perspectivas.\medskip

%% Enunciado Teorema Chung, Graham y Wilson
\begin{teorema} \label{Teorema CGW} (Chung, Graham y Wilson) 
    Sea $p\in (0,1)$ fijo. Para cualquier secuencia de grafos $(G_{n})_{n \to \infty}$ sobre $|V(G_n)|= n$ vértices y $e_{G_n}= (p + o(1))\tbinom{n}{2}$ aristas, las siguientes propiedades son equivalentes:\medskip

    \begin{enumerate}
        \item[\makebox[0.5cm]{$\disc_p$:} Para todo $X,Y\subseteq V(G_n)$,\medskip
        
        \[
            \Big| e(X, Y)- p|X||Y| \Big| = o(n^{2}).
        \]\medskip
        
        \item[\makebox[1.0cm]{$\discp_p$:} Para todo $X\subseteq V(G_n)$,\medskip 
        
        \[
            \Big| e(X) - p \tbinom{|X|}{2}\Big| = o(n^{2})\ ,\ \ \forall X \subseteq V(G_n).
        \]\medskip
        
        \item[\makebox[1.0cm]{$\Count_p$:} Para cada grafo $H$, la cantidad de copias etiquetadas de $H$ en $G_n$ está dada por\medskip
        
        \[
            \left|\tbinom{G_n}{H}\right| = \left(p^{e(H)} + o(1)\right) n^{v(H)}.
        \]\medskip
        
        \item[\makebox[1.0cm]{$\Count_{C4,p}$:} La cantidad de copias etiquetadas de ciclos de orden 4 es\medskip
        
        \[
            \left|\tbinom{G_n}{C_4}\right| = (p^{4} + o(1)) n^{4}.
        \]\medskip
        
        \item[\makebox[1.0cm]{$\codeg_p$:}\medskip 
        
        \[
            \displaystyle\sum_{u,v\in V(G_n)}\Big| \cod(u,v)-p^{2}n\Big| = o(n^3).
        \]\medskip

        \item[\makebox[1.0cm]{$\eig_p$:} Si $\lambda_1 \geq \cdots \geq \lambda_n$ son los autovalores de de la matriz de adyacencia de $G_n$, entonces\medskip
        
        \[
            \lambda_1 = pn + o(n)\ \ \text{,}\ \ \ \displaystyle\max_{i\not= 1}|\lambda _{i}| = o(n).
        \]
    \end{enumerate}
\end{teorema}\medskip

Para una comprensión preeliminar, el Teorema \ref{Teorema CGW} fue enunciado utilizando notación asintótica. Sin embargo, con dicha formulación no queda del todo claro las dependencias cuantificadas de los errores entre cada una de las propiedades. Entonces, se replantea equivalentemente cada propiedad con una versión cuantitativa asociando algún parámetro de error $\varepsilon$ para todo grafo $G$ con un conjunto de vértices suficientemente grande.\medskip

Por ejemplo, bajo los supuestos del Teorema \ref{Teorema CGW}, asuma que la sucesión de grafos $(G_n)_{n\to\infty}$ satisface $\disc_p$. Entonces, para todo $\varepsilon > 0$, existe $n_0 \in \mathbb{N}$ tal que el grafo $G$ sobre $n\geq n_0$ vértices satisface\medskip

\begin{equation*}
    \disc_p(\varepsilon):\ \ \ e(X,Y) = p|X||Y| \pm \varepsilon n^2 , \ \ \forall X,Y \subseteq V(G).  
\end{equation*}\medskip

De manera general, diremos que una secuencia de grafos $(G_n)_{n\to\infty}$ con $|V(G_n)| = n$ satisface la propiedad $P_{x_1,...,x_k}$\footnote{Los parámetros $x_1,...,x_k$ pueden ser de distinta naturaleza, dependiendo de la propiedad simbolizada. En las propiedades del Teorema \ref{Teorema CGW} se utiliza $k=1$ con $x_1 = p$ salvo en la propiedad $\Count_{C4,p}$, en donde $k=2$.} si para cada elección de $\varepsilon >0$, existe algún $n_0 \in \mathbb{N}$ tal que el grafo $G$ con $n\geq n_0$ vértices satisface $P_{x_1,...,x_k}(\varepsilon)$. Más aún, se dirá que la propiedad $Q_{y_1,...,y_\ell}$ implica la propiedad $P_{x_1,...,x_k}$ si y solamente si $P_{x_1,...,x_k}(\varepsilon)$ implica $Q_{y_1,...,y_\ell}$. Es decir, para todo $\varepsilon > 0$, existe $\delta > 0$ y $n_0\in\mathbb{N}$ tales que el grafo $G$ con $n\geq n_0$ vértices cumple con $Q_{y_1,...,y_\ell}(\delta)$ cada vez que satisfaga la propiedad $P_{x_1,...,x_k}(\varepsilon)$.\medskip

Se desarrollará la demostración formal del teorema de Chung, Graham y Wilson utilizando notación $\varepsilon$-$\delta$, mostrando que cada par de propiedades $P_{x_1,...,x_k}$ y $Q_{y_1,...,y_\ell}$ son equivalentes entre sí con un cambio polinomial en el error. Esto es, $P_{x_1,...,x_k}(\varepsilon) \Rightarrow Q_{y_1,...,y_\ell}(C\varepsilon^{c})$ para algún par de constantes $C,c > 0$.\medskip

\begin{flushleft}
    \Large
    \textbf{Demostración Teorema 2 (Chung, Graham y Wilson).}\\
    \normalsize
\end{flushleft}\medskip

La demostración de este teorema será descompuesta en ocho proposiciones, las cuales mostrarán la equivalencia entre todas las propiedades de la siguiente manera:\medskip

\begin{equation} \label{Ciclo demo CGW}
    \begin{aligned}
        &\discp_p & \overset{\mathrm{Prop.}\  \ref{discp => count}.}{\Longrightarrow} & \ \ \Count_p & \overset{\mathrm{Prop.}\ \ref{count => C4}.}{\Longrightarrow} & \ \ \Count_{C4,p} & \overset{\mathrm{Prop.}\ \ref{eig => C4}.\ \mathrm{y}\ \ref{C4 => eig}.}{\Longleftrightarrow} & \ \ \eig_p\\
        &\ \ \big\Updownarrow \overset{\mathrm{Prop.}\ \ref{disc => discp}\ \mathrm{y}\ \ref{discp => disc}.}{}\ & \ & \ & \ & \ \ \ \ \ \ \ \big\Downarrow \overset{\mathrm{Prop.}\ \ref{C4 => codeg}.}{}& \ & \ \\
        &\disc_p &\ &\ \ \overset{\mathrm{Prop.}\ \ref{codeg => disc}.}{\Longleftarrow} &\ &\ \ \ \codeg_p.
    \end{aligned}
\end{equation}\medskip

Así, damos paso a las pruebas de cada proposición.\medskip

%%% Proposición: DISC_p => DISC_p'
\begin{prop} \label{disc => discp}
    Para todo $\varepsilon > 0$ y $p\in(0,1)$, existe $\delta > 0$ y $n_0\in\mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices satisface $\discp_p (\varepsilon)$ cada vez que cumpla con $\disc_p (\delta)$. En particular,\medskip

    \[
        \disc_p \Rightarrow \discp_p.
    \]
\end{prop}\medskip

%%% Demostración DISC_p => DISC_p'
\begin{proof}
    Sea $\varepsilon > 0$, $p\in (0,1)$, $\delta < \frac{\varepsilon}{2}$ y $n_0 \in \mathbb{N}$ suficientemente grande. Considere el grafo $G$ sobre $n\geq n_0$ vértices que satisface $\disc_p(\delta)$ y $X\subset V(G)$, entonces utilizamos la propiedad $\disc_p(\delta)$ para obtener el resultado de la siguiente manera:\medskip

    \[
        e(X) = p\dfrac{|X|^{2}}{2} \pm \delta n^{2} = p\tbinom{|X|}{2} \pm 2\delta n^{2}.
    \]\medskip

    Las igualdades anteriores consideran $e(X,X) = 2e(X)$, por definición, y la aproximación  $\tbinom{|X|}{2}= \frac{|X|^2}{2} \pm \delta n^2$.
\end{proof}\medskip

%%%%%%%%%% Proposición: DISC_p' => DISC_p
\begin{prop} \label{discp => disc}
    Para todo $\varepsilon > 0$ y $p\in(0,1)$, existe $\delta > 0$ y $n_0\in\mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices satisface $\disc_p (\varepsilon)$ cada vez que cumpla con $\discp_p (\delta)$. En particular, \medskip

    \[
        \discp_p \Rightarrow \disc_p.
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración DISC_p' => DISC_p
\begin{proof}
    Sea $\varepsilon > 0$, $p\in (0,1)$, $\delta < \frac{\varepsilon}{4}$ y $n_0\in\mathbb{N}$ suficientemente grande. Consideramos el grafo $G$ sobre $n\geq n_0$ vértices que satisface $\discp_p(\delta)$.\medskip

    En primera instancia, llevaremos el conteo de aristas que existen entre pares de subconjuntos de vértices, a un conteo equivalente mediante la combinación aditiva de las aristas que se encuentran en un subconjunto único de vértices. Es decir, para $X,Y\subset V(G)$,\medskip

    \begin{equation} \label{polarización_aristas}
        e(X,Y) = e(X\cup Y) + e(X\cap Y) - e(X\setminus Y) - e(Y\setminus X).    
    \end{equation}\medskip

    Observe que con esta configuración, el conteo de las aristas entre $X$ e $Y$ es doble cuando los vértices que componen las aristas pertenecen a $X\cap Y$. Luego, utilizamos la propiedad $\discp_p(\delta)$ sobre la identidad \eqref{polarización_aristas} para conseguir el resultado.\medskip
    
    \begin{align*}
        e(X,Y) &= p\left( \tbinom{|X\cup Y|}{2} + \tbinom{|X\cap Y|}{2} - \tbinom{|X\setminus Y|}{2} - \tbinom{|Y\setminus X|}{2} \right) \pm 4\delta n^{2} \\
        &= p|X||Y| \pm 4\delta n^{2} \\
        &= p|X||Y| \pm \varepsilon n^{2}.
    \end{align*}
\end{proof}\medskip

%%%%%%%%%% Proposición: DISC'_P => COUNT_P
\begin{prop} \label{discp => count}
    Para todo $\varepsilon > 0$ y $p\in(0,1)$, existe $\delta > 0$ y $n_0\in\mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices satisface $\Count_p (\varepsilon)$ cada vez que cumpla con $\discp_p (\delta)$. En otras palabras,\medskip

    \[
        \discp_p \Rightarrow \Count_p.
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración DISC'_P => COUNT_P
\begin{proof}
    Sea $\varepsilon > 0$, $p\in (0,1)$ y $H$ un grafo sobre $\ell$ vértices, elegimos $\delta < \frac{\varepsilon}{6\ell^{2}}$ y $n_0\in \mathbb{N}$ suficientemente grande. Considere también el grafo $G = (V,E)$ con $n\geq n_0$ vértices que satisface la propiedad $\Count_{p}(\varepsilon)$.\medskip

    Dado cualquier grafo $F$ con $\ell$ vértices y $e_F \geq 1$ aristas, razonamos por inducción sobre su cantidad de aristas para probar que\medskip

    \begin{equation} \label{ind_count}
        \left| \tbinom{G}{F}\right| = p^{e_F}n^{\ell} \pm 4e_F \delta n^{\ell}.
    \end{equation}\medskip

    Una vez probada la ecuación \eqref{ind_count}, el resultado seguirá de tomar $F = H$ y la elección de $\delta$ para conseguir las siguientes desigualdades:\medskip

    \begin{equation*}
        4e_F \delta n^{\ell} \leq 4\tbinom{\ell}{2}\delta n^{\ell} \leq 4\delta\left( \frac{\ell^{2}}{2} + \delta\ell^{2}\right)n^{\ell} \leq 6\delta\ell^{2}n^{\ell} < \varepsilon n^{\ell}.
    \end{equation*}\medskip

    Cuando $e_F = 1$, $\left| \tbinom{G}{F}\right|$ es el número de pares ordenados de vértices de $G$ que forman una arista junto a cualquier combinación de $\ell -2$ vértices para completar una copia de $F$. Es decir,\medskip

    \begin{equation*}
        \left| \tbinom{G}{F}\right| = 2e_G(n-2)(n-3)\cdots(n-\ell + 1).
    \end{equation*}\medskip
    
    Luego, si aplicamos la propiedad $\discp_p(\delta)$ sobre $V$, tendremos que la cantidad de aristas es\medskip

    \begin{equation*}
        e_G = \frac{pn(n-1)}{2} \pm \delta n^{2}.
    \end{equation*}\medskip

    Así, con $\left| \tbinom{G}{F}\right| = pn^{\ell} \pm 4\delta n^{\ell}$, se prueba el caso inicial de la inducción.\medskip

    Ahora, sea $F$ un grafo con $e_F > 1$ aristas y asumiremos que se satisface la ecuación \eqref{ind_count} sobre cualquier grafo con una cantidad de aristas menor que $e_F$. Entonces, para desarrollar la inducción, vamos a considerar la siguiente notación:\medskip

    \begin{enumerate}
        \item[i)] $F^{-} := ([\ell], E(F)\setminus \lbrace ij\rbrace)$, es el grafo producido por eliminar la arista $ij$ de $F$.
        \item[ii)] $F^{*} := F[[\ell]\setminus \lbrace i,j\rbrace]$, es el grafo inducido por $[\ell]\setminus \lbrace i,j\rbrace$, i.e, grafo producido de eliminar los vértices de $ij$ en $F$. 
    \end{enumerate}\medskip

    %\begin{figure}[h]
    %    \centering
    %    \begin{tikzpicture}
    %        % F
    %        \begin{scope}[shift = {(0,0)}]
    %            \draw[step=0.5cm, gray, very thin] (-2,-2) grid (2,2);
    %            \draw[line width =1.2pt] (0,-0.75) ellipse (1.5 and 0.75) 
%
    %            \node[fill=black, circle, inner sep=2pt, minimum size=3pt, %label={90:$\mathbf{i}$}]  (i) at (-1,1.5) {};
    %            \node[fill=black, circle, inner sep=2pt, minimum size=3pt, %label={90:$\mathbf{j}$}]  (j) at (1,1.5) {};
%
    %            % Rellenar con puntos aleatorios la elipse
    %            \foreach \i in {1,...,6} {
    %                \pgfmathsetmacro{\angle}{rand*360}
    %                %\pgfmathsetmacro{\radius}{rand}
    %                \pgfmathsetmacro{\x}{1.2*cos(\angle)}
    %                \pgfmathsetmacro{\y}{0.15*sin(\angle)}
    %                \node[fill=black, circle, inner sep=2pt, minimum size=3pt] %(\i) at (1.2*\x,0.5*\y - 0.5);
    %            }
    %        \end{scope}
    %        
    %        % F^{-}
    %        \begin{scope}[shift = {(5,0)}]
    %            \draw[step=0.5cm, gray, very thin] (-2,-2) grid (2,2);
    %            \draw[line width =1.2pt] (0,-0.75) ellipse (1.5 and 0.75)
%
    %            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, %label={90:$\mathbf{i}$}]  (i) at (-1,1.5) {};
    %            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, %label={90:$\mathbf{j}$}]  (j) at (1,1.5) {};
    %        \end{scope}
%
    %        % F^{*}
    %        \begin{scope}[shift = {(10,0)}]
    %            \draw[step=0.5cm, gray, very thin] (-2,-2) grid (2,2);
    %            \draw[line width =1.2pt] (0,-0.75) ellipse (1.5 and 0.75)
%
    %            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, %label={90:$\mathbf{i}$}]  (i) at (-1,1.5) {};
    %            \node[fill=black, circle, inner sep=2pt, minimum size=4pt, %label={90:$\mathbf{j}$}]  (j) at (1,1.5) {};
    %        \end{scope}
    %    \end{tikzpicture}
    %\end{figure}\medskip

    Sea $T^{-}$ una copia etiquetada de $F^{-}$ en $G$, es decir, $T^{-}$ se corresponde con una aplicación inyectiva $f: V(F^{-}) \to V(T^{-})\subseteq V$ tal que $f(u)f(v)\in E(T^{-})$ cada vez que $uv\in E(F^{-})$. De esta manera, se define $e_{T^{-}}$ como la tupla \fs{Es una tupla?, es una arista?}$(f(i), f(j))$ resultante de la imagen de los vértices $i,j\in V(F^{-})$.\medskip

    Se escribe la cantidad de copias etiquetadas de $F$ en $G$ de manera conveniente y se utilizará la hipótesis de inducción como se muestra a continuación:\medskip

    \begin{align} \label{count_G_F}
        \left| \tbinom{G}{F}\right| &= \sum_{T^{-}\in \tbinom{G}{F^{-}}} \mathbbm{1}_{E}(e_{T^{-}})\nonumber \\
        &= \sum_{T^{-}\in \tbinom{G}{F^{-}}} \left[ \mathbbm{1}_{E}(e_{T^{-}}) + p - p\right]\nonumber \\
        &= \sum_{T^{-}\in \tbinom{G}{F^{-}}} p + \sum_{T^{-}\in \tbinom{G}{F^{-}}} \left[ \mathbbm{1}_{E}(e_{T^{-}}) -p\right]\nonumber \\
        &= p\left|\tbinom{G}{F^{-}}\right| +  \sum_{T^{-}\in \tbinom{G}{F^{-}}} \left[ \mathbbm{1}_{E}(e_{T^{-}}) -p\right]\nonumber \\
        &= p^{e_F}n^{\ell} + \sum_{T^{-}\in \tbinom{G}{F^{-}}} \left[ \mathbbm{1}_{E}(e_{T^{-}}) -p\right] \pm 4(e_F - 1)\delta n^{\ell}.
    \end{align}\medskip
    
    Ahora, es suficiente probar que el segundo sumando de la desigualdad \eqref{count_G_F} es pequeño. Para esto, considere $T^{*}$ una copia de $F^{*}$, y denote por $F_{i}^{*}$ y $F_{j}^{*}$ a los grafos resultantes de eliminar de $F^{-}$ los vértices $j$ e $i$ respectivamente. Definan los siguientes conjuntos:\medskip
    
    \[A_{i}^{T^{*}} := \lbrace v\in V\ :\ T^{*}\ \text{con}\ v\ \text{forma una copia de}\ F_{i}^{*}\rbrace \]
    \[A_{j}^{T^{*}} := \lbrace v\in V\ :\ T^{*}\ \text{con}\ v\ \text{forma una copia de}\ F_{j}^{*}\rbrace .\]\medskip

    Los conjuntos anteriores, por construcción, son tales que para cada tupla $(a,b)\in A_{i}^{T^{*}}\times A_{j}^{T^{*}}$ añadida a $T^{*}$ se obtiene una copia de $F^{-}$. Así, reescribiendo el segundo sumando de la igualdad \eqref{count_G_F} convenientemente y utilizando la propiedad $\discp_p(\delta)$,\medskip

    \begin{align*}
        \left| \sum_{T^{-}\in \tbinom{G}{F^{-}}} \left[\mathbbm{1}_{E}(e_{T^{-}}) - p\right]\right|
        &=  \left| \sum_{T^{*}\in \tbinom{G}{F^{*}}}\sum_{f\in A_{i}^{T^{*}}\times A_{j}^{T^{*}}} \left[ \mathbbm{1}_{E}(f) - p\right]\right| \\
        &\leq \sum_{T^{*}\in \tbinom{G}{F^{*}}} \left| \sum_{f\in A_{i}^{T^{*}}\times A_{j}^{T^{*}}} \left[ \mathbbm{1}_{E}(f) - p\right]\right|\\
        &= \sum_{T^{*}\in \tbinom{G}{F^{*}}} \left| e(A_{i}^{T^{*}}, A_{j}^{T^{*}}) - p| A_{i}^{T^{*}} | | A_{j}^{T^{*}}|\right|\\
        &\leq \sum_{T^{*}\in \tbinom{G}{F^{*}}} \delta n^{2}\\
        %&\leq  n^{\ell -2}\delta n^{2}\\
        &\leq 4\delta n^{\ell}.
    \end{align*}\medskip

    De esta manera, tomando la elección de $\delta$ y $F=H$ se obtiene el resultado.    
\end{proof}\medskip

%\begin{tikzpicture}
%    \pgfmathtruncatemacro\nrOfNodes{50}
%    \pgfmathtruncatemacro\diameter{60}
%
%    \foreach \i in {1,...,\nrOfNodes} {
%        \pgfmathsetmacro\posX{rnd*(\canvaswidth-0.6) + 0.3}
%        \pgfmathsetmacro\posY{rnd*(\canvasheight-0.6) + 0.3}
%        \node[node] (a\i) at (\posX, \posY) {};
%
%        % draw node connections
%        \ifnum\i>1
%            \pgfmathsetmacro\last{\i -1}
%            \foreach \j in {1,...,\last} {
%                \gettikzxy{(a\i)}{\pX}{\pY};
%                \gettikzxy{(a\j)}{\qX}{\qY};
%
%                % divide by 100 so the values are still small enough for tickz %to handle while preserving adequate precision
%                \pgfmathsetmacro\diffX{(\pX-\qX)/100}
%                \pgfmathsetmacro\diffY{(\pY-\qY)/100}
%                \pgfmathsetmacro\calculatedDistance{ sqrt( (\diffX)^2 + %(\diffY)^2 ) * 100};
%                \ifdim\calculatedDistance pt <\diameter pt
%                    \begin{pgfonlayer}{background}
%                        \draw (a\i) -- (a\j) node [midway, above, sloped] {};
%                    \end{pgfonlayer}
%                \fi
%            }
%        \fi
%    }
%
%    %draw radio ranges
%    \begin{pgfonlayer}{background}
%        \foreach \i in {1,...,\nrOfNodes} {
%            \draw[color=black,fill=blue, opacity=0.05] (a\i) circle (\diameter %pt);
%        }
%    \end{pgfonlayer}
%\end{tikzpicture}

%%%%%%%%%% Proposición: COUNT_p => COUNT_C4,p
\begin{prop} \label{count => C4}
    Para todo $\varepsilon > 0$ y $p\in (0,1)$, existe $\delta > 0$ y $n_0\in \mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices satisface $\Count_{C_4,p} (\varepsilon)$ cada vez que cumpla con $\Count_p(\delta)$. En otras palabras,\medskip

    \[
        \Count_p \Rightarrow \Count_{C_4,p}.
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración COUNT_p => COUNT_C4,p
\begin{proof}
    Se trata de un caso particular de $\Count_p$, en donde $H = C4$ y $\delta < \epsilon$.
\end{proof}\medskip

%%%%%%%%%% Proposición: COUNT_C4_p => CODEG_p
\begin{prop} \label{C4 => codeg}
    Para todo $\varepsilon > 0$ y $p\in (0,1)$, existe $\delta > 0$ y $n_0\in \mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas satisface $\codeg_p (\varepsilon)$ cada vez que cumpla con $\Count_{C_4,p}(\delta)$. En particular,\medskip

    \[
        \Count_{C_4,p} \Rightarrow \codeg_p.
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración COUNT_C4_p => CODEG_p
\begin{proof}
    Dado $\varepsilon > 0$ y $p\in (0,1)$, elegimos $\delta < \frac{\varepsilon^{2}}{16}$ y $n_0\in\mathbb{N}$ suficientemente grande. También considere el grafo $G$ sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas que satisface $\Count_{C_4,p}(\delta)$.\medskip

    La clave de esta demostración radica en encontrar una buena cota para $\sum_{u,v\in V(G)} \cod(u,v)$ y $\sum_{u,v\in V(G)} \cod(u,v)^{2}$, y la utilización apropiada de la desigualdad de Cauchy-Schwarz.\medskip
    
    Entonces, por un lado, utilizando la relación entre el grado y el cogrado visto en \eqref{grado-cogrado},\medskip

    \begin{align*}
        \displaystyle\sum_{u,v\in V(G)} \cod(u,v) &= \displaystyle\sum_{x\in V(G)} \deg(x)^{2}\\
        &\overset{\mathrm{CS}}{\geq} \dfrac{1}{n}\left( \displaystyle\sum_{x\in V(G)} \deg(x)\right)^{2}\\
        &= \dfrac{4e_G^{2}}{n}\\
        &\geq \dfrac{4}{n}\left( \dfrac{pn^{2}}{2} - \delta n^{2}\right)^{2}\\
        &\geq p^{2}n^{3} - 4\delta n^{3}.
    \end{align*}\medskip

    Por otro lado, usando $\Count_{C_4,p}(\delta)$,\medskip

    \begin{equation*}
        \displaystyle\sum_{u,v\in V(G)} \cod(u,v)^{2} = \left|\tbinom{G}{C_4}\right| \pm \delta n^{4} \leq p^{4}n^{4} + 2\delta n^{4}.
    \end{equation*}\medskip

    Así, con las cotas anteriores, se obtiene el resultado de la siguiente manera:\medskip

    \begin{align*}
        \displaystyle\sum_{u,v\in V(G)} \Big|\cod(u,v) - p^{2}n\Big| &\overset{\mathrm{CS}}{\leq} n\left(\displaystyle\sum_{u,v\in V(G)} (\cod(u,v) - p^{2}n)^{2} \right)^{1/2}\\
        &= n\left(\displaystyle\sum_{u,v\in V(G)} \cod(u,v)^{2} - 2p^{2}n\displaystyle\sum_{u,v\in V(G)} \cod(u,v) + \displaystyle\sum_{u,v\in V(G)} p^{4}n^{2} \right)^{1/2}\\
        &\leq n\left(p^{4}n^{4} + 2\delta n^{4} + 2p^{2}n(4\delta n^{3} - p^{2}n^{3}) + p^{4}n^{4} \right)^{1/2}\\
        &= n((2 + 8p^{2})\delta n^{4})^{1/2}\\
        %&\leq 10^{1/2}\delta^{1/2}n^{3}\\
        &\leq 4\delta^{1/2}n^{3}.
    \end{align*}
\end{proof}\medskip

%%%%%%%%%% Proposición: CODEG_p => DISC_p
\begin{prop} \label{codeg => disc}
    Para todo $\varepsilon > 0$ y $p\in (0,1)$, existe $\delta > 0$ y $n_0\in \mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas satisface $\disc_p (\varepsilon)$ cada vez que cumpla con $\codeg_p(\delta)$. En particular,\medskip

    \[
        \codeg_p \Rightarrow \disc_p.
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración CODEG_p => DISC_p
\begin{proof}
    Dado $\varepsilon > 0$, $p\in (0,1)$, seleccionamos $\delta < \frac{\varepsilon^{4}}{81}$ y $n_0\in\mathbb{N}$ suficientemente grande. Sea $G$ un grafo de $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas que satisface la propiedad $\codeg_p (\delta)$.\medskip

    En primera instancia note que la propiedad $\codeg_p(\delta)$ induce una concentración en los grados de los vértices de $G$. En efecto,\medskip

    \begin{align*}
        \displaystyle\sum_{x\in V(G)} \Big|\deg(x) - pn\Big| &\overset{\mathrm{CS}}{\leq} n^{1/2}\left( \displaystyle\sum_{x\in V(G)} (\deg(x) - pn)^{2}\right)^{1/2}\\
        &= n^{1/2}\left( \displaystyle\sum_{x\in V(G)} \deg(x)^{2} -2pn\displaystyle\sum_{x\in V(G)} \deg(x) + p^{2}n^{3}\right)^{1/2}\\
        &\overset{\eqref{grado-cogrado}}{=} n^{1/2}\left( \left(\displaystyle\sum_{u,v\in V(G)} \cod(u,v) - p^{2}n\right) -4pn e_G + 2p^{2}n^{3} \right)^{1/2}\\
        &\leq n^{1/2}\left( \left(\displaystyle\sum_{u,v\in V(G)} \Big|\cod(u,v) - p^{2}n\Big|\right) + 4pn\left( \delta n^{2} - \frac{pn^{2}}{2}\right) + 2p^{2}n^{3}\right)^{1/2}\\
        &\leq n^{1/2}\left( 2p^{2}n^{3} - 2p^{2}n^{3} + 4p\delta n^{3} + \delta n^{3}\right)^{1/2}\\
        %&< (5\delta)^{1/2}n^{2}\\
        &< 3\delta^{1/2}n^{2}.
    \end{align*}\medskip

    Luego, para todo $X,Y\in V(G)$, se reescribe la expresión de la propiedad $\disc_p$ de forma conveniente para posteriormente utilizar la desigualdad de Cauchy-Schwarz.\medskip

    \begin{equation} \label{ec_prop_6}
        \Big|e(X,Y) - p|X||Y|\Big| = \left| \displaystyle\sum_{x\in X} (\deg(x;Y) - p|Y|)\right| \overset{c-s}{\leq} n^{1/2}\left( \displaystyle\sum_{x\in X} (\deg(x;Y) - p|Y|)^{2}\right)^{1/2}.
    \end{equation}\medskip

    En la desigualdad anterior se ha conseguido que el argumento de la suma sea siempre no negativo, lo que permite extender su dominio de $X$ a $V(G)$. De esta manera, usando a la cota proveniente de la conentración de los grados en los vértices de $G$, se prueba el resultado continuando desde \eqref{ec_prop_6}:\medskip

    \begin{align*}
        \Big|e(X,Y) - p|X||Y|\Big| &\leq n^{1/2}\left( \displaystyle\sum_{x\in V(G)} (\deg(x;Y) - p|Y|)^{2}\right)^{1/2}\\
        &= n^{1/2}\left( \displaystyle\sum_{x\in V(G)} \deg(x; Y)^{2} - 2p|Y|\displaystyle\sum_{x\in V(G)} \deg(x;Y) + \displaystyle\sum_{x\in V(G)} p^{2}|Y|^{2}\right)^{1/2}\\
        &= n^{1/2}\left( 2p^{2}n|Y|^{2} - p^{2}n|Y|^{2} + 2p|Y| |Y|pn  - 2p|Y| |Y|pn +  \displaystyle\sum_{y,y'\in Y} \cod(y, y') - 2p|Y|\displaystyle\sum_{y\in Y} \deg(y) \right)^{1/2}\\
        &= n^{1/2}\left( \displaystyle\sum_{y,y'\in Y} (\cod(y,y') - p^{2}n) - 2p|Y|\displaystyle\sum_{y\in Y} (\deg(y) - pn) \right)^{1/2}\\
        &\leq n^{1/2}\left( \left|\displaystyle\sum_{y,y'\in Y} (\cod(y,y') - p^{2}n)\right| + \left|2p|Y|\displaystyle\sum_{y\in Y} (\deg(y) - pn)\right| \right)^{1/2}\\
        &\leq n^{1/2}\left( \displaystyle\sum_{u,v\in V(G)} \Big|\cod(u,v) - p^{2}n\Big| + 2p|Y|\displaystyle\sum_{x\in V(G)} \Big|\deg(x) - pn\Big|\right)^{2}\\
        &\leq n^{1/2}\left( \delta n^{3} + 6p\delta^{1/2}n^{3}\right)^{1/2}\\
        %&\leq 7^{1/2}\delta^{1/4}n^{2}
        &< 3\delta^{1/4}n^{2}.
    \end{align*} 
\end{proof}\medskip

%%%%%%%%%% Proposición: EIG_p => COUNT_C4,p
\begin{prop} \label{eig => C4}
    Para todo $\varepsilon > 0$ y $p\in (0,1)$, existe $\delta > 0$ y $n_0\in \mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas satisface $\Count_{C_4,p} (\varepsilon)$ cada vez que cumpla con $\eig_p(\delta)$. En particular,\medskip

    \[
        \eig_p \Rightarrow \Count_{C_4,p}.
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración EIG_p => COUNT_C4,p
\begin{proof}
    Dado $\varepsilon > 0$ y $p\in (0,1)$, se elige $\delta < \frac{\varepsilon}{20}$ y $n_0\in\mathbb{N}$ suficientemente grande. Consideramos el grafo $G$ sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas que satisface la propiedad $\eig_p (\delta)$, $A\in \mathcal{M}_{n\times n}(\mathbb{R})$ como la matriz de adyacencia de $G$, y $\lambda_1 \geq \cdots \geq \lambda_n$ los valores propios de $A$.\medskip

    Observe que la cantidad de copias etiquetadas de caminatas cerradas de largo 4 que no son $C_4$ en $G$ se encuentran dentro de un error de a lo más $\delta n^{4}$ con respecto al número de copias etiquetadas de $C_4$ en $G$. De esta observación, utilizando el Lema~\ref{potencia_matriz_adyacencia = caminatas} y el Corolario~\ref{Tr_Ak},\medskip

    \begin{align} \label{ec_prop_7.1}
        \left|\tbinom{G}{C_4}\right| &= \Tr(A^{4}) \pm \delta n^{4} \nonumber\\
        &= \sum_{i = 1}^{n} \lambda_{i}^{4} \pm \delta n^{4} \nonumber\\
        &= \lambda_{1}^{4} + \sum_{i = 2}^{n} \lambda_{i}^{4} \pm \delta n^{4}.
    \end{align}

    Luego, recordando que  $\Tr(A^{2}) = 2e_G$, y usando $\eig_p (\delta)$,\medskip

    \begin{equation} \label{ec_prop_7.2}
        \sum_{i = 2}^{n} \lambda_{i}^{4} \leq \max_{i \not = 1}\lambda_{i}^{2}\sum_{i = 1}^{n} \lambda_{i}^{2} \leq \delta n^{2}\Tr(A^{2}) \leq \delta n^{2}(pn^{2} + 2\delta n^{2}) \leq 3\delta n^{4}.
    \end{equation}\medskip

    Finalmente, se concluirá tras usar la propiedad $\eig_p (\delta)$ sobre el primer autovalor y la cota mostrada en \eqref{ec_prop_7.2}. Continuando desde la ecuación \eqref{ec_prop_7.1},\medskip

    \[
        \left|\tbinom{G}{C_4}\right| = \lambda_{1}^{4} + \sum_{i = 2}^{n}\lambda_{i}^{4} \pm \delta n^{4} \leq p^{4}n^{4} + 20\delta n^{4}.
    \]
\end{proof}\medskip

%%%%%%%%%% Proposición: COUNT_C4,p => EIG_p
\begin{prop} \label{C4 => eig}
    Para todo $\varepsilon > 0$ y $p\in (0,1)$, existe $\delta > 0$ y $n_0\in\mathbb{N}$ tales que el grafo $G$ sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas satisface $\eig_p(\varepsilon)$ cada vez que cumpla la propiedad $\Count_{C_4, p}(\delta)$. Es decir,\medskip

    \[
        \Count_{C_4,p} \Rightarrow \eig_p .
    \]
\end{prop}\medskip

%%%%%%%%%% Demostración COUNT_C4,p => EIG_p
\begin{proof}
    Sea $\varepsilon > 0$ y $p\in (0,1)$, escogemos $\delta < \frac{\varepsilon^{4}}{4}$ y $n_0\in\mathbb{N}$ suficientemente grande. Sea también $G$ un grafo sobre $n\geq n_0$ vértices y $e_G = \frac{pn^{2}}{2} \pm \delta n^{2}$ aristas que satisface la propiedad $\Count_{C_4, p}(\delta)$, $A\in\mathcal{M}_{n\times n}(\mathbb{R})$ la matriz de adyacencia de $G$, y $\lambda_1 \geq \cdots \geq \lambda_n$ los valores propios de $A$.\medskip

    En lo que respecta al primer autovalor, sabemos por un lado que éste es al menos el promedio de los grados gracias al Lema~\ref{cota_primer_autovalor}. Es decir,\medskip

    \begin{equation} \label{cota1_lambda1}
        \lambda_1 \geq \frac{\sum_{x\in V(G)}\deg(x)}{n} = \frac{2e_G}{n} = \frac{2}{n}\left( \frac{pn^{2}}{2} \pm \delta n^{2}\right) \geq pn - 2\delta n.
    \end{equation}\medskip

    Por otro lado, mediante el Lema~\ref{potencia_matriz_adyacencia = caminatas}, el Corolario~\ref{Tr_Ak} y la propiedad $\Count_{C_4,p}(\delta)$,\medskip

    \begin{equation} \label{cota2_lambda1}
        \lambda_{1}^{4} \leq \sum_{i = 1}^{n}\lambda_{i}^{4} = \Tr(A^{4}) = \left| \tbinom{G}{C_4}\right| \pm \delta n^{4} \leq p^{4}n^{4} + 2\delta n.
    \end{equation}\medskip

    La desigualdad \eqref{cota2_lambda1} implica que $\lambda_1 \leq pn + (2\delta)^{1/4} n$, y en combinación con la cota vista en $\eqref{cota1_lambda1}$, se obtiene que $\lambda_1 = pn \pm (2\delta)^{1/4} n$.\medskip

    Por último, observe por las cotas vistas anteriormente,\medskip

    \begin{align*}
        \max_{i\not= 1} |\lambda_1|^{4} &\leq \sum_{i = 2}^{n} \lambda_{i}^{4} + \lambda_1^{4} - \lambda_1^{4} \\
        &= \Tr(A^{4}) - \lambda_{1}^{4}\\
        &\leq p^{4}n^{4}  + 2\delta n^{2} - p^{4}n^{4} + 2\delta n^{4}\\
        &= 4\delta n^{4}.
    \end{align*}\medskip

    De esta manera, se logra probar el resultado determinando que $\displaystyle\max_{i \not= 1}|\lambda_i| \leq (4\delta)^{1/4}n$. 
\end{proof}\medskip

\subsection{Aspectos adicionales}\medskip

La noción inicial de un grafo casi-aleatorio por distribución de aristas presentada en la Definición \ref{casi-aleatoriedad} contempla verificar si todos los subconjuntos de vértices del grafo satisfacen su condición para determinar la casi-aleatoriedad de un grafo. Es decir, se debe corroborar sobre $2^{|X|}$ subconjuntos. Por esto, resulta sorprendente que la propiedad, aparentemente más débil, $\Count_{C_{4},p}$ sea una caracterización equivalente a todas las condiciones de casi-aleatoriedad que establece el teorema, puesto a que se verifica de manera polinomial. \fs{En verdad las otras también, pero siento que quizás le deba dar más énfasis a C4. Modifico el párrafo anterior??}\medskip

Una pregunta natural al observar la propiedad $\Count_{C_{4},p}$ es: ¿Podemos debilitar la condición para un conteo esperado de copias etiquetadas de $K_3$?. La respuesta es no, de hecho, la propiedad puede ser extendida a $\Count_{C_{2t},p}$ con $t\geq 2$. Es decir, para el grafo $G$,\medskip

\[
    \Count_{C_{2t},p} :\ \left| \tbinom{G}{C_{2t}}\right| = \left( p^{2t} + o(1)\right)n^{2t}\ ,\ \forall t\geq 2.
\]\medskip

Se expone un bosquejo de la demostración de la extensión de $\Count_{C_{4},p}$ a la propiedad $\Count_{C_{2t},p}$.\medskip

%%%% Proposición: Count_{C_2t,p} <=> EIG_p
\begin{prop}
    Sea $p\in (0,1)$ y $(G_n)_{n\to\infty}$ una secuencia de grafos con $|V(G_n)| = n$ vértices y $e_{G_n} = (p + o(1))\tbinom{n}{2}$ aristas, entonces las propiedades $\Count_{C_{2t},p}$ y $\eig_p$ son equivalentes.
\end{prop}\medskip

%%%% Demostración: Count_{C_2t,p} <=> EIG_p
\begin{proof}
    Este resultado es una consecuencia directa de las demostraciones de la Proposición \ref{eig => C4} y \ref{C4 => eig} tras notar el siguiente par de observaciones. En primer lugar, la cantidad de copias etiquetadas caminatas cerradas de largo $2t$ que no son $C_{2t}$ en $G_n$ están dentro de un error $O(n^{2t - 1})$, es decir,\medskip

    \[
        \Tr(A^{2t}) = \sum_{i=1}^{n} \lambda_{i}^{2t} = \left| \tbinom{G_n}{C_{2t}}\right| + O(n^{2t -1}).
    \]\medskip

    También, se debe modificar la cota presentada en la ecuación \eqref{ec_prop_7.2} como sigue:\medskip

    \[
        \sum_{i=2}^{n}\lambda_{i}^{2t} \leq \max_{i\not=1}\lambda_{i}^{2(t-1)}\sum_{i=1}^{n} \lambda_{i}^{2} = \max_{i\not=1}\lambda_{i}^{2t-2} \Tr(A^{2}).
    \]\medskip

    Con estas observaciones el resultado queda demostrado.
\end{proof}\medskip

Es importante destacar que la demostración anterior es funcional gracias a que los ciclos de orden par preservan una contribución positiva en la suma de cada uno de los autovalores de $G$, eliminando la posibilidad de cancelaciones entre ellos.\medskip

A continuación, se expone la construcción de un contraejemplo de un grafo que posee la cantidad de copias etiquetadas esperadas de $K_3$, pero no cumple las condiciones para ser casi-aleatorio. La idea de la construcción consiste en la combinación de dos grafos, uno con una cantidad mayor que la esperada de copias etiquetadas de $K_3$, y otro con una cantidad menor. Consideramos entonces independientemente los grafos completos $K_{n_1}$ y $K_{n_2, n_2}$ tales que su unión disjunta forma el grafo $G = K_{n_1}\cup K_{n_2, n_2}$ con $n_1 + 2n_2 = n$ vértices.\medskip

%%%% Dibujo contraejemplo
\begin{figure}[h]
    \centering
    \begin{tikzpicture}
        %\draw[step=0.5cm, gray, very thin] (-5,-3) grid (5,3);
        %\node[fill=red, circle, inner sep=2pt, minimum size=4pt] at (0,0) {};
        \node at (-3,0) {$G = $};
        % K_n1
        \node at (-1.5,1.2) {$K_{n_1}$};
        \draw[line width=1.2pt] (-1.5,0) ellipse (0.8 and 0.8);
        \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (1) at (-1.75,-0.4) {};
        \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (2) at (-1.25, 0.25) {}; 
        \draw (1) -- (2);

        % K_n_2,n_2
        \node at (2.5,0) {$K_{n_2,n_2}$};
        \draw[line width=1.2pt] (1.2,0.7) ellipse (0.8 and 0.5);
        \draw[line width=1.2pt] (1.2,-0.7) ellipse (0.8 and 0.5);
        \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (3) at (1.2,0.7) {};
        \node[fill=black, circle, inner sep=2pt, minimum size=4pt] (4) at (1.2,-0.7) {};
        \draw (3) -- (4);
    \end{tikzpicture}
    \label{Esquema_Contraejemplo}
    \caption{Esquema de la configuración del grafo usado como contraejemplo. Aquí, 
    \begin{tikzpicture}
        %\draw[step=0.5cm, gray, very thin] (-1,0) grid (1,0);
        \node[fill=black, circle,inner sep=1.5pt, minimum size=2pt] (a) at (0,0.06) {};
        \node[fill=black, circle,inner sep=1.5pt, minimim size=2pt] (b) at (0.5,0.06) {};
        \draw (a) -- (b);
    \end{tikzpicture} representa las aristas permitidas dentro del grafo $G$.}
\end{figure}\medskip

Sobre $K_{n_1}$ y $K_{n_2, n_2}$, observe que la cantidad de sus aristas y copias etiquetadas de $K_3$ son:\medskip

\begin{equation*}
    \begin{aligned}
        &e_{K_{n_1}} \approx \frac{n_{1}^{2}}{2} &\ \  , &\ \ \left| \tbinom{K_{n_1}}{K_3}\right| \approx n_{1}^{3}\ \ , \\
        &e_{K_{n_2, n_2}} \approx \frac{(n-n_1)^{2}}{4} &\ \  , &\ \ \left| \tbinom{K_{n_2, n_2}}{K_3}\right| = 0.
    \end{aligned}
\end{equation*}\medskip

Ahora, se encontrará el parámetro $p\in(0,1)$ de manera tal que el grafo $G$ posea la cantidad esperada de aristas y copias etiquetadas de $K_3$, acorde a un grafo aleatorio binomial con densidad $p$. Para ello, se plantea el siguiente sistema de ecuaciones:\medskip

\begin{equation*}
    \begin{cases}
        p\frac{n^{2}}{2} = \frac{n_{1}^{2}}{2} + \frac{(n-n_1)^{2}}{4}\\
        p^{3}n^{3} = n_{1}^{3}.
    \end{cases}
\end{equation*}\medskip

Resolviendo el sistema anterior, se obtiene que $p=\frac{1}{3}$ y $n_1 = n_2 = \frac{n}{3}$. Dicha configuración, en efecto, presenta\medskip

\begin{equation*}
    e_G = \binom{\frac{n}{3}}{2} + \frac{n^{2}}{9} = \frac{1}{3}\binom{n}{2} + o(n^{2}),
\end{equation*}\medskip

Como también,\medskip

\begin{equation*}
    \left| \tbinom{G}{K_3}\right| = \left(\frac{n}{3}\right)^{3} + o(n^{3}) = \left(\frac{1}{3}\right)^{3}n^{3} + o(n^{3}).
\end{equation*}\medskip

Sin embargo, el grafo $G$ no es casi-aleatorio debido a que no existen aristas entre $K_{n_1}$ y $K_{n_2, n_2}$ ni dentro de los conjuntos que conforman a $K_{n_2, n_2}$.\medskip

%Es posible replantear el Teorema \ref{Teorema CGW} para grafos bipartitos como %se muestra a continuación.
%
%%%%% Teorema : Versión bipartita Chung-Graham y Wilson.
%\begin{teorema} \label{Teorema CGW Bipartito} (Chung, Graham y Wilson, versión %bipartita)
%    Sea $p\in (0,1)$ fijo y una secuencia $(G_n)_{n\to\infty}$ de grafos %bipartitos $G_n$ con $n$ vértices, cuya partición de vértices es $V(G) = %U\cup W$ y su cantidad de aristas es $e_{G_n} = (p + o(1))|U||W|$. %Entonces, asumiendo que $|U|,|W|\to\infty$, las siguientes propiedades son %equivalentes:\medskip
%
%    \begin{enumerate}
%        % BI-DISC
%        \item[\makebox[0.5cm]{$\bidisc_p$:} Para todo $X\subset U$ e $Y\subset %W$,
%        \[
%            \Big| e(X,Y) - p|X||Y|\Big| = o(|U||W|).
%        \]
%
%        % BI-COOUNT
%        \item[\makebox[0.5cm]{$\bicount_p$:} Para todo grafo bipartito $H$ con %partición de vértices $S\cup T$, el número de copias etiquetadas de %$H$ en $G_n$ mapeando $S$ en $U$, y $T$ en $W$ es:
%        \[
%            \left( p^{e_H} + o(1)\right)|U|^{|S|}|W|^{|T|}.
%        \]
%
%        % BI-COUNT C4
%        \item[\makebox[0.5cm]{$\bicount_{C_4, p}$:} La cantidad de copias %etiquetadas de caminatas cerradas de largo 4 en $G_n$ comenzando en %$U$ es:
%        \[
%            \left( p^{4} + o(1)\right)|U|^{2} |W|^{2}.
%        \]
%
%        % IZQ-CODEG
%        \item[\makebox[0.5cm]{$\izcodeg_p$:} 
%        \[
%            \sum_{u,v\in U} \Big| \cod(u,v) - p^{2}|W|\Big| = o(|U|^{2}|W|).
%        \]
%
%        % DER-CODEG
%        \item[\makebox[0.5cm]{$\dercodeg_p$:}
%        \[
%            \sum_{u,v\in W} \Big| \cod(u,v) - p^{2}|U|\Big| = o(|U||W|^{2}).
%        \]
%
%        % BI-EIG
%        \item[\makebox[0.5cm]{$\bieig_p$:} Sean $\lambda_1 \geq \lambda_2 %\geq ...\geq \lambda_n$ los autovalores asociados a la matriz de %adyacencia del grafo $G_n$, entonces
%        \[
%            \lambda_1 = (p + o(1))\sqrt{|U||W|}\ \ \text{,}\ \ \ %\displaystyle\max_{i\not= 1}|\lambda _{i}| = o(\sqrt{|U||W|}).
%        \]
%    \end{enumerate}
%\end{teorema}\medskip
%
%Veremos que existe una relación directa entre los Teoremas \ref{Teorema CGW} y %\ref{Teorema CGW Bipartito} por medio de un determinado producto tensor entre %grafos.\medskip
%
%%%%% Definición: Producto tensor
%\begin{definicion}
%    Dado los grafos $G$ y $H$, el \textbf{producto tensor} $G\times H$ es un %grafo tal que:
%    \begin{itemize}
%        \item[i)] El conjunto de vértices del grafo $G\times H$ es el producto %cartesiano $V(G)\times V(H)$, y
%        \item[ii)] los vértices $(g,h)$ y $(g',h')$ son adyacentes en $G\times %H$ si y solo si $g$ es adyacente con $h$ en $G$, y $g'$ es adyacente %con $h'$ en $H$.
%    \end{itemize}
%\end{definicion}\medskip
%
%Observe que el producto tensor de todo grafo $G$ con el grafo completo $K_2$ %transforma a $G$ en un grafo bipartito. Dicha transformación es conocida como %el \textbf{cubrimiento doble bipartito} de $G$. Por ejemplo, si consideramos %los grafos $G = (\lbrace u,v,w\rbrace, \lbrace uv, uw, vw\rbrace)$ y $K_2 = %(\lbrace 0,1\rbrace, \lbrace 01\rbrace)$, el producto tensor resultante %es\medskip
%\begin{equation*}
%    G\times K_2 = \left(
%    \left\lbrace
%        \begin{array}{c}
%             (u,0) , (u,1)\\
%             (v,0) , (v,1)\\
%             (w,0) , (w,1)
%        \end{array}
%    \right\rbrace,
%    \left\lbrace
%        \begin{array}{c}
%            (u,0)(v,1) , (u,1)(v,0)\\
%            (u,0)(w,1) , (u,1)(w,0)\\
%            (v,0)(w,1) , (v,1)(w,0)
%        \end{array}
%    \right\rbrace
%    \right).
%\end{equation*}\medskip
%
%Con la observación anterior es posible demostrar que todo grafo $G$ satisface %cada propiedad del Teorema \ref{Teorema CGW} si y solo si $G\times K_2$ %satisface su respectiva propiedad bipartita del Teorema \ref{Teorema CGW %Bipartito}.

Finalmente, se explora un caso siempre interesante de estudio, ya que simplifica varios cálculos y surge de manera recurrente en la vida cotidiana: un grafo $d$-regulrar. En nuestro contexto, se verá que toda secuencia $(G_n)_{n\to \infty}$ de grafos $d$-regular satisface la propiedad $\disc_{\frac{d}{n}}$ si y solo si cumple con $\eig_{\frac{d}{n}}$. Dicha equivalencia nace como una consecuencia del siguiente teorema.\medskip

%%%% Enunciado Expander Mixing Lemma
\begin{teorema} \label{Expander Mixing Lemma} (Expander Mixing Lemma)
    Sea $G = ([n], E)$ un grafo $d$-regular, y $d=\lambda_1 \geq \lambda_2\geq...\geq\lambda_n$ los valores propios asociados a la matriz de adyacencia $A$ de $G$. Se denota:\medskip

    \[
        \lambda = \max_{i\not= 1}|\lambda_i|.
    \]\medskip

    Entonces, para cada $X,Y\subset [n]$,\medskip

    \begin{equation} \label{resultado EML}
        \left| e(X,Y) - \frac{d}{n}|X||Y|\right| \leq \lambda \sqrt{|X||Y|\left( 1 - \frac{|X|}{n}\right)\left( 1 - \frac{|Y|}{n}\right)}.
    \end{equation}
\end{teorema}\medskip

%%%% Demostración Expander Mixing Lemma
\begin{proof}
    Sea $\mathcal{B} = \lbrace v_1,...,v_n\rbrace$ la base ortonormal de $\mathbb{R}^{n}$ compuesta por los vectores propios de $A$. Utilizando la descomposición espectral, se denota\medskip

    \begin{equation*}
        A_1 = \lambda_1 v_1 v_{1}^{T}\ \ \text{y}\ \ \Delta = \sum_{i=2}^{n} \lambda_i v_i v_{i}^{T},
    \end{equation*}\medskip

    de manera que $A = A_1 + \Delta$.\medskip
    
    Coforme a la ecuación \eqref{e(X,Y)=espectral}, para todo $X,Y\subset [n]$, se cumple la siguiente igualdad:\medskip

    \begin{equation} \label{1ra ec EML}
        e(X,Y) = v_{X}^{T} A v_Y = v_{X}^{T} A_1 v_Y + v_{X}^{T} \Delta v_Y.
    \end{equation}\medskip

    De la ecuación anterior se espera que el primer sumando sea el término principal, mientras que el segundo el factor de error. Para esto, se representan los vectores $v_X$ y $v_Y$ según la base $\mathcal{B}$. Es decir,\medskip

    \begin{equation*}
        v_X = \sum_{i=1}^{n} \alpha_i v_i\ \ \text{y}\ \ v_Y = \sum_{i=1}^{n} \beta_i v_i,
    \end{equation*}\medskip

    donde $\alpha_i = v_{X}^{T}v_i$ y $\beta_i = v_{Y}^{T} v_i$. Con esto, se calcula:\medskip

    \begin{align*}
        \norm{\alpha_i}^{2} &= \sum_{i=1}^{n}\alpha_{i}^{2}\\
        &= \sum_{i=1}^{n} \langle v_X, v_i\rangle^{2}\\
        &= \sum_{i=1}^{n} \langle \sum_{j\in X}\mathbbm{1}_{j}, v_i\rangle^{2}\\
        &= \sum_{i=1}^{n}\sum_{j=1}^{n} \langle \mathbbm{1}_{j}, v_i\rangle^{2}\mathbbm{1}_{X}(i)\\
        &= \sum_{i=1}^{n} \norm{v_i}^{2}\mathbbm{1}_{X}(i)\\
        &= |X|.
    \end{align*}\medskip

    Análogamente, $\norm{\beta_i}^{2} = \sum_{i=1}^{n} \beta_{i}^{2} = |Y|$.\medskip

    Ahora, se estudian los sumandos de la igualdad \eqref{1ra ec EML} por separado. Por un lado,\medskip

    \begin{equation} \label{1er sumando EML}
        \begin{split}
            v_{X}^{T} A_1 v_Y &= \left( \sum_{i=1}^{n}\alpha_i v_i\right)^{T}\left( \lambda_1 v_1 v_{1}^{T}\right)\left( \sum_{j=1}^{n} \beta_j v_j\right)\\
            &= \lambda_1 \left( \sum_{i=1}^{n} \alpha_i v_{i}^{T}\right)\left( v_1 v_{1}^{T}\right)\left( \sum_{j=1}^{n}\beta_j v_j\right)\\
            &= \lambda_1 \sum_{i=1}^{n}\sum_{j=1}^{n} \alpha_i \beta_j \left( v_{i}^{T} v_1\right)\left(v_{1}^{T} v_j \right)\\
            &= \lambda_1\alpha_1\beta_1 .
        \end{split}
    \end{equation}\medskip

    Por otro lado, de la misma manera que el cálculo anterior,\medskip

    \begin{equation} \label{2do sumando EML}
        v_{X}^{T} \Delta v_Y = \left( \sum_{i=1}^{n}\alpha_i v_i\right)^{T}\left( \sum_{j=2}^{n}\lambda_j v_j v_{j}^{T}\right) \left( \sum_{k=1}^{n} \beta_k v_k\right) = \sum_{i=1}^{n}\lambda_i\alpha_i\beta_i .
    \end{equation}\medskip

    Luego, dado que $G$ es un grafo $d$-regular, $\lambda_1 = d$ y $v_1 = \frac{1}{\sqrt{n}}(1,...,1)^{T}$ son valor y vector propio respectivamente de $A$. En consecuencia,\medskip

    \begin{equation*}
        \alpha_1 = \frac{|X|}{\sqrt{n}}\ \ \text{y}\ \ \beta_1 = \frac{|Y|}{\sqrt{n}}.
    \end{equation*}\medskip

    Así, la ecuación \eqref{1er sumando EML} resulta en $v_{X}^{T} A_1 v_Y = \frac{d}{n}|X||Y|$.\medskip

    Para el término de error, recordando la definición de $\lambda$, se desarrolla el valor absoluto de la ecuación \eqref{2do sumando EML} usando la desigualdad de Cauchy-Schwarz.\medskip

    \begin{align*}
        \left| v_{X}^{T} \Delta v_Y\right| &= \left| \sum_{i=2}^{n} \lambda_i\alpha_i\beta_i \right|\\
        &\leq \lambda \left| \sum_{i=2}^{n} \alpha_i\beta_i \right|\\
        &\overset{\mathrm{CS}}{\leq} \lambda \sqrt{\sum_{i=2}^{n}\alpha_{i}^{2} \sum_{i=2}\beta_{i}^{2}}\\
        &= \lambda \sqrt{\left( \norm{\alpha_i}^{2} - \alpha_{1}^{2}\right)\left( \norm{\beta_i}^{2} - \beta_{1}^{2}\right)}\\
        &= \lambda \sqrt{|X||Y|\left( 1- \frac{|X|}{n} \right)\left( 1 - \frac{|Y|}{n} \right)}.
    \end{align*}\medskip

    Finalmente, el resultado se obtiene directamente de tomar el valor absoluto de la ecuación \eqref{1ra ec EML} de la siguiente manera:\medskip

    \[
        \left| e(X,Y) - v_{X}^{T}A_1 v_Y\right| = \left| v_{X}^{T}\Delta v_Y\right|.
    \]
\end{proof}\medskip

El teorema anterior permite asegurar que todo grafo $d$-regular $G = ([n],E)$ con un conjunto de vértices suficientemente grande que satisface la propiedad $\eig_{\frac{d}{n}}(\delta)$, también cumple con $\disc_{\frac{d}{n}}(\varepsilon)$. En efecto, para todo $\varepsilon > 0$ y $X,Y\subset [n]$, elija $n_0\in\mathbb{N}$ suficientemente grande y $\delta < \frac{\varepsilon n}{\sqrt{|X||Y|}}$. Entonces, si $G$ satisface la propiedad $\eig_{\frac{d}{n}}(\delta)$, por el Teorema \ref{Expander Mixing Lemma}:\medskip

\begin{align*}
    \left| e(X,Y) - \frac{d}{n}|X||Y| \right| &\leq \lambda \sqrt{|X||Y|\left( 1 - \frac{|X|}{n}\right)\left( 1 - \frac{|Y|}{n}\right)}\\
    &< \delta n\sqrt{|X||Y|}\\
    &< \varepsilon n^{2}.
\end{align*}\medskip

Finalmente, en un grafo $d$-regular, la equivalencia entre las propiedades $\eig_{\frac{d}{n}}$ y $\disc_{\frac{d}{n}}$ se completa por el camino de implicancias ya demostradas según el esquema \eqref{Ciclo demo CGW}.\medskip

\section{Lema de regularidad de Szemerédi} \label{Sec. LRS}

\hh{Aquí debo ingresar una breve descripción del lema de regularidad de Szemerédi y la fuerza que toma al combinarlo con el teorema de Chung-Graham-Wilson y comentar la aplicación que se mostrará. (Quizás también hablar de las dos demostraciones de este lema, usual y espectral.)}

\subsection{Enunciado y demostración}\medskip

Se tratará el concepto de regularidad de una manera un poco diferente a como es tradicionalmente conocida. En particular, se permite intersección entre pares de subconjuntos de vértices de un grafo en las futuras definiciones.\medskip

%%%% Definición par \varepsilon - regular
\begin{definicion}
    Sea $G$ un grafo y $X,Y \subset V(G)$ subconjuntos no necesariamente disjuntos. Diremos que $(X,Y)$ es un \textbf{par $\varepsilon$-regular} en $G$ si para todo $A\subset X$ y $B\subset Y$ con $|A| \geq \varepsilon |X|$ y $|B|\geq \varepsilon |Y|$, se cumple\medskip

    \[
    \Big| d(A,B) - d(X,Y)\Big| \leq \varepsilon
    \]\medskip

    Cuando $(X,Y)$ no es un par $\varepsilon$-regular, entonces la irregularidad es evidenciada por algún $A\subseteq X$ y $B\subseteq Y$ que satisfacen $|A| \geq \varepsilon |X|$ y $|B|\geq \varepsilon |Y|$, pero $\Big| d(A,B) - d(X,Y)\Big| > \varepsilon$.
\end{definicion}\medskip

Notaremos que la noción de un par $\varepsilon$-regular es, de hecho, una analogía de la propiedad $\disc_p(\varepsilon)$ para grafos bipartitos. Es decir, si $G$ es tal que $V(G) = U\cup W$ y $p\in (0,1)$, se cumple\medskip

\begin{equation} \label{BIDISC}
    \Big| e(X,Y) - p|X||Y|\Big| = o(|U||W|)\ ,\ \forall X\subset U,\ \forall Y\subset W.
\end{equation}\medskip

En efecto, si $(U,W)$ es un par $\varepsilon$-regular, entonces todo $A\subset U$ y $B\subset W$ tales que $|A|\geq\varepsilon |U|$ y $|B|\geq\varepsilon |W|$ satisfacen\medskip

\begin{align*}
    e(A,B) = d(U,W)|A||B| \pm \varepsilon|A||B| = d(U,W)|A||B| \pm \varepsilon|U||W|.
\end{align*}\medskip

Ahora bien, si al menos uno de los subconjuntos de la condición de un par $\varepsilon$-regular no es suficientemente grande, digamos $|A| < \varepsilon|X|$, entonces\medskip

\begin{align*}
    d(U,W)|A||B| - \varepsilon |U||W| < 0 \leq e(A,B) \leq |A||B| \leq \varepsilon |U||W| < d(U,W)|A||B| + \varepsilon|U||W|.
\end{align*}\medskip

De esta manera, tomando $p = d(U,W)$, se obtiene la analogía planteada.\medskip

Por otro lado, con el espíritu del Teorema \ref{Teorema CGW}, es posible expresar un resultado análogo a la propiedad $\Count_p(\varepsilon)$ utilizando el concepto de par $\varepsilon$-regular. Dicho resultado, para $H=K_3$ es conocido como el lema de conteo de triángulos.\medskip

%%%% Lema: Lema de conteo de triángulos
\begin{lema} \label{Triangle_Counting_Lemma} (Lema de conteo de triángulos)
    Sea $\varepsilon > 0$, $G = (V,E)$ un grafo, y los conjuntos no necesariamente disjuntos $X,Y,Z\subset V$ tales que los pares $(X,Y), (Y,Z)$ y $(X,Z)$ son $\varepsilon$-regular. Entonces,\medskip

    \begin{equation*}
        |\lbrace (x,y,z)\in X\times Y\times Z : xy,xz,yz\in E\rbrace| = d(X,Y)d(X,Z)d(Y,Z)|X||Y||Z| \pm 3\varepsilon |X||Y||Z|.
    \end{equation*}
\end{lema}\medskip

%%%% Demostración Teorema: Lema de conteo de triángulos
\begin{proof}
    Se realizará un proceso inductivo similar al visto en la demostración de la Proposición \ref{discp => count} sobre la cantidad de aristas del grafo $K_3 = ([3], \lbrace 12, 23, 13\rbrace)$. Cuando el grafo no posee aristas, entonces\medskip
    
    \begin{equation*}
        |\lbrace (x,y,z)\in X\times Y\times Z : xy,xz,yz\not\in E\rbrace| = |X||Y||Z|.
    \end{equation*}\medskip

    También, recordando que la condición de un par $\varepsilon$-regular es equivalente a $\bidisc_p (\varepsilon)$ para algún $p\in(0,1)$, cuando el grafo presenta una arista,\medskip
    
    \begin{equation*}
        |\lbrace (x,y,z)\in X\times Y\times Z : xy\in E\rbrace| = \left( d(X,Y)|X||Y| \pm \varepsilon|X||Y| \right)|Z|.
    \end{equation*}\medskip

    Ahora, se plantea la hipótesis inductiva de la siguiente manera:\medskip
    
    \begin{equation*}
        |\lbrace (x,y,z)\in X,Y,Z : xy,yz\in E\rbrace| = d(X,Y)d(Y,Z)|X||Y||Z| \pm 2\varepsilon |X||Y||Z|.
    \end{equation*}\medskip

    Defina  $e^{-} = \varphi(1)\varphi(3)$, y $T^{-}$ como el grafo correspondido a una copia etiquetada del grafo $([3],\lbrace 12,23\rbrace)$ en $G$ bajo la apliación inyectiva $\varphi : [3]\to V(T^{-})\subset V$. Con esto, se desarrolla inductivamente como sigue:\medskip
    
    \begin{align} \label{2doSum_TCL}
        |\lbrace (x,y,z)\in X\times Y\times Z : xy,yz,xz\in E\rbrace| &= \sum_{T^{-}} \left[ \mathbbm{1}_{E}(e^{-}) + d(X,Z) - d(X,Z) \right]\nonumber \\
        &= d(X,Y)d(Y,Z)d(X,Z)|X||Y||Z| \nonumber\\
        &\ \ \ + \sum_{T^{-}} \left( \mathbbm{1}_{E}(e^{-}) - d(X,Z)\right) \pm 2\varepsilon |X||Y||Z|.
    \end{align}\medskip

    En este punto, nos falta probar que el segundo sumando de la igualdad \eqref{2doSum_TCL} se corresponde con un factor de error, para esto, sea $T^{*}$ una copia del grafo singleton $\lbrace 2\rbrace$ en $G$, y considere los siguientes conjuntos:\medskip
    
    \[
        A_{1}^{T^{*}} = \lbrace x\in X: T^{*} \text{ con } x \text{ forma una copia de } (\lbrace 1,2\rbrace, \lbrace 12\rbrace) \text{ en } G\rbrace.
    \]
    \[
        A_{3}^{T^{*}} = \lbrace z\in Z: T^{*} \text{ con } z \text{ forma una copia de } (\lbrace 2,3\rbrace, \lbrace 23\rbrace) \text{ en } G\rbrace.
    \]\medskip

    De esta manera, dada la equivalencia de la condición del par $(X,Z)$ $\varepsilon$-regular con versión bipartita de la propiedad $\disc_{d(X,Z)}(\varepsilon)$ vista en \eqref{BIDISC}, se consigue la siguiente desigualdad:\medskip
    
    \begin{align*}
        \left| \sum_{T^{-}} \left( \mathbbm{1}_{E}(e^{-})\right) - d(X,Z)\right| &\leq \sum_{T^{*}} \left| \sum_{f\in A_{1}^{T^{*}}\times A_{3}^{T^{*}}} \left( \mathbbm{1}_{E}(f) - d(X,Z)\right)\right|\\
        &= \sum_{T^{*}} \left| e(A_{1}^{T^{*}}, A_{3}^{T^{*}}) - d(X,Z)|A_{1}^{T^{*}}||A_{3}^{T^{*}}|\right|\\
        &\leq \sum_{T^{*}} \varepsilon |X||Z|\\
        &\leq \varepsilon |X||Y||Z|.
    \end{align*}\medskip

    Finalmente, aplicando la última desigualdad en la ecuación \eqref{2doSum_TCL} se prueba lo prometido.
\end{proof}\medskip

En la demostración anterior solo fue necesario utilizar que los pares $(X,Y)$ y $(X,Z)$ son $\varepsilon$-regular, por lo que es interesante destacar que uno de los pares de conjuntos de vértices podría no ser necesariamente un par $\varepsilon$-regular para el que lema de conteo de triángulos funcione correctamente.\medskip

Bajo el mismo planteamiento de la inducción vista en la demostración del Lema \ref{Triangle_Counting_Lemma} (y Proposición \ref{discp => count}), es posible generalizar el resultado para contar apropiadamente cualquier grafo $H$. Se enuncia sin demostración.\medskip

%%%% Teorema: Lema de conteo de grafos
\begin{lema} \label{Lema_Conteo_Grafos} (Lema de conteo de grafos)
    Sea $\varepsilon > 0$, $H$ un grafo sobre $k$ vértices, y $G$ un grafo de $n$ vértices con los subconjuntos disjuntos $V_1 ,..., V_k\subset V(G)$ tales que los pares $(V_i, V_j)$ son $\varepsilon$-regular siempre que $ij\in E(H)$. Entonces, la cantidad de tuplas $(v_1,...,v_k)\in V_1\times\cdots\times V_k$ tales que $v_i v_j\in E(G)$ cada vez que $ij\in E(H)$ es\medskip
    
    \begin{equation*}
        \left( \prod_{ij\in E(H)} d(V_i, V_j)\right) \left( \prod_{\ell=1}^{k}|V_{\ell}|\right) \pm e_H\cdot \varepsilon \prod_{\ell = 1}^{k}|V_{\ell}|.
    \end{equation*}
\end{lema}\medskip

%Una consecuencia interesante de la definición anterior, es que la mayoría de los vértices tienen aproximadamente el mismo grado. Plasmamos este hecho en la siguiente proposición.\medskip
%
%%%%% Proposición: consecuencia grado par \epsilon regular
%\begin{prop} \label{consc_par_regular}
%    Sea $G$ un grafo y $X,Y\subset V(G)$ subconjuntos de vértices tales que $(X,Y)$ es un par $\varepsilon$-regular. Entonces menos de $\varepsilon |X|$ vértices en $X$ tienen menos de $(d(X,Y) - \varepsilon)|Y|$ vecinos en $Y$. De igual manera, menos de $\varepsilon |Y|$ vértices en $Y$ poseen menos de $(d(X,Y) - \varepsilon)|X|$ vecinos en $X$.
%\end{prop}
%
%%%%% Demostración: consecuencia grado par \epsilon regular
%\begin{proof}
%    Suponga que existe un conjunto $A\subset X$ con al menos $\varepsilon |X|$ vértices y que posee menos de $(d(X,Y) - \varepsilon)|Y|$ vecinos en $Y$. Esto significa que se satisface,
%    \[
%        d(A,Y)|Y| < (d(X,Y) - \varepsilon)|Y|.
%    \]
%    Se sigue directamente que $|d(X,Y) - d(A,Y)| > \varepsilon$, contradiciendo la hipótesis del par $\varepsilon$-regular. La otra afirmación es completamente análoga.
%\end{proof}\medskip
%
%\hh{Escribo también la negación?, es decir, más de $\varepsilon |X|$ vértices tienen a lo más $(d(X,Y) + \varepsilon)|Y|$ vecinos.}

Ya conociendo el concepto de regularidad entre pares de subconjuntos de vértices, estudiamos la regularidad en una partición del conjunto de vértices del grafo.\medskip

%%%% Definición partición \varepsilon - regular
\begin{definicion}
    Dado un grafo $G$, una partición $\mathcal{P} = \lbrace V_1,...,V_{k}\rbrace$ del conjunto de vértices $V(G)$ es una \textbf{partición $\varepsilon$-regular} si\medskip

    \[
    \sum_{\substack{ (i,j)\in [k]^{2} \\ (V_{i}, V_{j})\ \mathrm{no}\ \varepsilon-\mathrm{regular}}} |V_i||V_j| \leq \varepsilon |V(G)|^{2}.
    \]\medskip

    Es decir, todos los pares de subconjuntos de vértices en la partición son $\varepsilon$-regular salvo una fracción $\varepsilon$ de pares de vértices.

    %% Ojo: Descomentar si quiero incorporar el conjunto excepcional.
    %Más aún, si consideramos una partición $\mathcal{P} = \lbrace V_0, V_1,...,V_k\rbrace$ del conjunto de vértices $V(G)$, en donde $V_0$ es un conjunto excepcional (podría ser vacío), diremos que es una partioción $\varepsilon$-regular  de $G$ si satisface las siguientes condiciones:
    %\begin{enumerate}
    %    \item[i)] $|V_0| \leq \varepsilon |V(G)|$.
    %    \item[ii)] $|V_1| = \cdots = |V_k| = \frac{k}{n}$.
    %    \item[iii)] $\Big| (i,j)\in [k]^{2} : 1\leq i < j \leq k\ \text{y}\ (V_i, V_j)\ \text{no es par}\ \varepsilon\text{-regular}\Big| \leq \varepsilon k^{2}$. 
    %\end{enumerate}
\end{definicion}\medskip
%El papel que juega el subconjunto $V_0$ es únicamente por conveniencia; permite que los otros elementos de la partición posean exactamente el mismo tamaño.
%\hh{Vale la pena incluir el conjunto excepcional para obtener el resultado del lema de regularidad en partes del mismo tamaño?, ¡desarrollaré la demostración sin utilizar este conjunto de primeras!!}

Note que si una partición $\varepsilon$-regular de $k$ partes es en particular una equipartición, entonces a lo más $\varepsilon k^{2}$ pares de elementos de la partición no son $\varepsilon$-regular.\medskip

Ya con todo lo necesario, se introduce el lema de regularidad de Szemerédi. Intuitivamente, el lema permite particionar el conjunto de vértices de todo grafo en una cantidad finita de partes, satisfaciendo que la mayoría de sus pares de partes son $\varepsilon$-regular. Enunciamos el célebre lema, y se dará prueba formal más adelante.\medskip

%%%% Enunciado Lema de regularidad de Szemerédi
\begin{teorema} \label{szemeredi_regularity_lemma} (Lema de regularidad de Szemerédi)
    Para todo $\varepsilon > 0$, existe un entero $M = M(\varepsilon)$ tal que todo grafo admite una partición $\varepsilon$-regular de a lo más $M$ partes.
\end{teorema}\medskip

Para dar prueba a este teorema, se utilizará una técnica llamada \emph{argumento de incremento de energía}. Para todo grafo $G$, la técnica funciona algorítmicamente de la siguiente manera:\medskip

%%%% Algoritmo incremento de energía
\begin{enumerate}
    \item Comenzar con la partición trivial de $V(G)$, i.e, $\mathcal{P} = \lbrace V(G)\rbrace$.

    \item Mientras la partición actual $\mathcal{P}$ no es $\varepsilon$-regular:
    \begin{itemize}
        \item[(a)] Para cada par $(V_i, V_j)$ no $\varepsilon$-regular, encontrar los subconjuntos $A^{ij}\subset V_i$ y $A^{ji}\subset V_j$ que evidencian la irregularidad de cada par.

        \item[(b)] \label{Paso 2b} Refinar $\mathcal{P}$ utilizando simultáneamente los conjuntos $A^{ij}$ y $A^{ji}$ encontrados de cada par $(V_i, V_j)$ no $\varepsilon$-regular para obtener $\mathcal{Q}$. 

        \item[(c)] Actualizar $\mathcal{P}$ con $\mathcal{Q}$. 
    \end{itemize}
\end{enumerate}\medskip

Siendo $\mathcal{P}$ y $\mathcal{Q}$ dos particiones de un mismo conjunto de vértices, diremos que $\mathcal{Q}$ refina a $\mathcal{P}$ si cada parte de $\mathcal{Q}$ está contenida en una parte de $\mathcal{P}$. En lo que resta de esta sección mostraremos que el algoritmo tiene un fin, y que entrega una partición $\varepsilon$-regular en un número de iteraciones que solo depende de $\varepsilon$.\medskip

%%%% Definición Energía 
\begin{definicion} (Energía)
    Sea $G$ un grafo sobre $n$ vértices y $X,Y\subset V(G)$. Se define en primer lugar\medskip

    \[
    q(X,Y) := \frac{|X||Y|}{n^{2}}d(X,Y)^{2} = \frac{e(X,Y)^{2}}{n^{2}|X||Y|}.
    \]\medskip

    Luego, para particiones $\mathcal{P}_{X} = \lbrace X_1,...,X_k\rbrace$ de $X$ y $\mathcal{P}_{Y} = \lbrace Y_1,...,Y_\ell\rbrace$ de $Y$, se define\medskip

    \[
    q(\mathcal{P}_{X}, \mathcal{P}_{Y}) := \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} q(X_i, Y_j).
    \]\medskip

    Finalmente, para una partición $\mathcal{P} = \lbrace V_1,...,V_k \rbrace$, se define la \textbf{energía} mediante\medskip

    \[
    q(\mathcal{P}) := \sum_{i = 1}^{k}\sum_{j = 1}^{k}q(V_i, V_j) = \sum_{i = 1}^{k}\sum_{j = 1}^{k} \frac{|V_i||V_j|}{n^{2}}d(V_i, V_j)^{2}. 
    \]
\end{definicion}\medskip

Observe que en toda partición $\mathcal{P}$ de $V(G)$, siempre se tendrá que $0\leq q(\mathcal{P}) \leq 1$. En efecto,\medskip

\begin{align*}
    q(\mathcal{P}) &= \sum_{i = 1}^{k}\sum_{j = 1}^{k}\frac{|V_i||V_j|}{n^{2}}d(V_i,V_j)^{2}\\
    &\leq \frac{1}{n^{2}}\sum_{i = 1}^{k}|V_i|\sum_{j = 1}^{k}|V_j|\\
    &= 1.
\end{align*}\medskip

La última observación es crucial en la demostración del Teorema \ref{szemeredi_regularity_lemma}, puesto que los Lemas \ref{energia_no_decrece}, \ref{Energy boost un conjunto} y \ref{Energy boost particiones} nos asegurarán que la energía de una partición nunca decrece bajo refinamiento. Por consecuencia, el algoritmo de la técnica \emph{argumento de incremento de energía} tendrá un fin, entregando una partición $\varepsilon$-regular.\medskip

El siguiente lema muestra que la energía no disminuye al particionar o refinar arbitrariamente un conjunto o partición respectivamente.\medskip

%%%% Lema: la energía nunca decrece bajo refinamiento
\begin{lema} \label{energia_no_decrece}
    Sea $G$ un grafo, $X,Y\subset V(G)$, $\mathcal{P}_{X}$ y $\mathcal{P}_{Y}$ particiones de $X$ e $Y$ respectivamente, entonces $q(\mathcal{P}_{X}, \mathcal{P}_{Y}) \geq q(X,Y)$. Además, dadas dos particiones de vértices $\mathcal{P}$ y $\mathcal{P'}$ de $G$, $q(\mathcal{P}) \leq q(\mathcal{P'})$ cada vez que $\mathcal{P'}$ refina a $\mathcal{P}$. 
\end{lema}\medskip

%%%% Demostración nueva lema: la energía nunca decrece bajo refinamiento}
\begin{proof}
    Considere un grafo $G$ sobre $n$ vértices, los conjuntos $X,Y\subset V(G)$, y las particiones $\mathcal{P}_{X} = \lbrace X_1,...,X_k\rbrace$ y $\mathcal{P}_{Y} = \lbrace Y_1,...,Y_\ell\rbrace$ de $X$ e $Y$ respectivamente. En primera instancia, se utiliza la desigualdad \eqref{Desigualdad_from_CS} para probar que $q(\mathcal{P}_{X}, \mathcal{P}_{Y}) \geq q(X,Y)$. Para esto, se desarrolla como sigue:\medskip

    \begin{equation} \label{q(P_X,P_Y) >= q(X,Y)}
        \begin{split}
            q(\mathcal{P}_{X}, \mathcal{P}_{Y}) &= \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} q(X_{i}, Y_{j})\\
            &= \frac{1}{n^{2}} \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} \frac{e(X_i,Y_j)^{2}}{|X_i||Y_j|}\\
            &\overset{\eqref{Desigualdad_from_CS}}{\geq} \frac{1}{n^{2}}\frac{\left( \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} e(X_i,Y_j)\right)^{2}}{\sum_{i = 1}^{k}\sum_{j = 1}^{\ell} |X_i||Y_j|}\\
            &= \frac{1}{n^{2}} \frac{e(X,Y)^{2}}{\left( \sum_{i = 1}^{k} |X_i| \right)\left( \sum_{j = 1}^{\ell} |Y_j|\right)}\\
            &= \frac{e(X,Y)^{2}}{n^{2}|X||Y|}\\
            &= q(X,Y).    
        \end{split}
    \end{equation}\medskip

    Sea ahora la partición $\mathcal{P} = \lbrace V_1,...,V_k\rbrace$ de $V(G)$ y $\mathcal{P}' = \lbrace \mathcal{P}'_{V_1},...,\mathcal{P}'_{V_k}\rbrace$ un refinamiento de $\mathcal{P}$. Entonces, se utiliza el resultado probado previamente para completar el resultado:\medskip

    \begin{equation*}
        q(\mathcal{P}) = \sum_{i=1}^{k}\sum_{j=1}^{k} q(V_i,V_j) \overset{\eqref{q(P_X,P_Y) >= q(X,Y)}}{\leq} \sum_{i=1}^{k}\sum_{j=1}^{k} q(\mathcal{P}'_{V_i}, \mathcal{P}'_{V_j}).
    \end{equation*}
\end{proof}\medskip

%%%% Demostración antigua lema: la energía nunca decrece bajo refinamiento
%\begin{proof} \hh{Antigua}
%    Consideramos un grafo $G$ sobre $n$ vértices, los conjuntos $X,Y\subset V(G)$, y las particiones $\mathcal{P}_{X} = \lbrace X_1,...,X_k\rbrace$ y $\mathcal{P}_{Y} = \lbrace Y_1,...,Y_\ell\rbrace$ de $X$ e $Y$ respectivamente. Vamos a definir una variable aleatoria $Z$ seleccionando vértices $x\in X$ e $y\in Y$ independientemente y siguiendo una distribución uniforme. Supondremos entonces que $X_i \in \mathcal{P}_{X}$ e $Y_j \in \mathcal{P}_{Y}$ son aquellos elementos de las particiones que contienen a $x$ e $y$ respectivamente, y con ello, establecemos la variable aleatoria $Z := d(X_i, Y_j)$.
%
%    Estudiaremos los dos primeros momentos de $Z$,
%    \begin{align} \label{primer_momento_Z}
%        \mathbb{E}[Z] &= \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} \frac{|X_i|}{|X|}\frac{|Y_j|}{|Y|}d(X_i, Y_j) \nonumber\\
%        &= \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} \frac{e(X_i, Y_j)}{|X||Y|}\\
%        &= d(X,Y) = \sqrt{\frac{n^{2}}{|X||Y|} q(X,Y)}. \nonumber
%    \end{align}
%
%    También, 
%    \begin{equation} \label{segundo_momento_Z}
%        \mathbb{E}[Z^{2}] = \sum_{i = 1}^{k}\sum_{j = 1}^{\ell} \frac{|X_i|}{|X|}\frac{|Y_j|}{|Y|}d(X_i,Y_j)^{2} = \frac{n^{2}}{|X||Y|}q(\mathcal{P}_X, \mathcal{P}_Y).
%    \end{equation}
%
%    Así, producto de la desigualdad de Jensen utilizando la función convexa $f(x) = x^{2}$ vista en \ref{Jensen_implicación}, tendremos que $\mathb{E}[Z^{2}]\geq \mathbb{E}[Z]^{2}$ implica directamente que $q(\mathcal{P}_X, \mathcal{P}_Y) \geq q(X,Y)$.
%
%    Por otro lado, elegimos una partición $\mathcal{P} = \lbrace V_1,...,V_k\rbrace$ de $V(G)$ y suponemos que $\mathcal{P'}$ refina a cada elemento $V_i\in \mathcal{P}$ en una nueva partición $\mathcal{P'}_{V_i} = \lbrace V'_{i_1},...,V'_{i_m}\rbrace$, de tal forma que $\mathcal{P'} = \mathcal{P'}_{V_1}\cup \cdots \cup \mathcal{P'}_{V_k}$. Entonces, si aplicamos el resultado recien probado sobre cada elemento de $\mathcal{P}$,
%    \begin{equation*}
%        q(\mathcal{P}) = \sum_{i = 1}^{k}\sum_{j = 1}^{k} q(V_i,V_j) \leq \sum_{i = 1}^{k}\sum_{j = 1}^{k} q(\mathcal{P'}_{V_i}, \mathcal{P'}_{V_j}) = q(\mathcal{P'}).
%    \end{equation*}
%\end{proof}

Ahora, veremos que refinar un par $(X,Y)$ no $\varepsilon$-regular de un grafo $G$, mediante los subconjuntos que evidencian su irregularidad, provoca un aumento estricto en la energía.\medskip

%%%% Lema: Energy Boost
\begin{lema} \label{Energy boost un conjunto}
    Sea $\varepsilon > 0$, $G$ un grafo de $n$ vértices y $X,Y\subset V(G)$. Si $(X,Y)$ no es un par $\varepsilon$-regular, existen particiones $\mathcal{P}_{X} = \lbrace X_1, X_2\rbrace$ de $X$ y $\mathcal{P}_{Y} = \lbrace Y_1, Y_2\rbrace$ de $Y$ tales que\medskip

    \[
        q(\mathcal{P}_{X}, \mathcal{P}_{Y}) > q(X,Y) + \varepsilon^{4}\frac{|X||Y|}{n^{2}}.
    \]
\end{lema}\medskip

%%%% Demostración Energy boost
\begin{proof}
    Dado $\varepsilon > 0$, considere el grafo $G$ sobre $n$ vértices y $X,Y\subset V(G)$ subconjuntos tales que el par $(X,Y)$ no es $\varepsilon$-regular. Entonces, existen los subconjuntos $X_1 \subset X$ e $Y_1 \subset Y$ que evidencian la irregularidad del par $(X,Y)$, y son tales que\medskip

    \begin{equation} \label{condición tamaño conjunto regularidad}
        |X_1| \geq \varepsilon |X|\ \ \text{y}\ \ |Y_1| \geq \varepsilon |Y|.
    \end{equation}\medskip
    
    Se define adicionalmente los conjuntos $X_2 := X\setminus X_1$, $Y_2 := Y\setminus Y_1$, y $\eta := d(X_1, Y_1) - d(X,Y)$, cual por definición de par $\varepsilon$-regular, satisface\fs{Aquí quedé}\medskip

    \begin{equation} \label{|eta| > epsilon}
        \left| \eta\right| > \varepsilon.
    \end{equation}

    Por un lado, observe la siguiente descomposición,
    \begin{align*}
        e(X,Y) &= e(X_1, Y) + e(X_2, Y)\\
        &= e(X_1, Y_1) + e(X_1, Y_2) + e(X_2, Y_1) + e(X_2, Y_2).
    \end{align*}

    De esta manera,
    \begin{equation} \label{descomposición suma aristas}
        \sum_{i+j>2} e(X_i, Y_j) = e(X,Y) - e(X_1, Y_1).
    \end{equation}

    Por otro lado, se tiene que,
    \begin{align*}
        |X||Y| &= (|X_1| + |X_2|)(|Y_1| + |Y_2|)\\
        &= |X_1||Y_1| + |X_1||Y_2| + |X_2||Y_1| + |X_2||Y_2|.
    \end{align*}

    Así,
    \begin{equation} \label{descomposición multiplicación conjuntos}
        \sum_{i+j > 2} |X_i||Y_j| = |X||Y| - |X_1||Y_1| .
    \end{equation}

    Ahora, definiendo las particiones $\mathcal{P}_{X} = \lbrace X_1, X_2\rbrace$ de $X$ y $\mathcal{P}_{Y} = \lbrace Y_1, Y_2\rbrace$ de $Y$, desarrollamos,
    \begin{align} \label{Primer cálculo energy boost}
        q(\mathcal{P}_{X}, \mathcal{P}_{Y}) &= \sum_{i=1}^{2}\sum_{j=1}^{2} q(X_i, Y_j) \nonumber\\
        &= \sum_{i=1}^{2}\sum_{j=1}^{2} \frac{e(X_i, Y_j)^{2}}{n^{2}|X_i||Y_j|} \nonumber\\
        &= \frac{1}{n^{2}}\left( \frac{e(X_1, Y_1)^{2}}{|X_i||Y_j|} + \sum_{i+j > 2} \frac{e(X_i, Y_j)^{2}}{|X_i||Y_j|}\right) \nonumber\\
        &\overset{\eqref{Desigualdad_from_CS}}{\geq} \frac{1}{n^{2}}\left( \frac{e(X_1, Y_1)^{2}}{|X_1||Y_1|} + \frac{\left( \sum_{i+j > 2} e(X_i, Y_j)\right)^{2}}{\sum_{i+j > 2} |X_i||Y_j|}\right) \nonumber\\
        &\overset{\eqref{descomposición suma aristas}\ \text{y}\ \eqref{descomposición multiplicación conjuntos}}{=} \frac{1}{n^{2}}\left( \frac{e(X_1, Y_1)^{2}}{|X_1||Y_1|} + \frac{\left( e(X,Y) - e(X_1, Y_1)\right)^{2}}{|X||Y| - |X_1||Y_1|}\right).
    \end{align}

    Luego, por definición, note que
    \begin{equation} \label{e(X_1,Y_1) = ...}
        e(X_1, Y_1) = \frac{|X_1||Y_1| e(X,Y)}{|X||Y|} + \eta |X_1||Y_1|.
    \end{equation}

    Con esto, se continúa el cálculo desde la desigualdad \eqref{Primer cálculo energy boost} como sigue, \hh{Me podré saltar un espacio más pequeño abajo?}
    \begin{align} \label{Segundo cálculo energy boost}
        n^{2}q(\mathcal{P}_{X}, \mathcal{P}_{Y}) &\geq \frac{e(X_1, Y_1)^{2}}{|X_1||Y_1|} + \frac{\left( e(X,Y) - e(X_1, Y_1)\right)^{2}}{|X||Y| - |X_1||Y_1|}\nonumber\\
        \begin{split}
            &\overset{\eqref{e(X_1,Y_1) = ...}}{=} \frac{1}{|X_1||Y_1|}\left( \frac{|X_1||Y_1|e(X,Y)}{|X||Y|} + \eta |X_1||Y_1|\right)^{2} \\
            &\qquad + \frac{1}{|X||Y| - |X_1||Y_1|}\left( \frac{|X||Y| - |X_1||Y_1|}{|X||Y|}e(X,Y) - \eta |X_1||Y_1|\right)^{2}    
        \end{split}\nonumber\\
        \intertext{}
        \begin{split}
            &= \frac{|X_1||Y_1|}{|X|^{2}|Y|^{2}}e(X,Y)^{2} + 2\frac{|X_1||Y_1|}{|X||Y|}\eta e(X,Y) + \eta^{2}|X_1||Y_1| \\
            &\qquad + \frac{|X||Y| - |X_1||Y_1|}{|X|^{2}|Y|^{2}}e(X,Y)^{2} - 2\frac{|X_1||Y_1|}{|X||Y|}\eta e(X,Y) + \frac{\eta^{2} |X_1|^{2}|Y_1|^{2}}{|X||Y| - |X_1||Y_1|}    
        \end{split}\nonumber\\
        \intertext{ }
        &= \frac{e(X,Y)^{2}}{|X||Y|} + \eta^{2}|X_1||Y_1|\left( 1 + \frac{|X_1||Y_1|}{|X||Y| - |X_1||Y_1|}\right)\nonumber\\
        &\geq \frac{e(X,Y)^{2}}{|X||Y|} + \eta^{2}|X_1||Y_1|.
    \end{align}

    Finalmente, utilizando las cotas \eqref{condición tamaño conjunto regularidad} y \eqref{|eta| > epsilon}, podemos concluir desde la desigualdad \eqref{Segundo cálculo energy boost},
    \begin{align*}
        q(\mathcal{P}_{X}, \mathcal{P}_{Y}) &= \frac{e(X,Y)^{2}}{n^{2}|X||Y|} + \eta^{2}\frac{|X_1||Y_1|}{n^{2}}\\
        &= q(X,Y) + \eta^{2}\frac{|X_1||Y_1|}{n^{2}}\\
        &> q(X,Y) + \varepsilon^{4}\frac{|X||Y|}{n^{2}}.
    \end{align*}
\end{proof}\medskip

%%%% Demostración Energy boost
%\begin{proof} \hh{Antigua}
%    Consideramos $G$ un grafo sobre $n$ vértices, $X,Y\subset V(G)$ tales que el par $(X,Y)$ no es $\varepsilon$-regular, y $A\subset X$ y $B\subset Y$ subconjuntos con $|A| \geq \varepsilon|X|$ y $|B| \geq \varepsilon |Y|$ que evidencian la irregularidad del par $(X,Y)$. Para las particiones $\mathcal{P}_{X} = \lbrace A, X\setminus A\rbrace$ de $X$ y $\mathcal{P}_{Y} = \lbrace B, Y\setminus B\rbrace$ de $Y$, del mismo modo que en la demostración del lema \ref{energia_no_decrece}, se define la variable aleatoria $Z := d(X_i, Y_j)$.
%
%    Analizaremos la varianza de $Z$. Por un lado, se sabe que $\var[Z] = \mathbb{E}[Z^{2}] - \mathbb{E}[Z]^{2}$, y utilizando los resultados \ref{primer_momento_Z} y \ref{segundo_momento_Z} se obtiene
%    \begin{equation} \label{Var_Z_1}
%        \var[Z] = \frac{n^{2}}{|X||Y|}\left( q(\mathcal{P}_{X}, \mathcal{P}_Y) - q(X,Y)\right).
%    \end{equation}
%
%    Por otro lado, también se conoce que $\var[Z] = \mathbb{E}[(Z - \mathbb{E}[Z])^{2}]$. Si aislamos el evento en que un vértice se encuentre en $A$ y el otro en $B$ y utilizamos la definición de un par $\varepsilon$-regular junto con el resultado \ref{primer_momento_Z},
%    \begin{equation} \label{Var_Z_2}
%        \var[Z] \geq \frac{|A|}{|X|}\frac{|B|}{|Y|}\left( d(A,B) - d(X,Y)\right)^{2} > \varepsilon \cdot \varepsilon \cdot \varepsilon^{2}.
%    \end{equation} \hh{Este último paso no lo entiendo del todo bien :c}
%
%    Finalmente, comparando los resultados \ref{Var_Z_1} y \ref{Var_Z_2} de la varianza, se termina la prueba al obtener
%    \begin{equation*}
%        q(\mathcal{P}_{X}, \mathcal{P}_Y) > q(X,Y) + \varepsilon^{4}\frac{|X||Y|}{n^{2}}.
%    \end{equation*}
%\end{proof}

Vimos que particionar cualquier par de conjuntos no $\varepsilon$-regular por medio de sus subconjuntos que evidencian la irregularidad produce un aumento en la energía. Entonces, haciendo alusión al paso \ref{Paso 2b}(b) del algoritmo de la técnica \emph{argumento de incremento de energía}, se mostrará que refinar simultáneamente todos los pares de conjuntos no $\varepsilon$-regular de un grafo produce un aumento estricto de al menos $\varepsilon^{5}$ en la energía.\medskip

%%%% Lema: Energy boost para particiones
\begin{lema} \label{Energy boost particiones}
    Sea $\varepsilon > 0$, un grafo $G$ y una partición $\mathcal{P} = \lbrace V_1,...V_k\rbrace$ no $\varepsilon$-regular de $V(G)$. Entonces existe un refinamiento $\mathcal{Q}$ de $\mathcal{P}$, en el que cada $V_i$ se particiona en a lo más $2^{k}$ partes y es tal que
    \begin{equation*}
        q(\mathcal{Q}) > q(\mathcal{P}) + \varepsilon^{5}.
    \end{equation*}
\end{lema}

%%%% Demostración energy boost para particiones
\begin{proof}
    Sea $\varepsilon > 0$ y $\mathcal{P} = \lbrace V_1,...,V_k\rbrace$ una partición no $\varepsilon$-regular del conjunto de $n$ vértices de un grafo $G$ . Sabemos que para todos los $(i,j)\in [k]^{2}$ tales que el par $(V_i, V_j)$ no es $\varepsilon$-regular, existen los subconjuntos $A^{ij}\subset V_i$ y $A^{ji}\subset V_j$ testigos de su irregularidad. Observe que para cada $V_i$, podemos encontrar a lo más $k$ conjuntos no vacíos $A^{ij}$ que evidencian la irregularidad de los pares $(V_i, V_j)$ no $\varepsilon$-regular. Consideremos ahora la partición $\mathcal{Q} = \lbrace Q_1,...,Q_k\rbrace$ que refina a $\mathcal{P}$, en la que cada $Q_i$ es una partición resultante de dividir el conjunto $V_i$ según la intersección de todos los subconjuntos no vacíos $A^{ij}$ que atestiguan la irregularidad de los pares $(V_i, V_j)$ no $\varepsilon$-regular. En consecuencia, $|Q_i| \leq 2^{k}$.

    Por simplicidad en la notación, se define $\Theta := \lbrace (i,j)\in [k]^{2} : (V_i,V_j)\ \text{es}\ \varepsilon\text{-regular}\rbrace$. Luego, como la partición $\mathcal{P}$ no es $\varepsilon$-regular, se cumple la desigualdad
    \begin{equation} \label{condición partición no regular}
        \sum_{(i,j)\not\in \Theta} \frac{|V_i||V_j|}{n^{2}} > \varepsilon.
    \end{equation}

    Así, junto a los lemas probados previamente, damos prueba al resultado de la siguiente manera,
    \begin{align*}
        q(\mathcal{Q}) &= \sum_{(i,j)\in [k]^{2}} q(\mathcal{Q}_i, \mathcal{Q}_j) \\
        &= \sum_{(i,j)\in \Theta} q(\mathcal{Q}_i, \mathcal{Q}_j) + \sum_{(i,j)\not\in \Theta} q(\mathcal{Q}_i, \mathcal{Q}_j)\\
        &\overset{\text{Lema \ref{energia_no_decrece}}}{\geq} \sum_{(i,j)\in \Theta} q(V_i, V_j) + \sum_{(i,j)\not\in \Theta} q(\lbrace A^{ij}, V_i\setminus A^{ij}\rbrace, \lbrace A^{ji}, V_{j}\setminus A^{ji}\rbrace)\\
        &\overset{\text{Lema \ref{Energy boost un conjunto}}}{\geq} \sum_{(i,j)\in \Theta} q(V_i, V_j) + \sum_{(i,j)\not\in \Theta} \left( q(V_i, V_j) + \varepsilon^{4}\frac{|V_i||V_j|}{n^{2}} \right)\\
        &= \sum_{(i,j)\in [k]^{2}} q(V_i, V_j) + \sum_{(i,j)\not\in \Theta} \varepsilon^{4}\frac{|V_i||V_j|}{n^{2}}\\
        &\overset{\eqref{condición partición no regular}}{\geq} q(\mathcal{P}) + \varepsilon^{5}.
    \end{align*}

    \hh{Cambiar por $>$ en la última línea y donde dice lema 5, cuando lo cambio se me descuadra :c}
\end{proof}\medskip

Ya con todo lo necesario, damos prueba formal al Teorema \ref{szemeredi_regularity_lemma} mediante la técnica de \emph{argumento de incremento de energía}.\medskip

%%%% Demostración Lema de regularidad de Szemerédi
\begin{proof}[Demostración del Teorema \ref{szemeredi_regularity_lemma}]
    Dado $\varepsilon > 0$ y un grafo $G$, elegimos inicialmente la partición trivial del conjunto de vértices $\mathcal{P} = \lbrace V(G)\rbrace$. Ahora, iterativamente (actualizando $\mathcal{P}$), aplicaremos el Lema \ref{Energy boost particiones} cada vez que la partición actual no sea $\varepsilon$-regular. Observe que por cada aplicación del Lema \ref{Energy boost particiones} se consigue un aumento de al menos $\varepsilon^{5}$ en la energía, y como la energía de toda partición está acotada superiormente por 1, el proceso iterativo terminará luego de a lo más $\varepsilon^{-5}$ pasos. El resultado será necesariamente una partición $\varepsilon$-regular debido a la cota de la energía. 

    Para una partición no $\varepsilon$-regular con $k$ elementos, el Lema \ref{Energy boost particiones} encuentra un refinamiento de a lo más $k2^{k}$ partes. Dicho refinamiento será producido en cada iteración del algoritmo de \emph{argumento de incremento de energía}, y la cantidad de partes producidas las acotaremos crudamente en cada paso por $k2^{k} < 2^{2^{k}}$. Comenzando con la partición trivial de una parte, ejemplificaremos con las tres primeras iteraciones del algoritmo para mostrar la cantidad de partes producidas en cada paso tras aplicar el Lema \ref{Energy boost particiones}.
    
    \begin{equation*}
        \begin{aligned}
            1^{\text{\underline{ra}}}\ \text{Iteración:}\quad & 1 & \to\quad & 2 < 2^{2} & \text{partes.}\\
            2^{\text{\underline{da}}}\ \text{Iteración:}\quad & 2^{2} & \to\quad & \left( 2^{2}\right)2^{\left(  2^{2}\right)}  <  2^{2^{2^{2}}} & \text{partes.}\\
            3^{\text{\underline{ra}}}\ \text{Iteración:}\quad & 2^{2^{2^{2}}} & \to\quad & \left( 2^{2^{2^{2}}} \right)2^{\left( 2^{2^{2^{2}}} \right)} < 2^{2^{2^{2^{2^{2}}}}} & \text{partes.}
        \end{aligned}
    \end{equation*}

    Así, como el algoritmo debe luego de a lo más $\varepsilon^{-5}$ iteraciones, la cantidad de partes al final de proceso será
    \begin{equation*}
        M(\varepsilon) \leq \left. 2^{2^{\cdot^{\cdot^{\cdot^{2}}}}}\right\rbrace\ \text{Altura }2\varepsilon^{-5}.
    \end{equation*}
\end{proof}\medskip

Desde ahora en adelante, vamos a definir y consirar una \emph{torre de altura $k$} de la siguiente manera,
\begin{equation}
    \mathrm{torre}(k) := \left.2^{2^{\cdot^{\cdot^{\cdot^{2}}}}}\right\rbrace \text{Altura } k.
\end{equation}\medskip

\hh{En esta parte me gustaría dejar un comentario sobre lo grande que es la cota y el resultado que encontró Gowers en 1997 de cota inferior, pero no lo entiendo :c}\medskip

Una de las peculiaridades del lema de regularidad de Szemerédi es la flexibilidad que posee su enunciado, adaptando su aplicación a diferentes contextos. Por ejemplo, si en la demostración del Teorema \ref{szemeredi_regularity_lemma} tomamos una partición inicial arbitraria en vez de la partición trivial del conjunto de vértices del grafo, se logra obtener la siguiente variante del lema de regularidad.\medskip

%%%% Teorema: Lema de regularidad, partición inicial
\begin{teorema} \label{Regularidad_part_ini} (Regularidad de Szemerédi - Partición inicial arbitraria)
    Para todo $\varepsilon > 0$, existe un entero $M=M(\varepsilon)$ tal que todo grafo $G$ con una partición inicial $\mathcal{P}_0$ de $V(G)$ admite una partición $\varepsilon$-regular $\mathcal{P}$ de $V(G)$ que refina cada parte de $\mathcal{P}_0$ en a lo más $M$ partes.
\end{teorema}\medskip

Es posible fortalecer un poco más el lema de regularidad exigiendo que el resultado sea una equipartición del conjunto de vértices de un grafo $G$. Es decir, una partición $\mathcal{P} = \lbrace V_1,...,V_k \rbrace$ tal que $|V_1|\leq |V_2|\leq ...\leq |V_k| = |V_1| +1$.\medskip

%%%% Teorema: Lema de regularidad, equipartición
\begin{teorema} \label{Regularidad_equipart} (Regularidad de Szemerédi - Equipartición)
    Para todo $\varepsilon > 0$ y $m_0\in\mathbb{N}$, existe un entero $M = M(\varepsilon)$ tal que todo grafo admite una equipartición $\varepsilon$-regular de su conjunto de vértices de $k$ partes, con $m_0\leq k\leq M$. 
\end{teorema}\medskip

\fs{Comentar que cuando tenemos esta versión del teorema (que es la clásica), entonces la definición de una partición $\varepsilon$-regular se traduce en $...\leq\varepsilon k^{2}$. También hablar un poco de $m_0$, cual ayuda a que ninguna de las partes sea demasiado grande.}\medskip

La idea de la demostración del Teorema \ref{Regularidad_equipart} consiste en modificar el algoritmo de la técnica de argumento de incremento de energía, de manera que en cada iteración del refinamiento se logre obtener una equipartición. Este procedimiento conservará el incremento de energía en cada paso y  terminará con una equipartición del conjunto de vértices de un grafo cualquiera. Para todo grafo $G$, la modificación del algoritmo es la siguiente:\medskip



%%%% Algoritmo modificado argumento de incremento de la energía para equiparticiones
\begin{enumerate}
    % !er paso
    \item Comenzar con una equipartición inicial arbitraria $\mathcal{P}$ de $V(G)$ con $m_0$ partes.
    % 2do paso
    \item Mientras la partición actual $\mathcal{P}$ no es $\varepsilon$-regular:
    \begin{itemize}
        \item[(a)] Para cada par $(V_i, V_j)$ no $\varepsilon$-regular, encontrar los subconjuntos $A^{ij}\subset V_i$ y  $A^{ji}\subset V_j$ que evidencian la irregularidad de cada par.

        \item[(b)] \label{paso_2b_mod} Refinar $\mathcal{P}$ usando simultáneamente los conjuntos $A^{ij}$ y $A^{ji}$ para obtener la partición $\mathcal{Q}$, cual divide cada parte de $\mathcal{P}$ en a lo más $2^{|\mathcal{P}|}$ partes.

        \item[(c)] \label{paso_3c_mod} Modificar la partición $\mathcal{Q}$ refinando, si es posible, cada uno de sus elementos para formar partes iguales de tamaño $|V(G)|/m$ utilizando alguna elección apropiada del entero $m=m(|Q|,\varepsilon)$. Luego, los elementos de $\mathcal{Q}$ que no fueron refinados previamente a causa de su bajo tamaño y los conjuntos de vértices residuales del refinamiento anterior, deben ser combinados y posteriormente dividir el resultado en partes iguales de tamaño $|V(G)|/m$.

        \item[(d)] Actualizar $\mathcal{P}$ con la modificación de $\mathcal{Q}$. 
    \end{itemize}
\end{enumerate}\medskip

El algoritmo anterior obtiene una equipartición del conjunto de vértices del grafo $G$. En lo que respecta a la energía del proceso, el paso \ref{paso_2b_mod}(b) conserva un aumento de al menos $\varepsilon^{5}$ en cada iteración. El paso \ref{paso_3c_mod}(c) podría ocasionar una baja en la energía, sin embargo, no debería ser significativa con una elección de $m$ suficientemente grande.\footnote{\hh{Aquí quiero hacer un comentario/ejemplo de $m$. Yufei sugiere $m= \lfloor 100|\mathcal{Q}\varepsilon^{-5}|\rfloor$, pero tampoco lo entiendo mucho.}} En resumidas cuentas, el proceso anterior aumenta la energía en cada iteración en al menos $\varepsilon^{5}/2$, logrando terminar luego de a lo más $2\varepsilon^{-5}$ pasos con una equipartición de a lo más $\mathrm{torre}(\varepsilon^{-5})$ partes.

\subsection{Aplicaciones}

Usualmente las aplicaciones del lema de regularidad de Szemerédi son desarrolladas en base a los siguientes pasos:
\begin{enumerate}
    % Partición
    \item Obtener una \textbf{partición} del conjunto de vértices del grafo con el lema de regularidad.
    % Limpiar
    \item \textbf{Limpiar} el grafo eliminando aristas con mal comportamiento según el problema. Generalmente, se eliminan las aristas entre los pares de partes que presentan:
    \begin{itemize}
        \item[i)] Irregularidad.
        \item[ii)] Baja densidad.
        \item[iii)] Al menos una de las partes es demasiada pequeña.
    \end{itemize}
    % Contar
    \item \label{paso3_reg} \textbf{Contar} un determinado patrón en el grafo limpio utilizando algún lema de conteo.
\end{enumerate}\medskip

Teniendo esta fórmula en mente, damos paso a la primera aplicación del lema de regularidad, cual plantea intuitivamente que todo grafo con \emph{pocos} triángulos puede convertirse en un grafo libre de triángulos eliminando \emph{pocas} aristas. Formalmente, \medskip

%%%% Teorema: Lema de eliminación de triángulos
\begin{teorema} \label{Enunciado TRL} (Lema de eliminación de triángulos)
    Para todo $\varepsilon > 0$, existe $\delta > 0$ y $n_0\in \mathbb{N}$ tal que todo grafo sobre $n\geq n_0$ vértices con a lo más $\delta n^{3}$ triángulos se puede hacer libre de triángulos eliminando a lo más $\varepsilon n^{2}$ aristas.
\end{teorema}

%%%% Demostración Teorema: Lema de eliminación de triángulos
\begin{proof}

    Dado $\varepsilon > 0$, elija $\varepsilon_r = \frac{1}{4}\left(  \frac{\varepsilon}{3}\right)^{3}$ y  utilice el Teorema \ref{szemeredi_regularity_lemma} para obtener la constante $M=M(\varepsilon_r)$. Considere además $\delta = \frac{1}{2}\frac{\varepsilon_{r}^{4}}{M^{3}}$ y $n_0\in\mathbb{N}$ suficientemente grande, de manera tal que el grafo $G = (V,E)$ con $n\geq n_0$ vértices posee a lo más $\varepsilon n^{3}$ triángulos. Luego, nuevamente por el Teorema \ref{szemeredi_regularity_lemma}, se asegura la existencia de una partición $\varepsilon_r$-regular $\mathcal{P} = \lbrace V_1,...,V_M \rbrace$.\medskip

    Para limpiar el grafo, para cada $(i,j)\in [M]^{2}$, se eliminan todas las aristas entre $V_i$ y $V_j$ cuando\medskip
    
    \begin{itemize}
        \item[(a)] ($V_i , V_j$) no es un par $\varepsilon_r$-regular,
        \item[(b)] $d(V_i, V_j) < (4\varepsilon_r)^{1/3}$, o
        \item[(c)] $\min\lbrace |V_i||V_j|\rbrace < \frac{n}{M}\varepsilon_r$.
    \end{itemize}\medskip

    De esta manera, como la partición es $\varepsilon_r$-regular, las aristas removidas por la condición (a) son a lo más\medskip
    
    \begin{equation*}
        \sum_{\substack{(i,j)\in [M]^{2} \\ (V_i , V_j) \text{ no } \varepsilon_r\text{-regular}}} |V_i||V_j|\leq \varepsilon_r n^{2}.
    \end{equation*}\medskip

    Las aristas eliminadas en los conjuntos de baja densidad por la condición (b) son a lo más\medskip

    \begin{equation*}
        \sum_{\substack{(i,j)\in [M]^{2} \\ d(V_i, V_j) < (4\varepsilon_r)^{1/3}}} d(V_i, V_j)|V_i||V_j| < (4\varepsilon_r)^{1/3} \sum_{(i,j)\in [M]^{2}} |V_i||V_j| = (4\varepsilon_r)^{1/3} n^{2}.
    \end{equation*}\medskip

    Por último, debido a que cada vértice de $G$ puede ser adyacente con a lo más $\frac{n}{M}\varepsilon_r$ vértices en a lo más $M$ subconjuntos demasiado pequeños, las aristas removidas por (c) son a lo más\medskip

    \begin{equation*}
        M\cdot \frac{n}{M}\varepsilon_r \cdot n = \varepsilon_r n^{2}.
    \end{equation*}\medskip

    En total, en la limpieza, se eliminan a lo más $\varepsilon n^{2}$ aristas.\medskip

    Ahora, nos falta probar que el grafo limpio $G' = (V, E')$ es libre de triángulos. Para esto, observe que la condición de eliminación de aristas (a) nos asegura que cada par $(V_i , V_j)$ es $\varepsilon_r$-regular, y que se satisface la hipótesis del lema de conteo de grafos. Entonces, si luego de la limpieza del grafo aún existe un triángulo $(x,y,z)\in V_i\times V_j\times V_\ell$, el Lema \ref{Triangle_Counting_Lemma} nos dice que incluso hay más triángulos. En particular, gracias a la eliminación de las aristas por la condición (b) y (c),\medskip

    \begin{align*}
        \left| \lbrace (x,y,z)\in V_i\times V_j\times V_\ell : xy,yz,xz\in E'\rbrace\right| &\geq d(V_i, V_j)d(V_i, V_\ell)d(V_j, V_\ell)|V_i||V_j||V_\ell| - 3\varepsilon_r |V_i||V_j||V_\ell|\\
        &\geq \varepsilon_r |V_i| |V_j| |V_\ell|\\
        &\geq \frac{\varepsilon^{4} n^{3}}{M^{3}}\\
        &> \delta n^{3}.
    \end{align*}\medskip

    Finalmente, con nuestra elección de $\delta$, el resultado se prueba formulando la siguiente contradicción: si existe un triángulo en el grafo limpio $G'$, el lema de conteo de triángulos nos dice que en realidad existen más de $\delta n^{3}$ triángulos. No obstante, el grafo original posee a lo más $\delta n^{3}$ triángulos, por lo que se concluye que el grafo $G'$ obtenido desde $G$ es libre de triángulos removiendo a lo más $\varepsilon n^{2}$ aristas.
\end{proof}\medskip

Denotaremos por $k$-PA a una prograsión aritmética de $k$ elementos. En particular, diremos que un conjunto de números naturales $A$ es libre de 3-PA si no existen los elementos $x,x+y,x+2y\in A$, con $y\not= 0$. Cuando $y= 0$, diremos que la 3-PA es trivial.\medskip

%%%% Teorema: Roth
\begin{teorema} \label{Teorema Roth} (Teorema de Roth)
    Para todo $\varepsilon > 0$, existe $n_0\in\mathbb{N}$ tal que si el conjunto $A\subset [n]$ posee $|A|\geq \varepsilon n$ elementos, entonces $A$ contiene una $\mathrm{3}$-$\mathrm{PA}$ no trivial cada vez que $n\geq n_0$.
\end{teorema}

%%%% Demostración: Teorema de Roth
\begin{proof}
    Sea $\varepsilon > 0$ y el conjunto $A\subset [n]$ con $|A|\geq\varepsilon n$ elementos. La idea es construir un grafo $3$-partito de manera conveniente para posteriormente utilizar el lema de eliminación de triángulos. Considere el grafo 3-partito $G = (V,E)$ con partición de vértices $V = V_1 \cup V_2 \cup V_3$, en donde $V_1 = [n]$, $V_2 = [2n]$ y $V_3 = [3n]$, y son disjuntos entre cada par de ellos. Así, $G$ tiene $6n$ vértices, y se definen las aristas de la siguiente manera:\medskip

    \begin{enumerate}
        \item Existe una arista desde $i\in V_1$ hasta $j\in V_2$ si y solamente si $j-i\in A$.
        \item Existe una arista desde $j\in V_2$ hasta $k\in V_3$ si y solamente si $k-j\in A$.
        \item Existe una arista desde $i\in V_1$ hasta $k\in V_3$ si y solamente si $\frac{k-i}{2}\in A$.
    \end{enumerate}\medskip

    Luego, la tupla $(i,j,k)\in V_1\times V_2\times V_3$ define un triángulo en $G$ si y solamente si $j-i\in A$, $k-j\in A$ y $\frac{k-i}{2}\in A$, o bien, $\left\lbrace j-i, \frac{k-i}{2}, k-j\right\rbrace$ es una $3$-PA en $A$ con diferencia $\frac{k-2j+i}{2}$. En específico, diremos que un triángulo $(i,j,k)\in V_1\times V_2\times V_3$ es trivial en $G$ si para algún $a\in A$ se satisface que $j-i = \frac{k-i}{2} = k-j = a$.\medskip

    Ahora, observando que cada triángulo trivial se puede identificar con el par $(i,a)\in V_1 \times A$, la cantidad de triángulos triviales es exactamente $n|A| \geq \varepsilon n^{2}$. Además, por construcción, no existen triángulos triviales que compartan una arista, por lo que no se puede eliminar dos triángulos triviales removiendo solo una arista. En consecuencia, debemos eliminar al menos $\varepsilon n^{2} = \frac{\varepsilon}{36}(6n)^{2}$ aristas para hacer de $G$ libre de triángulos.\medskip

    Utilizando el lema eliminación de triángulos eligiendo $\varepsilon_0 = \frac{\varepsilon}{36}$, existen $\delta_0 > 0$ y $n'_0\in\mathbb{N}$ tal que el grafo $G$ con $6n \geq n'_0$ vértices y a lo más $\delta_0 (6n)^{3}$ triángulos, se convierte en libre de triángulos eliminando a lo más $\varepsilon_0 (6n)^{2}$ aristas. Entonces, estableciendo $\delta = 216\delta_0$, note que existen como máximo $\delta n^{3} - \varepsilon n^{2}$ triángulos no triviales. Sabiendo esto, aseguramos la existencia de un triángulo no trivial cuando $n > \frac{\varepsilon + 1}{\delta}$. En efecto,\medskip
    
    \begin{equation*}
        n > \frac{\varepsilon + 1}{\delta} \ \Rightarrow\  \delta n - \varepsilon > 1 \ \Rightarrow\  n^{2}(\delta n - \varepsilon) > 1.
    \end{equation*}\medskip

    Finalmente, el resultado queda demostrado tomando $n_0 > \max\left\lbrace \frac{n'_0}{6}, \frac{\varepsilon + 1}{\delta}\right\rbrace$ suficientemente grande.
\end{proof}\medskip

%%%% Definición: Emparejamiento
\begin{definicion}
    Dado un grafo $G = (V,E)$, un un conjunto $M\subseteq E$ es un \textbf{emparejamiento} en $G$ si no existen un par de aristas en $M$ que compartan algún vértice. %Es decir, si denotamos por $V(M)$ al conjunto de vértices correspondiente a $M$, cada elemento de $V(M)$ tiene grado $1$.
    Diremos que $M$ es un \textbf{emparejamiento inducido} si es un emparejamiento y toda arista de $G$ con un vértice en $V(M)$ es una arista en $M$.
\end{definicion}

\fs{Usar $k$ o $M$ para la cantidad de partes?, aquí se me confunde con el emparejamiento, pero en TRL y demo espectral de regularidad usé $M$ como las partes. De momento en esta parte lo dejaré con $k$.}

%%%% Teorema: Emparejamiento inducido
\begin{teorema}  \label{Teo_emp_ind} (Emparejamiento inducido)
    Para todo $\varepsilon > 0$, existe $n_0\in \mathbb{N}$ tal que todo grafo $G = (V,E)$ de $n\geq n_0$ vértices que está compuesto por la unión de $n$ emparejamientos inducidos, posee a lo más $\varepsilon n^{2}$ aristas.
\end{teorema}

%%%% Demostración: Emparejamiento inducido
\begin{proof}
    Dado $\varepsilon > 0$, aplique el Teorema \ref{szemeredi_regularity_lemma} con $\varepsilon_r = \frac{\varepsilon}{10}$ para obtener la constante $M(\varepsilon_r)$. Considere $n_0\in\mathbb{N}$ suficientemente grande, y asuma que el grafo $G = (V,E)$ con $n\geq n_0$ vértices y compueston por $n$ emparejamientos inducidos satisface $e_G > \varepsilon n$. Nuevamente, por el Teorema \ref{szemeredi_regularity_lemma}, se asegura la existencia de la partición $\mathcal{P} = \lbrace V_1,...,V_k\rbrace$ con $k\leq M(\varepsilon)$ partes que es $\varepsilon_r$-regular.\medskip
    
    Para cada $(i,j)\in [k]^{2}$ se eliminan todas las aristas entre los conjuntos $V_i$ y $V_j$ cuando éstos presenten irregularidad, densidad menor que $2\varepsilon_r$, o al menos uno de los conjuntos es menor que $\frac{n}{k}\varepsilon_r$. En total, el proceso de limpieza remueve a lo más $4\varepsilon_r n^{2}$ aristas de $G$ para obtener un nuevo grafo $G'$. En consecuencia,\medskip
    
    \begin{equation*}
        e_G' \geq e_G - 4\varepsilon_r n^{2} > \varepsilon n^{2} - \frac{4}{10}\varepsilon n^{2} > \frac{\varepsilon}{2}n^{2}.
    \end{equation*}\medskip

    Ahora, observe que debe existir un emparejamiento inducido $M$ en $G'$ con al menos $\frac{\varepsilon}{2}n$ aristas (y al menos $\varepsilon n$ vértices). De no ser así, todos los emparejamientos tendrán a lo más $\frac{\varepsilon}{2}n$ aristas, por lo que $e_G' < \frac{\varepsilon}{2}n^{2}$.\medskip

    Se define $U_i := V_i \cap V(M)$ como el subconjunto de vértices de $M$ que comparte elementos con $V_i$, y $U := \displaystyle\bigcup_{i\in [k]} \lbrace U_i : |U_i| \geq \varepsilon_r |V_i|\rbrace$. Es decir, $U$ es la unión de todos los conjuntos $U_i \subset V(M)$ que comparten una fracción suficientemente grande de vértices con $V_i$. Note que podemos obtener el conjunto $U$ removiendo a lo más $\varepsilon_r n = \frac{\varepsilon}{10}n$ vértices de $V(M)$, pues\medskip

    \begin{equation*}
        \sum_{i\in [k]} |U_i| < \sum_{i\in [k]} \varepsilon_r |V_i| = \frac{\varepsilon}{10} n.
    \end{equation*}\medskip

    De esta manera, recordando que $|V(M)| \geq \varepsilon n$, se determina que $|U| > \varepsilon n - \frac{\varepsilon}{10}n = \frac{9}{10}\varepsilon n$. Además, como también $|M| \geq \frac{\varepsilon}{2}n$, debe existir al menos un vértice en $U$ que sea parte de una arista en $M$. Luego, dada la limpieza de $G$, dicha arista debe pertenecer a algún par $U_t\times U_\ell$ que satisfacen $|U_k| \geq \varepsilon_r |V_k|$ y  $|U_\ell| \geq \varepsilon_r |V_\ell|$, y son tales que 
    su correspondiente par $(V_t, V_\ell)$ es $\varepsilon_r$-regular con densidad $d(V_t, V_\ell) \geq 2\varepsilon_r$. Entonces, por regularidad,

    \begin{equation} \label{eq1_emp_ind}
        d(U_t, U_\ell) = d(V_t, V_\ell) \pm \varepsilon_r \geq 2\varepsilon_r - \varepsilon_r = \varepsilon_r.
    \end{equation}\medskip

    Ahora, como que $M$ es un emparejamiento inducido, todo par de subconjuntos $A,B\subset V(M)$ debe satisfacer\medskip

    \begin{equation*}
        e(A,B) \leq \min\lbrace |A|, |B|\rbrace.
    \end{equation*}\medskip

    Sin embargo, la desigualdad \eqref{eq1_emp_ind} implica que\medskip

    \begin{align*}
        e(U_t, U_\ell) &= d(U_t, U_\ell)|U_t||U_\ell|\\
        &\geq |U_t||U_\ell| \varepsilon_r\\
        &\geq |U_t| |V_\ell| \varepsilon_{r}^{2}\\
        &\geq |U_t|\frac{n}{k}\varepsilon_{r}^{3}\\
        &> |U_t|.
    \end{align*}\medskip

    La desigualdad anterior nos dice que existe una arista entre $U_k$ y $U_\ell$ que no pertenece a $M$, por lo que se contradice la hipótesis de que $M$ es un emparejamiento inducido. 
\end{proof}\medskip

\fs{Comentar que el siguiente teorema será utilizado para demostrar alternativamente el Teorema de Roth.}


%%%% Teorema: Esquina (Ajtai-Szemerédi)
\begin{teorema} \label{Corner_Theorem} (Ajtai-Szemerédi)
    Para todo $\varepsilon > 0$, existe $n_0\in\mathbb{N}$ tal que siempre que $n\geq n_0$, todo subconjunto $S\subset [n]^{2}$ con $|S| \geq \varepsilon n^{2}$ posee elementos de la forma $\lbrace (a,b), (a+d, b), (a, b+d)\rbrace$ para algún $a,b,d \in \mathbb{N}$, con $d \not= 0$.
\end{teorema}

%%%% Demostración: Esquina (Ajtai-Szemerédi)
\begin{proof}
    Sea $\varepsilon > 0$, $n_0\in\mathbb{N}$ suficientemente grande tal que $n\geq n_0$, y $S\subset [n]^{2}$ un subconjunto con al menos $\varepsilon n^{2}$ elementos. Vamos a construir un grafo bipartito $G = (U\cup W, E)$ con conjunto de vértices $U = \lbrace u_1,...,u_n\rbrace$ y  $W = \lbrace w_1,...,w_n\rbrace$ definiendo las aristas de la siguiente manera:\medskip

    \[
        u_i w_j\in E \Longleftrightarrow (i,j)\in S.
    \]\medskip

    Interpretando a $[n]^{2}$ como una grilla bidimensional, se puede definir una relación entre pares de aristas en $G$ en función de la distancia que abarca la suma de las coordenadas de sus respectivos pares en $S$. Esto es,\medskip

    \[
        u_i w_j \sim u_k w_\ell \Longleftrightarrow i + j = k + \ell = q.
    \]\medskip

    \fs{Dibujito con 2 ejemplos de $q$.}
    Observe que para cada $2\leq q\leq 2n$ se define un emparejamiento en $G$ debido a que no existen aristas que compartan un vértice, por lo que las clases de equivalencia (cada una asociada a algún $q$) de la relación forman una partición de emparejamientos de $E$. En efecto, suponga que las aristas que pertenecen a la misma clase $u_i w_j$ y $u_k w_j$ comparten el vértice $w_j$. Entonces, como $i+j = k+j$, se determina que $u_i = u_k$ y se concluye que $u_i w_j$ y $u_k w_j$ son la misma arista.\medskip

    Luego, como $e_G = |S| \geq \varepsilon n^{2}$, el Teorema \ref{Teo_emp_ind} asegura que existe al menos un emparejamiento no inducido. Esto significa que en un emparejamiento que contiene las aristas con la relación $u_i w_j \sim u_k w_\ell$ puede existir el trío de aristas $u_i w_j$, $u_k w_\ell$ y $u_i w_\ell$. Así, para algún $d\in \mathbb{N}$, $(i,j)$, $(k,\ell)$ y $(i,\ell)$ elementos de $S$ que satisfacen\medskip

    \[
        k - i = j - \ell = d.
    \]\medskip

    Finalmente, el resultado se consigue tomando $(i,\ell)$ = $(a,b)$ para obtener $j = b + d$ y $k = a + d$. \fs{Poner dibujito de la esquina}
\end{proof}\medskip

\fs{Comentar que el Teorema de la esquina nos entrega otro camino para demostrar el Teorema de Roth.}\medskip

\begin{proof}[Segunda demostración Teorema \ref{Teorema Roth}]
    Dado $\varepsilon > 0$, escogemos $n_0\in\mathbb{N}$ suficientemente grande. Para $n\geq n_0$, sea $A\subset [n]$ un conjunto que posee al menos $\varepsilon n$ elementos. Se define el siguiente conjunto:\medskip
    
    \[
        B = \lbrace (x,y)\in [2n]^{2} : x-y\in A\rbrace,
    \]\medskip
    
    Observe que cada $a\in A$ da lugar a exactamente $n$ elementos en $B$ con $x-y=a$, permitiendo determinar que $|B| = n|A| \geq \varepsilon n^{2}$. Luego, el Teorema \ref{Corner_Theorem} asegura la existencia de elementos de la forma $\lbrace (a,b), (a, b+d), (a+d,b)\rbrace$ en $B$. Por consecuencia, se encuentra una 3-PA no trivial en $A$ tomando $x = a-b$, e $y = d$.
\end{proof}\medskip

\fs{Explicar que ahora vamos a demostrar con teoría espectral el lema de regularidad de Szemerédi. Comentar también que esta versión la realizó Terence Tao.}\medskip

%%%% Demostración espectral: Lema de regularidad Szemerédi
\begin{proof}[Demostración espectral Teorema \ref{szemeredi_regularity_lemma}] 
    Sea $\varepsilon > 0$, $G = ([n],E)$ un grafo y $T$ su matriz de adyacencia. Consideramos además $\lbrace u_1,...,u_n\rbrace$ la base ortonormal de $\mathbb{R}^{n}$ formada por los vectores propios de $T$, y $|\lambda_1| \geq ... \geq |\lambda_n|$ los valores propios de $T$ ordenados de manera decreciente.\medskip

    Por la Proposición \ref{potencia_matriz_adyacencia = caminatas} y el Corolario \ref{Tr_Ak}, se satisface\medskip

    \begin{equation} \label{eq_1 Spectral_Proof}
        \Tr(T) = \sum_{i=1}^{n} \lambda_{1}^{2} =  2e_G \leq n^{2}.
    \end{equation}\medskip

    De esta manera, al notar que $i\lambda_{i}^{2} \leq \sum_{j=1}^{i} \lambda_{j}^{2} \leq n^{2}$, es posible acotar cada valor propio de la siguiente manera:\medskip

    \begin{equation} \label{eq_2 Spectral_Proof}
        \lambda_{i} \leq \frac{n}{\sqrt{i}}\ ,\ \forall i\in [n].
    \end{equation}\medskip

    Al final de esta demostración se entregará una función $f:\mathbb{N}\to \mathbb{N}$ que depende únicamente de $\varepsilon$ y que satisface $f(i) > i$. Denotando por $f^{(k)}$ a la $k$-ésima composición de $f$ con ella misma, consideramos una partición de $[n]$ en intervalos de la forma $[f^{(k-1)}(1), f^{k}(1)]$, para $k\in \lbrace 1,...,\frac{1}{\varepsilon^{3}}\rbrace$. Con esta construcción, debe existir un natural $\ell = f^{(k-1)}(1)$ que cumple con\medskip

    \begin{equation} \label{eq_3 Spectral_Proof}
        \sum_{\ell \leq j < f(\ell)} |\lambda_j|^{2} \leq \varepsilon^{3}n^{2}.
    \end{equation}\medskip

    De lo contrario, la suma de $|\lambda_j|^{2}$ sobre todos los intervalos definidos es estrictamente mayor que $\varepsilon^{3}n^{2}$. Así, como son $\frac{1}{\varepsilon^{3}}$ intervalos, se contradice la desigualdad \eqref{eq_1 Spectral_Proof}, pues\medskip

    \begin{equation*}
        \sum_{j=1}^{n} |\lambda_j|^{2} > \frac{1}{\varepsilon^{3}}\cdot \varepsilon^{3}n^{2} = n^{2}.
    \end{equation*}\medskip

    Ahora, usando el natural $\ell$, separamos la matriz $T$ en tres partes. En específico,\medskip

    \begin{equation*}
        T = T_1 + T_2 + T_3.
    \end{equation*}\medskip

    Se interpretará $T_1$ como la componente \emph{estructural},\medskip

    \begin{equation*}
        T_1 := \sum_{i < \ell} \lambda u_i u_{i}^{T},
    \end{equation*}\medskip

    $T_2$ como la componente de \emph{error},\medskip

    \begin{equation*}
        T_2 := \sum_{\ell \leq i < f(\ell)} \lambda_i u_i u_{i}^{T},
    \end{equation*}\medskip

    y $T_3$ como la componente \emph{casi-aleatoria},\medskip

    \begin{equation*}
        T_3 := \sum_{i \geq f(\ell)} \lambda_i u_i u_{i}^{T}.
    \end{equation*}\medskip

    Pensamos cada vector propio de $T$ como una función $u_i : [n]\to \mathbb{R}$. En otras palabras, todo vector propio asigna un \emph{peso} a cada vértice de $G$.\medskip

    \textbf{Analizamos} $\mathbf{T_1}$. La idea es particionar el conjunto de vértices $[n]$ de manera tal que $T_1$ es aproximadamente constante en la mayoría de las partes. Veremos que el número de partes será $O_{\ell, \varepsilon}(1)$, es decir, un valor constante que depende solo de $\ell$ y $\varepsilon$.\medskip

    Para cada $i\in [\ell - 1]$ ordenamos de manera creciente los vértices de $G$ según la asignación de \emph{pesos} que otorga $u_i (\cdot)$. En primera instancia, se agrupa en un conjunto excepcional a aquellos vértices que presenten un \emph{peso} demasiado grande en magnitud. Dicho conjunto se define de la siguiente manera:\medskip

    \begin{equation*}
        V_{0}^{i} := \left\lbrace k\in [n]: |u_i (k)| > \sqrt{\frac{\ell}{\varepsilon}} n^{-1/2}\right\rbrace.
    \end{equation*}\medskip

    Dado que $\norm{u_i} = 1$, cada $V_{0}^{i}$ no puede tener muchos elementos. En efecto, al observar que\medskip

    \begin{equation*}
        |V_{0}^{i}|\left( \sqrt{\frac{\ell}{\varepsilon}}n^{-1/2}\right)^{2} < \sum_{k=1}^{n} u_{i}(k)^{2} = \norm{u_i}^{2} = 1,
    \end{equation*}\medskip

    es posible determinar que $|V_{0}^{i}| < \frac{\varepsilon}{\ell}n$.\medskip

    Aquellos vértices que no están en $V_{0}^{i}$, serán agrupados particionando la recta de largo $2\sqrt{\frac{\ell}{\varepsilon}}n^{-1/2}$ en subintervalos de tamaño a lo más $\left( \frac{\varepsilon^{3/2}}{\ell^{3/2}}\right)n^{-1/2}$. Esta configuración provoca gráficamente el siguiente esquema para cada $u_i (\cdot)$.\medskip

    \fs{Poner dibujito...}\medskip

    Por consecuencia, para $i\in [\ell -1]$, la cantidad de partes que genera cada $u_{i}(\cdot)$ son a lo más\medskip

    \begin{equation*}
        \frac{
            2\sqrt{\frac{\ell}{\varepsilon}} n^{-1/2}
        }{
            \frac{\varepsilon^{3/2}}{\ell^{3/2}} n^{-1/2}
        } = \frac{2\ell^{2}}{\varepsilon^{2}} = O_{\ell, \varepsilon}(1).
    \end{equation*}\medskip

    
    Para conseguir la partición deseada de $[n]$, por un lado, se toma la unión de todos los conjuntos excepcionales $V_{0}^{i}$ para dar lugar al conjunto $V_0$ de tamaño a lo más $(\ell - 1)\cdot \frac{\varepsilon n}{\ell} < \varepsilon n$. Por otro lado, combine las particiones generadas por los $\ell - 1$ primeros vectores propios mediante un refinamiento usual. Así, se consigue una partición del conjunto de vértices de $G$ de la forma $[n] = V_0 \cup V_1 \cup ...\cup V_{M}$. Dada la construcción, la cantidad de partes que se obtienen son\medskip

    \begin{equation} \label{eq_4 Spectral_Proof}
        M(\varepsilon) \leq \left( \frac{2\ell^{2}}{\varepsilon^{2}}\right)^{\ell}
    \end{equation}\medskip

    Ahora, intuitivamente, se mostrará que los valores de la matriz $T_1$ en cada bloque $V_i \times V_j$ son aproximadamente constante, i.e, no varían más que $o_{\varepsilon}(1)$. Para esto, como se hizo con los vectores propios, pensamos la matriz de adyacencia como una función $T: [n]\times [n]\to \mathbb{R}$ para identificar sus entradas. De esta manera, para cada $i,j\in [M]$, $a,c\in V_i$, y $b,d\in V_j$,\medskip

    \begin{align*}
        \left| T_1(a,b) - T_1(c,d)\right| &= \left| \sum_{i < \ell} \lambda_i u_i(a) u_i(b) - \lambda_i u_i(c) u_i(d)\right|\\
        &\leq \sum_{i < \ell} \left| \lambda_i\right| \left| u_i(a) u_i(b) - u_i(c)u_i(b) + u_i(c)u_i(b) - u_i(c)u_i(d)\right|\\
        &\leq \sum_{i < \ell} \left| \lambda_1\right| \left| u_i(b)(u_i(a) - u_i(c)) + u_i(c)(u_i(b) - u_i(d))\right|\\
        &\leq \sum_{i < \ell} n \left| u_i(b)\right| \left| u_i(a) - u_i(c)\right| + n\left| u_i(c)\right| \left| u_i(b) - u_i(d)\right|\\
        &\leq \ell n\left( 2\sqrt{\frac{\ell}{\varepsilon}} n^{-1/2}\cdot \frac{\varepsilon^{3/2}}{\ell^{3/2}} n^{-1/2} + 2\sqrt{\frac{\ell}{\varepsilon}} n^{-1/2}\cdot \frac{\varepsilon^{3/2}}{\ell^{3/2}} n^{-1/2}\right)\\
        &= 4\varepsilon.
    \end{align*}\medskip

    Luego, para $i,j\in [M]$, defina $d_{ij}$ como el promedio de los valores del bloque $V_i \times V_j$ en $T_1$ y observe que se satisface\medskip

    \begin{equation*}
        \left| T_1(a,b) -d_{ij}\right| \leq 4\varepsilon\ ,\ \forall a\in V_1, \forall b\in V_j.
    \end{equation*}\medskip

    En efecto, como $d_{ij}$ es un promedio, deben existir los pares $(x_0, y_0), (x_1,y_1)\in V_i \times V_j$ tales que $T_1 (x_0, y_0) \leq d_{ij}$ y $T_1 (x_1,y_1) \geq d_{ij}$. Luego, si $\left| T_1 (a,b) - d_{ij}\right| > 4\varepsilon$, entonces se encuentra una contradicción al determinar que $T_1 (a,b) - T_1 (x_0, y_0) > 4\varepsilon$, o bien $T_1 (a,b) - T_1 (x_1, y_1) < -4\varepsilon$.\medskip

    Usando lo anterior y la desigualdad triangular, para todo $A\subset V_i$ y $B\subset V_j$, obtenemos la siguiente cota.\medskip

    \begin{align} \label{eq_5 Spectral_Proof}
        \left| v_{A}^{T} (T_1 - d_{ij}\mathbbm{1}_{n\times n}) v_B\right| &\leq \sum_{a\in A}\sum_{b\in B} \left| T_1 (a,b) - d_{ij}\right| \nonumber\\
        &\leq 4\varepsilon |A||B|\\
        &\leq 4\varepsilon |V_i| |V_j|\nonumber.
    \end{align}\medskip

    \textbf{Analizamos} $\mathbf{T_2}$. Observe en primer lugar, por construcción,\medskip

    \begin{equation*}
        \Tr (T_{2}^{2}) = \sum_{\ell \leq j < f(\ell)} \lambda_{j}^{2} \leq \varepsilon^{3}n^{2}.
    \end{equation*}\medskip

    Adicionalmente, por la ortonormalidad de la base,\medskip

    \begin{align*}
        \sum_{a,b\in [n]} T_2 (a,b)^{2} &= \sum_{a,b\in [n]} \left( \sum_{\ell \leq i < f(\ell)} \lambda_i u_i(a) u_i(b)\right)^{2}\\
        &= \sum_{a,b\in [n]} \sum_{\ell \leq i,j < f(\ell)} \lambda_i \lambda_j u_i(a) u_j(a) u_i(b) u_j(b)\\
        &= \sum_{\ell \leq i,j < f(\ell)} \lambda_i \lambda_j \sum_{a\in [n]} u_i(a) u_j(a) \sum_{b\in [n]} u_i(b) u_j(b)\\
        &= \sum_{\ell \leq i < f(\ell)} \lambda_{i}^{2} \norm{u_i}^{4}\\
        &= \Tr (T_{2}^{2}).
    \end{align*}\medskip

    Entonces, dada la igualdad anterior, se determina que\medskip

    \begin{equation} \label{eq_6 Spectral_Proof}
        \sum_{a,b\in [n]} T_{2}(a,b)^{2} \leq \varepsilon^{3}n^{2}.
    \end{equation}\medskip

    Ahora, defina el conjunto $\Theta_1 \subset [M]^{2}$ de manera tal que todo par $(i,j)\not\in \Theta_1$ satisface\medskip

    \begin{equation} \label{eq_7 Spectral_Proof}
        \sum_{a\in V_i} \sum_{b\in V_j} T_{2}(a,b)^{2} \leq \varepsilon |V_i| |V_j|.
    \end{equation}\medskip

    Más aún, para los pares $(i,j)\in \Theta_1$, la desigualdad \eqref{eq_6 Spectral_Proof} en particular establece que\medskip

    \begin{equation*}
        \varepsilon^{3} n^{2} \geq \sum_{(i,j)\in \Theta_1} \sum_{a\in V_i} \sum_{b\in V_j} T_{2}(a,b)^{2} > \varepsilon \sum_{(i,j)\in \Theta_1} |V_i| |V_j|.
    \end{equation*}\medskip

    Por consecuencia,\medskip

    \begin{equation} \label{eq_8 Spectral_Proof}
        \sum_{(i,j)\in \Theta_1} |V_i| |V_j| \leq \varepsilon^{2} n^{2}.
    \end{equation}\medskip

    De esta manera, para $(i,j)\not\in \Theta_1$, $A\subset V_i$ y $B\subset V_j$, utilizamos la desigualdad \eqref{eq_7 Spectral_Proof} y Cauchy-Schwarz para conseguir\medskip

    \begin{align*}
    \left| v_{A}^{T} T_2 v_B\right|^{2} &= \left| \sum_{a\in A}\sum_{b\in B} T_{2}(a,b)\right|^{2}\\
    &\overset{\mathrm{C-S}}{\leq} \left( \sum_{a\in A}\sum_{b\in B} T_{2}(a,b)^{2}\right)|A||B|\\
    &\leq \varepsilon^{2} |V_i| |V_j| |A| |B|\\
    &\leq \varepsilon^{2} |V_i|^{2} |V_j|^{2}.
    \end{align*}\medskip

    Así, se obtiene la cota asociada a $T_2$.\medskip

    \begin{equation} \label{eq_9 Spectral_Proof}
        |v_{A}^{T} T_2 v_B| \leq \varepsilon |V_i| |V_j|.
    \end{equation}\medskip

    \textbf{Analizamos} $\mathbf{T_3}$. Note que el valor propio más grande en magnitud de $T_3$ es $\lambda_{f(\ell)}$. Entonces, utilizando el operador norma \fs{Definir...} de la matriz $T_3$ y el Teorema \ref{Teo Courant-Fischer},\medskip

    \begin{equation*}
        \frac{\norm{T_3 v_B}}{\norm{v_B}} \leq \sup_{\substack{x\in \mathbb{R}^{n} \\ x\not= 0}} \frac{\norm{T_3 x}}{\norm{x}} = \left|\lambda_{f(\ell)}\right| \leq \frac{n}{\sqrt{f(\ell)}}.
    \end{equation*}\medskip

    Como resultado,\medskip

    \begin{equation*}
        \norm{T_3 v_B} \leq \norm{v_B}\frac{n}{\sqrt{f(\ell)}}.
    \end{equation*}\medskip

    Usando la desigualdad anterior junto a Cauchy-Schwarz se obtiene la siguiente cota para $T_3$.\medskip

    \begin{align} \label{eq_10 Spectral_Proof}
        \left| v_{A}^{T} T_3 v_B\right| &= \left| \langle v_A, T_3 v_B \rangle \right| \nonumber\\
        &\overset{\mathrm{C-S}}{\leq} \norm{v_A} \norm{T_3 v_B} \nonumber\\
        &\leq \norm{v_A} \norm{v_B} \frac{n}{\sqrt{f(\ell)}} \\
        &= \sqrt{|A| |B|} \frac{n}{\sqrt{f(\ell)}} \nonumber\\
        &\leq \frac{n^{2}}{\sqrt{f(\ell)}}.\nonumber
    \end{align}\medskip

    Ya con el control de $T_1$, $T_2$ y $T_3$, nos enfocamos en estudiar $G$ de manera global. Consideramos $\Theta \subset \lbrace 0,1,...,M\rbrace^{2}$ definido de la siguiente manera:\medskip

    \begin{equation*}
        \Theta := \left\lbrace (i,j)\in \lbrace 0,1,...,M\rbrace^{2} : (i,j)\in \Theta_1\  \vee\  i = 0\  \vee\  j = 0\  \vee\  \min\lbrace |V_i|, |V_j|\rbrace\leq \frac{\varepsilon n}{M}\right\rbrace.
    \end{equation*}\medskip

    Con esta definición, la desigualdad \eqref{eq_8 Spectral_Proof}, y recordando que $|V_0| < \varepsilon n$,\medskip

    \begin{align*}
        \sum_{(i,j)\in \Theta} |V_i| |V_j| &= \sum_{(i,j)\in \Theta_1} |V_i| |V_j| + \sum_{j=0}^{M} |V_0| |V_j| + \sum_{i=0}^{M} |V_i| |V_0| + \sum_{|V_i| \leq \frac{\varepsilon n}{M}} |V_i| |V_j| + \sum_{|V_j|\leq \frac{\varepsilon n}{M}} |V_i| |V_j| \\
        &\leq \sum_{(i,j)\in \Theta_1} |V_i| |V_j| + 2|V_0|n + 2\sum_{|V_i|\leq \frac{\varepsilon n}{M}} |V_i| n \\
        &\leq \varepsilon^{2} n^{2} + 2\varepsilon n^{2} + 2M\frac{\varepsilon}{M} n^{2}\\
        &\leq 5\varepsilon n^{2}.
    \end{align*}\medskip

    Al ver la cota anterior, $\Theta$ se interpreta como un conjunto excepcional de pocos elementos que contiene los malos casos. Ahora bien, si $(i,j)\not\in \Theta$, todo $A\subset V_i$ y $B\subset V_j$ satisfacen la desigualdad\medskip

    \begin{align} \label{eq_11 Spectral_Proof}
        \Big| e(A,B) - d_{ij}|A||B|\Big| &= \left| v_{A}^{T}(T - d_{ij}\mathbbm{1}_{n\times n}) v_B \right|\nonumber\\
        &\leq \left| v_{A}^{T} (T_1 -d_{ij}\mathbbm{1}_{n\times n}) v_B\right| + \left| v_{A}^{T} T_2 v_B\right| + \left| v_{A}^{T} T_3 v_B\right|\nonumber\\
        &\leq 4\varepsilon |V_i| |V_j| + \varepsilon |V_i| |V_j| + \frac{n^{2}}{\sqrt{f(\ell)}}.
    \end{align}\medskip

    Observando la desigualdad en \eqref{eq_11 Spectral_Proof}, para $(i,j)\not\in \Theta$, se necesita que $\frac{n^{2}}{\sqrt{f(\ell)}} \leq \varepsilon |V_i| |V_j|$ para asegurar que la partición $\lbrace V_0, V_1,..., V_M\rbrace$ de $[n]$ es $(6\varepsilon)$-regular. Para esto, gracias a que $|V_i|, |V_j|\geq \frac{\varepsilon n}{M}$, se cumple la desigualdad $\frac{\varepsilon^{2} n^{2}}{M^{2}} \leq |V_i| |V_j|$, y por consecuencia\medskip

    \begin{equation*}
        \frac{n^{2}}{\sqrt{f(\ell)}} \leq \frac{M^{2} |V_i| |V_j|}{\varepsilon^{2}\sqrt{f(\ell)}}.
    \end{equation*}\medskip

    Finalmente, para obtener la partición $(6\varepsilon)$-regular del conjunto de vértices del grafo $G$, es suficiente asumir que $\frac{1}{\sqrt{f(\ell)}} \leq \frac{\varepsilon^{3}}{M^{2}}$. Así, recordando la cota vista en \eqref{eq_4 Spectral_Proof}, basta elegir\medskip

    \begin{equation*}
        f(x) \geq \frac{1}{\varepsilon^{6}}\left( \frac{2x^{2}}{\varepsilon^{2}}\right)^{4x}.
    \end{equation*}
    \end{proof}


\section{Bibliografía}
\begin{enumerate}
    \item[[1]] Krivelevich, M., & Sudakov, B. (2006). Pseudo-random Graphs. In Bolyai Society Mathematical Studies (pp. 199–262). Springer Berlin Heidelberg.
    \item[[2]] Chung, F. R. K., Graham, R. L., & Wilson, R. M. (1989). Quasi-random graphs. Combinatorica. An International Journal on Combinatorics and the Theory of Computing.
    \item[[3]] Chan, T. F. N., Král’, D., Noel, J. A., Pehova, Y., Sharifzadeh, M., & Volec, J. (2020). Characterization of quasirandom permutations by a pattern sum. Random Structures & Algorithms.
    \item[[4]] Hàn, H., Kiwi, M., & Pavez-Signé, M. (2021). Quasi-random words and limits of word sequences. Journal Europeen de Combinatoire [European Journal of Combinatorics].
\end{enumerate}



\end{document}